{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data...\n",
      "Data shape: (1724, 19, 100, 10), Labels shape: (1724,)\n",
      "Training set: (1379, 19, 100, 10), Testing set: (345, 19, 100, 10)\n",
      "New training data shape: (1379, 19, 100, 10)\n",
      "New testing data shape: (345, 19, 100, 10)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(root_path, test_size=0.2, random_state=42):\n",
    "    \"\"\"Loads gesture dataset and splits into train/test sets.\"\"\"\n",
    "    data_path = os.path.join(root_path, \"processed_gesture_data.npy\")\n",
    "    label_path = os.path.join(root_path, \"gesture_labels.npy\")\n",
    "    \n",
    "    if not os.path.exists(data_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"Processed gesture data or labels not found. Please run process_all_gesture_files first.\")\n",
    "    \n",
    "    print(\"Loading processed data...\")\n",
    "    X = np.load(data_path, allow_pickle=True)\n",
    "    y = np.load(label_path, allow_pickle=True)\n",
    "    \n",
    "    print(f\"Data shape: {X.shape}, Labels shape: {y.shape}\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "    \n",
    "    print(f\"Training set: {X_train.shape}, Testing set: {X_test.shape}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def extract_emg_features(signal, fs=1000):\n",
    "    \"\"\"Extracts features from an EMG signal (100 time steps).\"\"\"\n",
    "    mav = np.mean(np.abs(signal))  # Mean Absolute Value\n",
    "    rms = np.sqrt(np.mean(signal**2))  # Root Mean Square\n",
    "    var = np.var(signal)  # Variance\n",
    "    zc = np.sum(np.diff(np.sign(signal)) != 0)  # Zero Crossing Count\n",
    "    wl = np.sum(np.abs(np.diff(signal)))  # Waveform Length\n",
    "\n",
    "    # Frequency-domain features using FFT\n",
    "    fft_vals = np.fft.rfft(signal)\n",
    "    freqs = np.fft.rfftfreq(len(signal), d=1/fs)\n",
    "    power = np.abs(fft_vals)**2\n",
    "    total_power = np.sum(power)\n",
    "    mean_freq = np.sum(freqs * power) / total_power if total_power else 0\n",
    "\n",
    "    cumsum_power = np.cumsum(power)\n",
    "    median_freq = freqs[np.where(cumsum_power >= total_power/2)[0][0]] if total_power else 0\n",
    "\n",
    "    return np.array([mav, rms, var, zc, wl, mean_freq, median_freq])\n",
    "\n",
    "def synthesize_time_series(features, num_timesteps=100):\n",
    "    \"\"\"\n",
    "    Generates a synthetic time series of length `num_timesteps` from extracted features.\n",
    "    Uses Gaussian noise centered at the mean feature values.\n",
    "    \"\"\"\n",
    "    synthesized_signal = np.zeros((num_timesteps,))\n",
    "    \n",
    "    for i, feature in enumerate(features):\n",
    "        synthesized_signal += feature * np.sin(2 * np.pi * (i + 1) * np.linspace(0, 1, num_timesteps))\n",
    "    \n",
    "    return synthesized_signal + np.random.normal(0, 0.05, num_timesteps)  # Add small noise\n",
    "\n",
    "def replace_emg_with_synthetic_data(X, fs=1000):\n",
    "    \"\"\"\n",
    "    Replaces the first 4 EMG channels in each window with synthesized time series\n",
    "    generated from extracted features, while keeping the last 6 IMU channels unchanged.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Shape (num_samples, num_windows, num_timesteps, num_channels)\n",
    "    - fs: Sampling frequency\n",
    "\n",
    "    Returns:\n",
    "    - X_new: Same shape as X, but with EMG channels replaced by synthetic features\n",
    "    \"\"\"\n",
    "    num_samples, num_windows, num_timesteps, num_channels = X.shape\n",
    "    new_X = np.copy(X)  # Keep the original structure\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        for j in range(num_windows):\n",
    "            for ch in range(4):  # Replace only the first 4 EMG channels\n",
    "                features = extract_emg_features(X[i, j, :, ch], fs)\n",
    "                new_X[i, j, :, ch] = synthesize_time_series(features, num_timesteps)\n",
    "\n",
    "    return new_X\n",
    "\n",
    "# Load original data\n",
    "data_folder = r\"new_collect\"  \n",
    "X_train, X_test, y_train, y_test = load_data(data_folder)\n",
    "\n",
    "# Replace EMG channels with synthesized time series\n",
    "X_train_new = replace_emg_with_synthetic_data(X_train, fs=1000)\n",
    "X_test_new = replace_emg_with_synthetic_data(X_test, fs=1000)\n",
    "\n",
    "print(f\"New training data shape: {X_train_new.shape}\")\n",
    "print(f\"New testing data shape: {X_test_new.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Classes: 23, Batches: 1379, Windows: 19, Features: 100, Channels: 10\n",
      "X_train_new shape: (1379, 19, 100, 10), y_train shape: (1379, 23)\n",
      "X_test_new shape: (345, 19, 100, 10), y_test shape: (345, 23)\n",
      "Epoch 1/100\n",
      "44/44 [==============================] - 3s 19ms/step - loss: 3.4460 - accuracy: 0.0508 - val_loss: 3.0636 - val_accuracy: 0.1043 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 3.0249 - accuracy: 0.0928 - val_loss: 2.7766 - val_accuracy: 0.1623 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 2.8127 - accuracy: 0.1516 - val_loss: 2.5721 - val_accuracy: 0.2464 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 2.5857 - accuracy: 0.2132 - val_loss: 2.2242 - val_accuracy: 0.3507 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 2.3557 - accuracy: 0.2487 - val_loss: 1.9968 - val_accuracy: 0.4116 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 2.1497 - accuracy: 0.3176 - val_loss: 1.6585 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1.9699 - accuracy: 0.3466 - val_loss: 1.4835 - val_accuracy: 0.5014 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.8207 - accuracy: 0.3851 - val_loss: 1.4085 - val_accuracy: 0.5188 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1.6490 - accuracy: 0.4300 - val_loss: 1.2358 - val_accuracy: 0.5739 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1.5291 - accuracy: 0.4757 - val_loss: 1.0054 - val_accuracy: 0.6725 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1.4128 - accuracy: 0.5185 - val_loss: 0.9255 - val_accuracy: 0.6812 - lr: 9.0000e-04\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1.2517 - accuracy: 0.5577 - val_loss: 0.7791 - val_accuracy: 0.7246 - lr: 9.0000e-04\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 1.0684 - accuracy: 0.6062 - val_loss: 0.6773 - val_accuracy: 0.7623 - lr: 9.0000e-04\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 1.0754 - accuracy: 0.6323 - val_loss: 0.6724 - val_accuracy: 0.7768 - lr: 9.0000e-04\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.9394 - accuracy: 0.6512 - val_loss: 0.5537 - val_accuracy: 0.7826 - lr: 9.0000e-04\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.8821 - accuracy: 0.6802 - val_loss: 0.4931 - val_accuracy: 0.8319 - lr: 9.0000e-04\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.9022 - accuracy: 0.6701 - val_loss: 0.5012 - val_accuracy: 0.8145 - lr: 9.0000e-04\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.9510 - accuracy: 0.6439 - val_loss: 0.5456 - val_accuracy: 0.7942 - lr: 9.0000e-04\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.7170 - accuracy: 0.7259 - val_loss: 0.4393 - val_accuracy: 0.8174 - lr: 9.0000e-04\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.7037 - accuracy: 0.7433 - val_loss: 0.3486 - val_accuracy: 0.8638 - lr: 9.0000e-04\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.6722 - accuracy: 0.7484 - val_loss: 0.3683 - val_accuracy: 0.8696 - lr: 8.1000e-04\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.5862 - accuracy: 0.7658 - val_loss: 0.3432 - val_accuracy: 0.8812 - lr: 8.1000e-04\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.7492 - accuracy: 0.7288 - val_loss: 0.4106 - val_accuracy: 0.8580 - lr: 8.1000e-04\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.6040 - accuracy: 0.7708 - val_loss: 0.3110 - val_accuracy: 0.8609 - lr: 8.1000e-04\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.5589 - accuracy: 0.7817 - val_loss: 0.3531 - val_accuracy: 0.8522 - lr: 8.1000e-04\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.4897 - accuracy: 0.8013 - val_loss: 0.2891 - val_accuracy: 0.8754 - lr: 8.1000e-04\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.4837 - accuracy: 0.8144 - val_loss: 0.2978 - val_accuracy: 0.9043 - lr: 8.1000e-04\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.4360 - accuracy: 0.8281 - val_loss: 0.2605 - val_accuracy: 0.8812 - lr: 8.1000e-04\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.4407 - accuracy: 0.8238 - val_loss: 0.2957 - val_accuracy: 0.8870 - lr: 8.1000e-04\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.4138 - accuracy: 0.8528 - val_loss: 0.2388 - val_accuracy: 0.9014 - lr: 8.1000e-04\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.3381 - accuracy: 0.8745 - val_loss: 0.2405 - val_accuracy: 0.8957 - lr: 7.2900e-04\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.3228 - accuracy: 0.8738 - val_loss: 0.2089 - val_accuracy: 0.9014 - lr: 7.2900e-04\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.3393 - accuracy: 0.8651 - val_loss: 0.2441 - val_accuracy: 0.8928 - lr: 7.2900e-04\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.3303 - accuracy: 0.8709 - val_loss: 0.1984 - val_accuracy: 0.9304 - lr: 7.2900e-04\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.3054 - accuracy: 0.8934 - val_loss: 0.2217 - val_accuracy: 0.9072 - lr: 7.2900e-04\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2711 - accuracy: 0.8934 - val_loss: 0.2551 - val_accuracy: 0.9043 - lr: 7.2900e-04\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.3224 - accuracy: 0.8876 - val_loss: 0.2452 - val_accuracy: 0.8899 - lr: 7.2900e-04\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.3206 - accuracy: 0.8753 - val_loss: 0.2956 - val_accuracy: 0.8870 - lr: 7.2900e-04\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.4101 - accuracy: 0.8557 - val_loss: 0.3689 - val_accuracy: 0.8667 - lr: 7.2900e-04\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.3028 - accuracy: 0.8905 - val_loss: 0.2597 - val_accuracy: 0.8812 - lr: 7.2900e-04\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2663 - accuracy: 0.9021 - val_loss: 0.2569 - val_accuracy: 0.9159 - lr: 6.5610e-04\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2228 - accuracy: 0.9094 - val_loss: 0.2535 - val_accuracy: 0.9130 - lr: 6.5610e-04\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2249 - accuracy: 0.9115 - val_loss: 0.2255 - val_accuracy: 0.9101 - lr: 6.5610e-04\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.2027 - accuracy: 0.9231 - val_loss: 0.2305 - val_accuracy: 0.9159 - lr: 6.5610e-04\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2048 - accuracy: 0.9217 - val_loss: 0.2654 - val_accuracy: 0.9217 - lr: 6.5610e-04\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2303 - accuracy: 0.9144 - val_loss: 0.2724 - val_accuracy: 0.9043 - lr: 6.5610e-04\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.1792 - accuracy: 0.9362 - val_loss: 0.1968 - val_accuracy: 0.9449 - lr: 6.5610e-04\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.1550 - accuracy: 0.9369 - val_loss: 0.2374 - val_accuracy: 0.9217 - lr: 6.5610e-04\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.1841 - accuracy: 0.9420 - val_loss: 0.2696 - val_accuracy: 0.9275 - lr: 6.5610e-04\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.1658 - accuracy: 0.9492 - val_loss: 0.2217 - val_accuracy: 0.9304 - lr: 6.5610e-04\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.1807 - accuracy: 0.9398 - val_loss: 0.3267 - val_accuracy: 0.9101 - lr: 5.9049e-04\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.1588 - accuracy: 0.9333 - val_loss: 0.2666 - val_accuracy: 0.9217 - lr: 5.9049e-04\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2115 - accuracy: 0.9253 - val_loss: 0.3017 - val_accuracy: 0.9043 - lr: 5.9049e-04\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2406 - accuracy: 0.9159 - val_loss: 0.2396 - val_accuracy: 0.9275 - lr: 5.9049e-04\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2109 - accuracy: 0.9275 - val_loss: 0.2165 - val_accuracy: 0.9420 - lr: 5.9049e-04\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2041 - accuracy: 0.9289 - val_loss: 0.2241 - val_accuracy: 0.9333 - lr: 5.9049e-04\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.2192 - accuracy: 0.9275 - val_loss: 0.2351 - val_accuracy: 0.9304 - lr: 5.9049e-04\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.1590 - accuracy: 0.9463 - val_loss: 0.3041 - val_accuracy: 0.9043 - lr: 5.9049e-04\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.2025 - accuracy: 0.9304 - val_loss: 0.2193 - val_accuracy: 0.9304 - lr: 5.9049e-04\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.1479 - accuracy: 0.9478 - val_loss: 0.2011 - val_accuracy: 0.9362 - lr: 5.9049e-04\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.1101 - accuracy: 0.9587 - val_loss: 0.2264 - val_accuracy: 0.9304 - lr: 5.3144e-04\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 0.1101 - accuracy: 0.9616 - val_loss: 0.2426 - val_accuracy: 0.9333 - lr: 5.3144e-04\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.1368 - accuracy: 0.9492 - val_loss: 0.2239 - val_accuracy: 0.9391 - lr: 5.3144e-04\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 3s 59ms/step - loss: 0.1288 - accuracy: 0.9623 - val_loss: 0.1853 - val_accuracy: 0.9391 - lr: 5.3144e-04\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.1020 - accuracy: 0.9630 - val_loss: 0.2207 - val_accuracy: 0.9449 - lr: 5.3144e-04\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.1097 - accuracy: 0.9565 - val_loss: 0.1917 - val_accuracy: 0.9362 - lr: 5.3144e-04\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.1113 - accuracy: 0.9637 - val_loss: 0.2153 - val_accuracy: 0.9304 - lr: 5.3144e-04\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.0937 - accuracy: 0.9710 - val_loss: 0.3403 - val_accuracy: 0.9217 - lr: 5.3144e-04\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 0s 9ms/step - loss: 0.1790 - accuracy: 0.9413 - val_loss: 0.3062 - val_accuracy: 0.9188 - lr: 5.3144e-04\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 2s 50ms/step - loss: 0.1240 - accuracy: 0.9594 - val_loss: 0.2241 - val_accuracy: 0.9420 - lr: 5.3144e-04\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.1563 - accuracy: 0.9594 - val_loss: 0.2400 - val_accuracy: 0.9275 - lr: 4.7830e-04\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.1229 - accuracy: 0.9616 - val_loss: 0.2126 - val_accuracy: 0.9449 - lr: 4.7830e-04\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.1224 - accuracy: 0.9587 - val_loss: 0.1983 - val_accuracy: 0.9420 - lr: 4.7830e-04\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0983 - accuracy: 0.9623 - val_loss: 0.2029 - val_accuracy: 0.9449 - lr: 4.7830e-04\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0874 - accuracy: 0.9703 - val_loss: 0.1918 - val_accuracy: 0.9536 - lr: 4.7830e-04\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0912 - accuracy: 0.9732 - val_loss: 0.2545 - val_accuracy: 0.9362 - lr: 4.7830e-04\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.1129 - accuracy: 0.9681 - val_loss: 0.2463 - val_accuracy: 0.9478 - lr: 4.7830e-04\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.1003 - accuracy: 0.9666 - val_loss: 0.2308 - val_accuracy: 0.9420 - lr: 4.7830e-04\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0967 - accuracy: 0.9724 - val_loss: 0.2033 - val_accuracy: 0.9478 - lr: 4.7830e-04\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 0.0657 - accuracy: 0.9775 - val_loss: 0.3029 - val_accuracy: 0.9333 - lr: 4.7830e-04\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0560 - accuracy: 0.9826 - val_loss: 0.2338 - val_accuracy: 0.9536 - lr: 4.3047e-04\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 0.0680 - accuracy: 0.9782 - val_loss: 0.3032 - val_accuracy: 0.9159 - lr: 4.3047e-04\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0907 - accuracy: 0.9717 - val_loss: 0.3122 - val_accuracy: 0.9246 - lr: 4.3047e-04\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0591 - accuracy: 0.9826 - val_loss: 0.2662 - val_accuracy: 0.9304 - lr: 4.3047e-04\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 1s 14ms/step - loss: 0.0675 - accuracy: 0.9746 - val_loss: 0.3247 - val_accuracy: 0.9246 - lr: 4.3047e-04\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 1s 13ms/step - loss: 0.0765 - accuracy: 0.9768 - val_loss: 0.3266 - val_accuracy: 0.9304 - lr: 4.3047e-04\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0527 - accuracy: 0.9848 - val_loss: 0.2765 - val_accuracy: 0.9391 - lr: 4.3047e-04\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0473 - accuracy: 0.9855 - val_loss: 0.2370 - val_accuracy: 0.9449 - lr: 4.3047e-04\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 0s 11ms/step - loss: 0.0477 - accuracy: 0.9848 - val_loss: 0.2901 - val_accuracy: 0.9362 - lr: 4.3047e-04\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0378 - accuracy: 0.9884 - val_loss: 0.2479 - val_accuracy: 0.9391 - lr: 4.3047e-04\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0444 - accuracy: 0.9869 - val_loss: 0.2938 - val_accuracy: 0.9420 - lr: 3.8742e-04\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0473 - accuracy: 0.9848 - val_loss: 0.2535 - val_accuracy: 0.9565 - lr: 3.8742e-04\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0490 - accuracy: 0.9840 - val_loss: 0.2422 - val_accuracy: 0.9478 - lr: 3.8742e-04\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0507 - accuracy: 0.9869 - val_loss: 0.2539 - val_accuracy: 0.9478 - lr: 3.8742e-04\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0381 - accuracy: 0.9869 - val_loss: 0.2575 - val_accuracy: 0.9420 - lr: 3.8742e-04\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0542 - accuracy: 0.9848 - val_loss: 0.2534 - val_accuracy: 0.9391 - lr: 3.8742e-04\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0676 - accuracy: 0.9840 - val_loss: 0.2909 - val_accuracy: 0.9333 - lr: 3.8742e-04\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0845 - accuracy: 0.9790 - val_loss: 0.2542 - val_accuracy: 0.9362 - lr: 3.8742e-04\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 0s 10ms/step - loss: 0.0833 - accuracy: 0.9753 - val_loss: 0.3324 - val_accuracy: 0.9072 - lr: 3.8742e-04\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 1s 11ms/step - loss: 0.0496 - accuracy: 0.9833 - val_loss: 0.2718 - val_accuracy: 0.9304 - lr: 3.8742e-04\n",
      "11/11 [==============================] - 0s 4ms/step\n",
      "Test Accuracy: 0.9304\n",
      "Model saved as cnn_emg_model.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed, Conv1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling1D\n",
    "\n",
    "X_train_new = np.nan_to_num(X_train_new, nan=0.0)\n",
    "X_test_new = np.nan_to_num(X_test_new, nan=0.0)\n",
    "y_train = np.nan_to_num(y_train, nan = 0.0)\n",
    "y_test = np.nan_to_num(y_test, nan = 0.0)\n",
    "# **获取数据形状**\n",
    "num_batches = X_train_new.shape[0]  # batch 维度\n",
    "num_windows = X_train_new.shape[1]  # 时间步（窗口数 59）\n",
    "num_features = X_train_new.shape[2]  # 特征数（15）\n",
    "num_channels = X_train_new.shape[3]  # 通道数（1）\n",
    "\n",
    "# **检测类别数量**\n",
    "unique_classes = np.unique(y_train)\n",
    "num_classes = len(unique_classes)  # 确保类别数正确\n",
    "\n",
    "print(f\"Corrected Classes: {num_classes}, Batches: {num_batches}, Windows: {num_windows}, Features: {num_features}, Channels: {num_channels}\")\n",
    "\n",
    "# **保持 X 形状**\n",
    "X_train_new = X_train_new.reshape(num_batches, num_windows, num_features, num_channels)\n",
    "X_test_new = X_test_new.reshape(X_test_new.shape[0], num_windows, num_features, num_channels)\n",
    "X_train_new = X_train_new[:,:,:,:]\n",
    "X_test_new = X_test_new[:,:,:,:]\n",
    "\n",
    "# print(X_train_new.shape)\n",
    "\n",
    "num_features = X_train_new.shape[2] \n",
    "num_channels = X_train_new.shape[3]\n",
    "# **标签编码**\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)  # 转换成 0,1,2\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "# **转换为 One-Hot**\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "print(f\"X_train_new shape: {X_train_new.shape}, y_train shape: {y_train.shape}\")  # (batch, 59, 15, 1) (batch, 3)\n",
    "print(f\"X_test_new shape: {X_test_new.shape}, y_test shape: {y_test.shape}\")  # (batch, 59, 15, 1) (batch, 3)\n",
    "\n",
    "\n",
    "X_train_new = X_train_new.reshape(X_train_new.shape[0], X_train_new.shape[1], -1)  # (batch_size, 29, 40)\n",
    "X_test_new = X_test_new.reshape(X_test_new.shape[0], X_test_new.shape[1], -1)  \n",
    "\n",
    "# # print(num_features)\n",
    "# # **构建 LSTM 处理通道的模型**\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(num_windows, num_features * num_channels)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')  # 多分类输出\n",
    "])\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        return lr * 0.9  # 每 10 个 epoch，学习率减半\n",
    "    return lr\n",
    "\n",
    "# **编译模型**\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),  # 初始学习率\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# **使用回调函数**\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# **训练时加上 callback**\n",
    "history = model.fit(X_train_new, y_train, epochs=100, callbacks=[lr_callback], validation_data=(X_test_new, y_test))\n",
    "\n",
    "\n",
    "# **测试模型**\n",
    "y_pred = model.predict(X_test_new)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# **计算准确率**\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# **保存模型**\n",
    "model.save(\"cnn_emg_model.h5\")\n",
    "print(\"Model saved as cnn_emg_model.h5\")\n",
    "# Test Accuracy: 0.9826\n",
    "# Gt: Test Accuracy: 0.9391\n",
    "\n",
    "# 2 datasets:\n",
    "# Test Accuracy: 0.9524\n",
    "\n",
    "# 3 datasets:\n",
    "# Test Accuracy: 0.9304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grad_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
