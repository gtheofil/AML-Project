import threading
import serial
import csv
import os
import time
import numpy as np
from datetime import datetime
from collections import deque
from tensorflow.keras.models import load_model
from sklearn.preprocessing import StandardScaler

# **å…¨å±€å˜é‡**
data_buffer = deque(maxlen=5000)  # 5s æ•°æ®ç¼“å­˜
stop_event = threading.Event()

# **ä¸²å£é…ç½®**
SERIAL_PORT = "COM4"  # ä¿®æ”¹ä¸º Arduino ç«¯å£
BAUD_RATE = 115200
FILENAME = "sensor_data.csv"

# **LSTM æ¨¡å‹**
MODEL_PATH = "new_collect/fzh/rnn_emg_model.h5"

# **ä¼ æ„Ÿå™¨æ•°æ®æ ¼å¼ (EMG + IMU)**
NUM_CHANNELS = 10  # 4 EMG + 6 IMU
WINDOW_SIZE = 1000  # 5s æ•°æ® (1000ms * 5)
STRIDE = 50  # æ¯ 50ms å¤„ç†ä¸€æ¬¡
TIME_STEPS = 100  # LSTM æœŸæœ›çš„ time_steps
NUM_WINDOWS = 19  # è®¡ç®—å¾—åˆ°çš„æ—¶é—´çª—å£æ•°é‡

# **å½’ä¸€åŒ–**
scaler = StandardScaler()

# **åŠ è½½ LSTM æ¨¡å‹**
if os.path.exists(MODEL_PATH):
    model = load_model(MODEL_PATH)
    print("âœ… LSTM Model loaded successfully!")
else:
    raise FileNotFoundError(f"âŒ Model file not found at {MODEL_PATH}")

# **æ•°æ®é‡‡é›†çº¿ç¨‹**
def record_sensor_data():
    """ ä» Arduino è¯»å–ä¼ æ„Ÿå™¨æ•°æ® (EMG + IMU) å¹¶å­˜å…¥ data_buffer """
    try:
        ser = serial.Serial(SERIAL_PORT, BAUD_RATE, timeout=1)
    except serial.SerialException as e:
        print(f"âŒ ä¸²å£é”™è¯¯: {e}")
        return

    print(f"[INFO] âœ… å¼€å§‹é‡‡é›†æ•°æ®ï¼Œå­˜å…¥: {FILENAME}")

    with open(FILENAME, 'w', newline='') as csvfile:
        writer = csv.writer(csvfile)
        writer.writerow(["Time (ms)", "EMG1", "EMG2", "EMG3", "EMG4", "AccX", "AccY", "AccZ", "GyroX", "GyroY", "GyroZ"])

        start_time = datetime.now()
        try:
            while not stop_event.is_set():
                line = ser.readline().decode('utf-8', errors='ignore').strip()
                if line:
                    parts = line.split()
                    if len(parts) == 10:  # ç¡®ä¿æ•°æ®å®Œæ•´
                        try:
                            emg_values = list(map(int, parts[:4]))  # EMG æ•°æ®
                            imu_values = list(map(int, parts[4:]))  # IMU æ•°æ®
                            elapsed_time = (datetime.now() - start_time).total_seconds() * 1000  # æ¯«ç§’

                            # å­˜å…¥é˜Ÿåˆ—
                            data_buffer.append([elapsed_time] + emg_values + imu_values)

                        except ValueError:
                            print(f"[WARNING] â— æ•°æ®è§£æå¤±è´¥: {line}")

            print("[INFO] âœ… æ•°æ®é‡‡é›†å®Œæˆ")
        except KeyboardInterrupt:
            print("\n[INFO] ğŸ›‘ æ‰‹åŠ¨åœæ­¢æ•°æ®é‡‡é›†")
        finally:
            ser.close()
            print("[INFO] âœ… ä¸²å£å·²å…³é—­")

# **æ•°æ®é¢„å¤„ç†çº¿ç¨‹**
def data_preprocess():
    """ æ¯ 0.5s è¯»å– 5s æ•°æ®ï¼Œå¹¶è¿›è¡Œçª—å£åŒ–å¤„ç† """
    while not stop_event.is_set():
        if len(data_buffer) < WINDOW_SIZE:
            time.sleep(0.1)  # ç¼“å†²æ•°æ®ä¸è¶³æ—¶ç­‰å¾…
            continue

        # è·å–æœ€æ–° 5s æ•°æ®
        recent_data = list(data_buffer)[-WINDOW_SIZE:]

        # è½¬æ¢ä¸º NumPy æ•°ç»„ (1000, 10)
        data_array = np.array(recent_data)[:, 1:]  # ç§»é™¤æ—¶é—´æˆ³ï¼Œåªä¿ç•™ EMG & IMU

        # **å½’ä¸€åŒ–**
        data_array = scaler.fit_transform(data_array)

        # **æ„å»ºæ»‘åŠ¨çª—å£**
        windows = []
        for start in range(0, WINDOW_SIZE - TIME_STEPS + 1, STRIDE):  # 1000-100+1ï¼Œç¡®ä¿19ä¸ªçª—å£
            windows.append(data_array[start:start + TIME_STEPS])  # (100, 10)

        # **è½¬æ¢å½¢çŠ¶ (19, 100, 10)**
        windows = np.array(windows)

        # **è°ƒæ•´å½¢çŠ¶ä¸º (1, 19, 1000)**
        processed_windows = windows.reshape(1, NUM_WINDOWS, TIME_STEPS * NUM_CHANNELS)

        # å­˜å…¥å…¨å±€å˜é‡
        global processed_data
        processed_data = processed_windows

        # print(f"[INFO] âœ… é¢„å¤„ç†å®Œæˆ: {processed_windows.shape}")

        time.sleep(0.5)  # 0.5s è¿è¡Œä¸€æ¬¡


# **é¢„æµ‹çº¿ç¨‹**
def prediction():
    """ æ¯ 0.5s è¿è¡Œä¸€æ¬¡é¢„æµ‹ """
    while not stop_event.is_set():
        if 'processed_data' not in globals():
            time.sleep(0.1)
            continue

        # è·å–æœ€è¿‘çš„é¢„å¤„ç†æ•°æ®
        input_data = processed_data  # (1, 19, 1000)

        # **è¿›è¡Œé¢„æµ‹**
        predictions = model.predict(input_data,verbose=0)
        predicted_label = np.argmax(predictions, axis=1)

        print(f"ğŸ”® é¢„æµ‹ç»“æœ: {predicted_label}")

        time.sleep(0.1)  # æ¯ 0.5s é¢„æµ‹ä¸€æ¬¡

# **å¯åŠ¨å¤šçº¿ç¨‹**
def start_threads():
    """ å¯åŠ¨æ•°æ®é‡‡é›†ã€é¢„å¤„ç†å’Œé¢„æµ‹çº¿ç¨‹ """
    # çº¿ç¨‹ 1ï¼šæ•°æ®é‡‡é›†
    thread_record = threading.Thread(target=record_sensor_data, daemon=True)

    # çº¿ç¨‹ 2ï¼šæ•°æ®é¢„å¤„ç†
    thread_preprocess = threading.Thread(target=data_preprocess, daemon=True)

    # çº¿ç¨‹ 3ï¼šå®æ—¶é¢„æµ‹
    thread_predict = threading.Thread(target=prediction, daemon=True)

    # å¯åŠ¨çº¿ç¨‹
    thread_record.start()
    thread_preprocess.start()
    thread_predict.start()

    return thread_record, thread_preprocess, thread_predict

# **è¿è¡Œä¸»ç¨‹åº**
if __name__ == "__main__":
    print("[INFO] ğŸš€ å¯åŠ¨ EMG è¯†åˆ«ç³»ç»Ÿ")

    # å¯åŠ¨çº¿ç¨‹
    threads = start_threads()

    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        print("\n[INFO] ğŸ›‘ ç»ˆæ­¢æ‰€æœ‰çº¿ç¨‹...")
        stop_event.set()
        for t in threads:
            t.join()

    print("[INFO] âœ… ç³»ç»Ÿå·²å®‰å…¨å…³é—­")
