{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data...\n",
      "Data shape: (325, 19, 100, 10), Labels shape: (325,)\n",
      "Training set: (260, 19, 100, 10), Testing set: (65, 19, 100, 10)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(root_path, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    加载预处理的手势数据，并拆分为训练集和测试集。\n",
    "    \n",
    "    参数：\n",
    "    root_path (str): 存储 processed_gesture_data.npy 和 gesture_labels.npy 的根目录\n",
    "    test_size (float): 测试集比例，默认 20%\n",
    "    random_state (int): 随机种子，确保可复现性\n",
    "    \n",
    "    返回：\n",
    "    X_train, X_test, y_train, y_test: 训练集和测试集的数据及标签\n",
    "    \"\"\"\n",
    "    data_path = os.path.join(root_path, \"processed_gesture_data.npy\")\n",
    "    label_path = os.path.join(root_path, \"gesture_labels.npy\")\n",
    "    \n",
    "    if not os.path.exists(data_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"Processed gesture data or labels not found. Please run process_all_gesture_files first.\")\n",
    "    \n",
    "    print(\"Loading processed data...\")\n",
    "    X = np.load(data_path,allow_pickle=True)\n",
    "    y = np.load(label_path,allow_pickle=True)\n",
    "    \n",
    "    print(f\"Data shape: {X.shape}, Labels shape: {y.shape}\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "    \n",
    "    print(f\"Training set: {X_train.shape}, Testing set: {X_test.shape}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "data_folder = r\"new_collect\\fzh\"  \n",
    "X_train, X_test, y_train, y_test = load_data(data_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load selected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading processed data...\n",
      "Original Data shape: (325, 19, 100, 10), Labels shape: (325,)\n",
      "Training set: (260, 19, 100, 10), Testing set: (65, 19, 100, 10)\n",
      "Loading processed data...\n",
      "Original Data shape: (325, 19, 100, 10), Labels shape: (325,)\n",
      "Filtered Data shape (after selecting labels {1, 4, 6, 7}): (100, 19, 100, 10)\n",
      "Training set: (80, 19, 100, 10), Testing set: (20, 19, 100, 10)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(root_path, selected_labels=None, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    加载预处理的手势数据，并拆分为训练集和测试集，支持选择特定的标签。\n",
    "    \n",
    "    参数：\n",
    "    - root_path (str): 存储 `processed_gesture_data.npy` 和 `gesture_labels.npy` 的根目录\n",
    "    - selected_labels (list[int] or None): 选择加载的标签列表，例如 [1, 4, 6, 7]。如果 None，则加载所有数据。\n",
    "    - test_size (float): 测试集比例，默认 20%\n",
    "    - random_state (int): 随机种子，确保可复现性\n",
    "    \n",
    "    返回：\n",
    "    - X_train, X_test, y_train, y_test: 训练集和测试集的数据及标签\n",
    "    \"\"\"\n",
    "    data_path = os.path.join(root_path, \"processed_gesture_data.npy\")\n",
    "    label_path = os.path.join(root_path, \"gesture_labels.npy\")\n",
    "    \n",
    "    if not os.path.exists(data_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"Processed gesture data or labels not found. Please run process_all_gesture_files first.\")\n",
    "    \n",
    "    print(\"Loading processed data...\")\n",
    "    X = np.load(data_path, allow_pickle=True)\n",
    "    y = np.load(label_path, allow_pickle=True)\n",
    "    \n",
    "    print(f\"Original Data shape: {X.shape}, Labels shape: {y.shape}\")\n",
    "\n",
    "    # 选择指定标签的数据\n",
    "    if selected_labels is not None:\n",
    "        selected_labels = set(selected_labels)  # 转换为集合加速查询\n",
    "        mask = np.isin(y, list(selected_labels))  # 选择符合标签的数据\n",
    "        X = X[mask]\n",
    "        y = y[mask]\n",
    "        print(f\"Filtered Data shape (after selecting labels {selected_labels}): {X.shape}\")\n",
    "\n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    print(f\"Training set: {X_train.shape}, Testing set: {X_test.shape}\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# 示例调用：加载所有数据\n",
    "data_folder = r\"new_collect\\fzh\"\n",
    "X_train, X_test, y_train, y_test = load_data(data_folder)\n",
    "\n",
    "# 示例调用：只加载选定的标签\n",
    "selected_labels = [1, 4, 6, 7]\n",
    "X_train, X_test, y_train, y_test = load_data(data_folder, selected_labels=selected_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Classes: 13, Batches: 260, Windows: 19, Features: 100, Channels: 10\n",
      "X_train shape: (260, 19, 100, 10), y_train shape: (260, 13)\n",
      "X_test shape: (65, 19, 100, 10), y_test shape: (65, 13)\n",
      "Epoch 1/100\n",
      "9/9 [==============================] - 8s 210ms/step - loss: 2.5671 - accuracy: 0.0385 - val_loss: 2.5540 - val_accuracy: 0.1231 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 2.5492 - accuracy: 0.0769 - val_loss: 2.5331 - val_accuracy: 0.1077 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 2.5145 - accuracy: 0.1154 - val_loss: 2.5068 - val_accuracy: 0.1692 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 2.4954 - accuracy: 0.1423 - val_loss: 2.4919 - val_accuracy: 0.1538 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 2.4726 - accuracy: 0.2115 - val_loss: 2.4644 - val_accuracy: 0.2000 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 2.4509 - accuracy: 0.1962 - val_loss: 2.4398 - val_accuracy: 0.2000 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 2.4215 - accuracy: 0.2192 - val_loss: 2.4166 - val_accuracy: 0.2000 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 52ms/step - loss: 2.3925 - accuracy: 0.2577 - val_loss: 2.3834 - val_accuracy: 0.2462 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 2.3615 - accuracy: 0.2769 - val_loss: 2.3486 - val_accuracy: 0.2308 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 2.3204 - accuracy: 0.2962 - val_loss: 2.3049 - val_accuracy: 0.2769 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 2.2838 - accuracy: 0.3269 - val_loss: 2.2611 - val_accuracy: 0.2923 - lr: 8.0000e-05\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 2.2431 - accuracy: 0.3846 - val_loss: 2.2367 - val_accuracy: 0.3077 - lr: 8.0000e-05\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 2.2183 - accuracy: 0.4077 - val_loss: 2.2110 - val_accuracy: 0.4000 - lr: 8.0000e-05\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 2.1820 - accuracy: 0.4500 - val_loss: 2.1624 - val_accuracy: 0.4462 - lr: 8.0000e-05\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 2.1279 - accuracy: 0.4615 - val_loss: 2.1080 - val_accuracy: 0.4462 - lr: 8.0000e-05\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 2.0753 - accuracy: 0.4500 - val_loss: 2.0473 - val_accuracy: 0.4615 - lr: 8.0000e-05\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 2.0107 - accuracy: 0.4577 - val_loss: 1.9983 - val_accuracy: 0.3846 - lr: 8.0000e-05\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 1.9548 - accuracy: 0.4692 - val_loss: 1.9377 - val_accuracy: 0.3692 - lr: 8.0000e-05\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 1.8869 - accuracy: 0.4346 - val_loss: 1.8782 - val_accuracy: 0.4154 - lr: 8.0000e-05\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 1.8243 - accuracy: 0.4731 - val_loss: 1.8152 - val_accuracy: 0.5077 - lr: 8.0000e-05\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 1.7516 - accuracy: 0.5654 - val_loss: 1.7599 - val_accuracy: 0.5385 - lr: 6.4000e-05\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 1.7013 - accuracy: 0.5885 - val_loss: 1.7064 - val_accuracy: 0.5846 - lr: 6.4000e-05\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 1.6494 - accuracy: 0.6038 - val_loss: 1.6455 - val_accuracy: 0.5692 - lr: 6.4000e-05\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1.5766 - accuracy: 0.6731 - val_loss: 1.5935 - val_accuracy: 0.6462 - lr: 6.4000e-05\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 1s 58ms/step - loss: 1.5227 - accuracy: 0.6692 - val_loss: 1.5320 - val_accuracy: 0.6462 - lr: 6.4000e-05\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 1.4623 - accuracy: 0.7192 - val_loss: 1.4653 - val_accuracy: 0.6769 - lr: 6.4000e-05\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 1.3924 - accuracy: 0.7462 - val_loss: 1.3996 - val_accuracy: 0.6769 - lr: 6.4000e-05\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1.3340 - accuracy: 0.7423 - val_loss: 1.3240 - val_accuracy: 0.6769 - lr: 6.4000e-05\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 1.2660 - accuracy: 0.7808 - val_loss: 1.2648 - val_accuracy: 0.7231 - lr: 6.4000e-05\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 1.2243 - accuracy: 0.7654 - val_loss: 1.2186 - val_accuracy: 0.7385 - lr: 6.4000e-05\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1.1619 - accuracy: 0.7846 - val_loss: 1.1634 - val_accuracy: 0.7385 - lr: 5.1200e-05\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 1.1024 - accuracy: 0.8038 - val_loss: 1.1182 - val_accuracy: 0.7538 - lr: 5.1200e-05\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 1.0621 - accuracy: 0.8077 - val_loss: 1.0745 - val_accuracy: 0.7692 - lr: 5.1200e-05\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 1.0056 - accuracy: 0.8269 - val_loss: 1.0228 - val_accuracy: 0.8000 - lr: 5.1200e-05\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.9670 - accuracy: 0.8077 - val_loss: 0.9778 - val_accuracy: 0.8308 - lr: 5.1200e-05\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.9299 - accuracy: 0.8115 - val_loss: 0.9477 - val_accuracy: 0.8000 - lr: 5.1200e-05\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.8932 - accuracy: 0.8346 - val_loss: 0.9171 - val_accuracy: 0.8000 - lr: 5.1200e-05\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.8514 - accuracy: 0.8192 - val_loss: 0.8827 - val_accuracy: 0.8000 - lr: 5.1200e-05\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.8011 - accuracy: 0.8654 - val_loss: 0.8788 - val_accuracy: 0.8000 - lr: 5.1200e-05\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.7678 - accuracy: 0.8615 - val_loss: 0.8476 - val_accuracy: 0.8000 - lr: 5.1200e-05\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.7404 - accuracy: 0.8654 - val_loss: 0.8137 - val_accuracy: 0.8308 - lr: 4.0960e-05\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.7031 - accuracy: 0.8577 - val_loss: 0.7942 - val_accuracy: 0.8308 - lr: 4.0960e-05\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.6923 - accuracy: 0.8692 - val_loss: 0.7728 - val_accuracy: 0.8308 - lr: 4.0960e-05\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.6655 - accuracy: 0.8808 - val_loss: 0.7474 - val_accuracy: 0.8462 - lr: 4.0960e-05\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.6342 - accuracy: 0.8846 - val_loss: 0.7225 - val_accuracy: 0.8615 - lr: 4.0960e-05\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.6324 - accuracy: 0.8692 - val_loss: 0.6930 - val_accuracy: 0.8462 - lr: 4.0960e-05\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 57ms/step - loss: 0.5989 - accuracy: 0.9000 - val_loss: 0.6742 - val_accuracy: 0.8615 - lr: 4.0960e-05\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 1s 60ms/step - loss: 0.5891 - accuracy: 0.8769 - val_loss: 0.6690 - val_accuracy: 0.8308 - lr: 4.0960e-05\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 53ms/step - loss: 0.5774 - accuracy: 0.8962 - val_loss: 0.6606 - val_accuracy: 0.8462 - lr: 4.0960e-05\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5689 - accuracy: 0.8846 - val_loss: 0.6589 - val_accuracy: 0.8308 - lr: 4.0960e-05\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.5375 - accuracy: 0.8962 - val_loss: 0.6443 - val_accuracy: 0.8462 - lr: 3.2768e-05\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.5293 - accuracy: 0.8846 - val_loss: 0.6290 - val_accuracy: 0.8462 - lr: 3.2768e-05\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5219 - accuracy: 0.8962 - val_loss: 0.6113 - val_accuracy: 0.8615 - lr: 3.2768e-05\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.5132 - accuracy: 0.9000 - val_loss: 0.6017 - val_accuracy: 0.8615 - lr: 3.2768e-05\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.4931 - accuracy: 0.9077 - val_loss: 0.5940 - val_accuracy: 0.8308 - lr: 3.2768e-05\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4958 - accuracy: 0.8962 - val_loss: 0.5900 - val_accuracy: 0.8462 - lr: 3.2768e-05\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 55ms/step - loss: 0.4917 - accuracy: 0.9038 - val_loss: 0.5775 - val_accuracy: 0.8308 - lr: 3.2768e-05\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.4670 - accuracy: 0.9154 - val_loss: 0.5716 - val_accuracy: 0.8308 - lr: 3.2768e-05\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4547 - accuracy: 0.9000 - val_loss: 0.5675 - val_accuracy: 0.8308 - lr: 3.2768e-05\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.4626 - accuracy: 0.9038 - val_loss: 0.5538 - val_accuracy: 0.8154 - lr: 3.2768e-05\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4252 - accuracy: 0.9346 - val_loss: 0.5526 - val_accuracy: 0.8000 - lr: 2.6214e-05\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.4207 - accuracy: 0.9308 - val_loss: 0.5454 - val_accuracy: 0.8154 - lr: 2.6214e-05\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.4221 - accuracy: 0.9231 - val_loss: 0.5403 - val_accuracy: 0.8154 - lr: 2.6214e-05\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.4082 - accuracy: 0.9462 - val_loss: 0.5352 - val_accuracy: 0.8308 - lr: 2.6214e-05\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.3935 - accuracy: 0.9308 - val_loss: 0.5241 - val_accuracy: 0.8154 - lr: 2.6214e-05\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3970 - accuracy: 0.9346 - val_loss: 0.5236 - val_accuracy: 0.8308 - lr: 2.6214e-05\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3943 - accuracy: 0.9423 - val_loss: 0.5129 - val_accuracy: 0.8462 - lr: 2.6214e-05\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3895 - accuracy: 0.9231 - val_loss: 0.5049 - val_accuracy: 0.8462 - lr: 2.6214e-05\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.3842 - accuracy: 0.9231 - val_loss: 0.5025 - val_accuracy: 0.8462 - lr: 2.6214e-05\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.3768 - accuracy: 0.9231 - val_loss: 0.4915 - val_accuracy: 0.8615 - lr: 2.6214e-05\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3643 - accuracy: 0.9269 - val_loss: 0.4868 - val_accuracy: 0.8462 - lr: 2.0972e-05\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.3849 - accuracy: 0.9154 - val_loss: 0.4842 - val_accuracy: 0.8462 - lr: 2.0972e-05\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.3505 - accuracy: 0.9500 - val_loss: 0.4754 - val_accuracy: 0.8308 - lr: 2.0972e-05\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3669 - accuracy: 0.9385 - val_loss: 0.4735 - val_accuracy: 0.8308 - lr: 2.0972e-05\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.3537 - accuracy: 0.9385 - val_loss: 0.4689 - val_accuracy: 0.8462 - lr: 2.0972e-05\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3425 - accuracy: 0.9423 - val_loss: 0.4676 - val_accuracy: 0.8462 - lr: 2.0972e-05\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.3509 - accuracy: 0.9308 - val_loss: 0.4641 - val_accuracy: 0.8462 - lr: 2.0972e-05\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3506 - accuracy: 0.9308 - val_loss: 0.4593 - val_accuracy: 0.8462 - lr: 2.0972e-05\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.3415 - accuracy: 0.9346 - val_loss: 0.4649 - val_accuracy: 0.8308 - lr: 2.0972e-05\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3409 - accuracy: 0.9385 - val_loss: 0.4603 - val_accuracy: 0.8462 - lr: 2.0972e-05\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.3349 - accuracy: 0.9385 - val_loss: 0.4585 - val_accuracy: 0.8462 - lr: 1.6777e-05\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.3331 - accuracy: 0.9462 - val_loss: 0.4550 - val_accuracy: 0.8462 - lr: 1.6777e-05\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.3399 - accuracy: 0.9308 - val_loss: 0.4525 - val_accuracy: 0.8462 - lr: 1.6777e-05\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.3197 - accuracy: 0.9423 - val_loss: 0.4496 - val_accuracy: 0.8462 - lr: 1.6777e-05\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.3175 - accuracy: 0.9500 - val_loss: 0.4466 - val_accuracy: 0.8462 - lr: 1.6777e-05\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2936 - accuracy: 0.9692 - val_loss: 0.4422 - val_accuracy: 0.8462 - lr: 1.6777e-05\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3064 - accuracy: 0.9308 - val_loss: 0.4423 - val_accuracy: 0.8308 - lr: 1.6777e-05\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3063 - accuracy: 0.9538 - val_loss: 0.4381 - val_accuracy: 0.8308 - lr: 1.6777e-05\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2977 - accuracy: 0.9577 - val_loss: 0.4356 - val_accuracy: 0.8308 - lr: 1.6777e-05\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.3026 - accuracy: 0.9346 - val_loss: 0.4312 - val_accuracy: 0.8462 - lr: 1.6777e-05\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3132 - accuracy: 0.9423 - val_loss: 0.4290 - val_accuracy: 0.8462 - lr: 1.3422e-05\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.3049 - accuracy: 0.9385 - val_loss: 0.4281 - val_accuracy: 0.8615 - lr: 1.3422e-05\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3031 - accuracy: 0.9500 - val_loss: 0.4274 - val_accuracy: 0.8462 - lr: 1.3422e-05\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2844 - accuracy: 0.9577 - val_loss: 0.4256 - val_accuracy: 0.8462 - lr: 1.3422e-05\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.3057 - accuracy: 0.9500 - val_loss: 0.4255 - val_accuracy: 0.8462 - lr: 1.3422e-05\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.2756 - accuracy: 0.9462 - val_loss: 0.4297 - val_accuracy: 0.8462 - lr: 1.3422e-05\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2958 - accuracy: 0.9385 - val_loss: 0.4302 - val_accuracy: 0.8308 - lr: 1.3422e-05\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.2991 - accuracy: 0.9538 - val_loss: 0.4281 - val_accuracy: 0.8308 - lr: 1.3422e-05\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.2790 - accuracy: 0.9538 - val_loss: 0.4233 - val_accuracy: 0.8462 - lr: 1.3422e-05\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2761 - accuracy: 0.9538 - val_loss: 0.4195 - val_accuracy: 0.8462 - lr: 1.3422e-05\n",
      "3/3 [==============================] - 1s 7ms/step\n",
      "Test Accuracy: 0.8462\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed, Conv1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling1D\n",
    "\n",
    "X_train = np.nan_to_num(X_train, nan=0.0)\n",
    "X_test = np.nan_to_num(X_test, nan=0.0)\n",
    "y_train = np.nan_to_num(y_train, nan = 0.0)\n",
    "y_test = np.nan_to_num(y_test, nan = 0.0)\n",
    "# **获取数据形状**\n",
    "num_batches = X_train.shape[0]  # batch 维度\n",
    "num_windows = X_train.shape[1]  # 时间步（窗口数 59）\n",
    "num_features = X_train.shape[2]  # 特征数（15）\n",
    "num_channels = X_train.shape[3]  # 通道数（1）\n",
    "\n",
    "# **检测类别数量**\n",
    "unique_classes = np.unique(y_train)\n",
    "num_classes = len(unique_classes)  # 确保类别数正确\n",
    "\n",
    "print(f\"Corrected Classes: {num_classes}, Batches: {num_batches}, Windows: {num_windows}, Features: {num_features}, Channels: {num_channels}\")\n",
    "\n",
    "# **保持 X 形状**\n",
    "X_train = X_train.reshape(num_batches, num_windows, num_features, num_channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_windows, num_features, num_channels)\n",
    "X_train = X_train[:,:,:,:]\n",
    "X_test = X_test[:,:,:,:]\n",
    "\n",
    "# print(X_train.shape)\n",
    "\n",
    "num_features = X_train.shape[2] \n",
    "num_channels = X_train.shape[3]\n",
    "# **标签编码**\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)  # 转换成 0,1,2\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "# **转换为 One-Hot**\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")  # (batch, 59, 15, 1) (batch, 3)\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")  # (batch, 59, 15, 1) (batch, 3)\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], -1)  # (batch_size, 29, 40)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], -1)  \n",
    "\n",
    "# # print(num_features)\n",
    "# # **构建 LSTM 处理通道的模型**\n",
    "\n",
    "model = Sequential([\n",
    "    # TimeDistributed(Conv1D(filters=16, kernel_size=3, activation='relu'), input_shape=(num_windows, num_features, num_channels)),  \n",
    "    # TimeDistributed(GlobalAveragePooling1D()),  # 只对特征维度池化，不影响时间维度\n",
    "    LSTM(64, return_sequences=True),  # 保持时间序列结构\n",
    "    Dropout(0.2),\n",
    "    LSTM(128, return_sequences=False),  # 输出 2D (batch, 128)\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  # 最终分类\n",
    "])\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        return lr * 0.8  # 每 10 个 epoch，学习率减半\n",
    "    return lr\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),  # 初始学习率\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100, callbacks=[lr_callback], validation_data=(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# **保存模型**\n",
    "# model.save(\"rnn_emg_model.h5\")\n",
    "# print(\"Model saved as rnn_emg_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 8s 195ms/step - loss: 0.2855 - accuracy: 0.9346 - val_loss: 0.4091 - val_accuracy: 0.8769 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2628 - accuracy: 0.9538 - val_loss: 0.4019 - val_accuracy: 0.8615 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.2716 - accuracy: 0.9308 - val_loss: 0.3932 - val_accuracy: 0.8615 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2625 - accuracy: 0.9500 - val_loss: 0.3495 - val_accuracy: 0.9077 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.2716 - accuracy: 0.9231 - val_loss: 0.3516 - val_accuracy: 0.9231 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2487 - accuracy: 0.9500 - val_loss: 0.3167 - val_accuracy: 0.9231 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.2488 - accuracy: 0.9346 - val_loss: 0.3492 - val_accuracy: 0.9231 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.2357 - accuracy: 0.9423 - val_loss: 0.3485 - val_accuracy: 0.9077 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2339 - accuracy: 0.9500 - val_loss: 0.3488 - val_accuracy: 0.9077 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2298 - accuracy: 0.9154 - val_loss: 0.3480 - val_accuracy: 0.8769 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2265 - accuracy: 0.9500 - val_loss: 0.3660 - val_accuracy: 0.8769 - lr: 8.0000e-05\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2243 - accuracy: 0.9462 - val_loss: 0.3422 - val_accuracy: 0.8923 - lr: 8.0000e-05\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.2076 - accuracy: 0.9538 - val_loss: 0.3161 - val_accuracy: 0.9231 - lr: 8.0000e-05\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.2030 - accuracy: 0.9423 - val_loss: 0.3130 - val_accuracy: 0.8923 - lr: 8.0000e-05\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1830 - accuracy: 0.9538 - val_loss: 0.2891 - val_accuracy: 0.9077 - lr: 8.0000e-05\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1844 - accuracy: 0.9500 - val_loss: 0.2940 - val_accuracy: 0.9077 - lr: 8.0000e-05\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1728 - accuracy: 0.9731 - val_loss: 0.2817 - val_accuracy: 0.9231 - lr: 8.0000e-05\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1832 - accuracy: 0.9615 - val_loss: 0.2878 - val_accuracy: 0.9231 - lr: 8.0000e-05\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1862 - accuracy: 0.9538 - val_loss: 0.3061 - val_accuracy: 0.9231 - lr: 8.0000e-05\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1787 - accuracy: 0.9577 - val_loss: 0.3025 - val_accuracy: 0.9231 - lr: 8.0000e-05\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1734 - accuracy: 0.9654 - val_loss: 0.2940 - val_accuracy: 0.9231 - lr: 6.4000e-05\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1678 - accuracy: 0.9615 - val_loss: 0.2826 - val_accuracy: 0.9231 - lr: 6.4000e-05\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1674 - accuracy: 0.9577 - val_loss: 0.2861 - val_accuracy: 0.9077 - lr: 6.4000e-05\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1720 - accuracy: 0.9692 - val_loss: 0.2879 - val_accuracy: 0.9231 - lr: 6.4000e-05\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1648 - accuracy: 0.9654 - val_loss: 0.3044 - val_accuracy: 0.9231 - lr: 6.4000e-05\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1593 - accuracy: 0.9615 - val_loss: 0.2901 - val_accuracy: 0.9231 - lr: 6.4000e-05\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1739 - accuracy: 0.9500 - val_loss: 0.2810 - val_accuracy: 0.9231 - lr: 6.4000e-05\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1594 - accuracy: 0.9615 - val_loss: 0.2930 - val_accuracy: 0.9231 - lr: 6.4000e-05\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1541 - accuracy: 0.9731 - val_loss: 0.2767 - val_accuracy: 0.9231 - lr: 6.4000e-05\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1499 - accuracy: 0.9538 - val_loss: 0.2795 - val_accuracy: 0.9077 - lr: 6.4000e-05\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1471 - accuracy: 0.9577 - val_loss: 0.2874 - val_accuracy: 0.9077 - lr: 5.1200e-05\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1688 - accuracy: 0.9423 - val_loss: 0.2880 - val_accuracy: 0.9231 - lr: 5.1200e-05\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1378 - accuracy: 0.9654 - val_loss: 0.2863 - val_accuracy: 0.9231 - lr: 5.1200e-05\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1308 - accuracy: 0.9769 - val_loss: 0.2812 - val_accuracy: 0.9231 - lr: 5.1200e-05\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1310 - accuracy: 0.9692 - val_loss: 0.2772 - val_accuracy: 0.9231 - lr: 5.1200e-05\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.1428 - accuracy: 0.9577 - val_loss: 0.2846 - val_accuracy: 0.9231 - lr: 5.1200e-05\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.1414 - accuracy: 0.9615 - val_loss: 0.2965 - val_accuracy: 0.9231 - lr: 5.1200e-05\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.1445 - accuracy: 0.9615 - val_loss: 0.2835 - val_accuracy: 0.9231 - lr: 5.1200e-05\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1294 - accuracy: 0.9692 - val_loss: 0.2736 - val_accuracy: 0.9231 - lr: 5.1200e-05\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 0.1215 - accuracy: 0.9808 - val_loss: 0.2711 - val_accuracy: 0.9231 - lr: 5.1200e-05\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1184 - accuracy: 0.9808 - val_loss: 0.2652 - val_accuracy: 0.9231 - lr: 4.0960e-05\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.1260 - accuracy: 0.9731 - val_loss: 0.2683 - val_accuracy: 0.9231 - lr: 4.0960e-05\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1258 - accuracy: 0.9654 - val_loss: 0.2642 - val_accuracy: 0.9231 - lr: 4.0960e-05\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.1092 - accuracy: 0.9769 - val_loss: 0.2678 - val_accuracy: 0.9231 - lr: 4.0960e-05\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.1224 - accuracy: 0.9654 - val_loss: 0.2737 - val_accuracy: 0.9231 - lr: 4.0960e-05\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.1190 - accuracy: 0.9808 - val_loss: 0.2730 - val_accuracy: 0.9231 - lr: 4.0960e-05\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.1197 - accuracy: 0.9731 - val_loss: 0.2654 - val_accuracy: 0.9231 - lr: 4.0960e-05\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 0.1056 - accuracy: 0.9846 - val_loss: 0.2614 - val_accuracy: 0.9231 - lr: 4.0960e-05\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.1157 - accuracy: 0.9769 - val_loss: 0.2587 - val_accuracy: 0.9231 - lr: 4.0960e-05\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1071 - accuracy: 0.9731 - val_loss: 0.2592 - val_accuracy: 0.9231 - lr: 4.0960e-05\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1024 - accuracy: 0.9846 - val_loss: 0.2668 - val_accuracy: 0.9231 - lr: 3.2768e-05\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.1026 - accuracy: 0.9769 - val_loss: 0.2665 - val_accuracy: 0.9231 - lr: 3.2768e-05\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1071 - accuracy: 0.9731 - val_loss: 0.2645 - val_accuracy: 0.9231 - lr: 3.2768e-05\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1008 - accuracy: 0.9731 - val_loss: 0.2628 - val_accuracy: 0.9231 - lr: 3.2768e-05\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 36ms/step - loss: 0.1059 - accuracy: 0.9769 - val_loss: 0.2599 - val_accuracy: 0.9231 - lr: 3.2768e-05\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0967 - accuracy: 0.9846 - val_loss: 0.2584 - val_accuracy: 0.9231 - lr: 3.2768e-05\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.1136 - accuracy: 0.9654 - val_loss: 0.2641 - val_accuracy: 0.9231 - lr: 3.2768e-05\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0913 - accuracy: 0.9885 - val_loss: 0.2649 - val_accuracy: 0.9231 - lr: 3.2768e-05\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.0987 - accuracy: 0.9923 - val_loss: 0.2684 - val_accuracy: 0.9231 - lr: 3.2768e-05\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.0924 - accuracy: 0.9808 - val_loss: 0.2687 - val_accuracy: 0.9231 - lr: 3.2768e-05\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.1036 - accuracy: 0.9769 - val_loss: 0.2651 - val_accuracy: 0.9231 - lr: 2.6214e-05\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 0.1027 - accuracy: 0.9808 - val_loss: 0.2650 - val_accuracy: 0.9231 - lr: 2.6214e-05\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.1108 - accuracy: 0.9731 - val_loss: 0.2687 - val_accuracy: 0.9231 - lr: 2.6214e-05\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 0.1028 - accuracy: 0.9846 - val_loss: 0.2700 - val_accuracy: 0.9231 - lr: 2.6214e-05\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 0.0964 - accuracy: 0.9808 - val_loss: 0.2715 - val_accuracy: 0.9231 - lr: 2.6214e-05\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0965 - accuracy: 0.9769 - val_loss: 0.2699 - val_accuracy: 0.9231 - lr: 2.6214e-05\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 35ms/step - loss: 0.0978 - accuracy: 0.9769 - val_loss: 0.2690 - val_accuracy: 0.9231 - lr: 2.6214e-05\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0996 - accuracy: 0.9769 - val_loss: 0.2669 - val_accuracy: 0.9231 - lr: 2.6214e-05\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.0869 - accuracy: 0.9885 - val_loss: 0.2652 - val_accuracy: 0.9231 - lr: 2.6214e-05\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0838 - accuracy: 0.9808 - val_loss: 0.2662 - val_accuracy: 0.9231 - lr: 2.6214e-05\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 37ms/step - loss: 0.0823 - accuracy: 0.9885 - val_loss: 0.2651 - val_accuracy: 0.9231 - lr: 2.0972e-05\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0866 - accuracy: 0.9846 - val_loss: 0.2642 - val_accuracy: 0.9231 - lr: 2.0972e-05\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0812 - accuracy: 0.9846 - val_loss: 0.2661 - val_accuracy: 0.9231 - lr: 2.0972e-05\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 54ms/step - loss: 0.0951 - accuracy: 0.9808 - val_loss: 0.2658 - val_accuracy: 0.9231 - lr: 2.0972e-05\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 40ms/step - loss: 0.1067 - accuracy: 0.9731 - val_loss: 0.2606 - val_accuracy: 0.9231 - lr: 2.0972e-05\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0889 - accuracy: 0.9846 - val_loss: 0.2608 - val_accuracy: 0.9231 - lr: 2.0972e-05\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0780 - accuracy: 0.9885 - val_loss: 0.2612 - val_accuracy: 0.9231 - lr: 2.0972e-05\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0817 - accuracy: 0.9885 - val_loss: 0.2628 - val_accuracy: 0.9231 - lr: 2.0972e-05\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.0872 - accuracy: 0.9885 - val_loss: 0.2633 - val_accuracy: 0.9231 - lr: 2.0972e-05\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0761 - accuracy: 0.9885 - val_loss: 0.2642 - val_accuracy: 0.9231 - lr: 2.0972e-05\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 46ms/step - loss: 0.0742 - accuracy: 0.9923 - val_loss: 0.2637 - val_accuracy: 0.9231 - lr: 1.6777e-05\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0968 - accuracy: 0.9654 - val_loss: 0.2656 - val_accuracy: 0.9231 - lr: 1.6777e-05\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0973 - accuracy: 0.9731 - val_loss: 0.2681 - val_accuracy: 0.9231 - lr: 1.6777e-05\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 47ms/step - loss: 0.0824 - accuracy: 0.9769 - val_loss: 0.2683 - val_accuracy: 0.9231 - lr: 1.6777e-05\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0860 - accuracy: 0.9808 - val_loss: 0.2685 - val_accuracy: 0.9231 - lr: 1.6777e-05\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0852 - accuracy: 0.9769 - val_loss: 0.2701 - val_accuracy: 0.9231 - lr: 1.6777e-05\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0846 - accuracy: 0.9769 - val_loss: 0.2710 - val_accuracy: 0.9231 - lr: 1.6777e-05\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0750 - accuracy: 0.9923 - val_loss: 0.2710 - val_accuracy: 0.9231 - lr: 1.6777e-05\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 56ms/step - loss: 0.0882 - accuracy: 0.9808 - val_loss: 0.2725 - val_accuracy: 0.9231 - lr: 1.6777e-05\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 50ms/step - loss: 0.0869 - accuracy: 0.9885 - val_loss: 0.2731 - val_accuracy: 0.9231 - lr: 1.6777e-05\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0713 - accuracy: 0.9808 - val_loss: 0.2697 - val_accuracy: 0.9231 - lr: 1.3422e-05\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.0761 - accuracy: 0.9769 - val_loss: 0.2679 - val_accuracy: 0.9231 - lr: 1.3422e-05\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 42ms/step - loss: 0.0821 - accuracy: 0.9769 - val_loss: 0.2660 - val_accuracy: 0.9231 - lr: 1.3422e-05\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 48ms/step - loss: 0.0849 - accuracy: 0.9846 - val_loss: 0.2675 - val_accuracy: 0.9231 - lr: 1.3422e-05\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0741 - accuracy: 0.9923 - val_loss: 0.2659 - val_accuracy: 0.9231 - lr: 1.3422e-05\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 45ms/step - loss: 0.0723 - accuracy: 0.9885 - val_loss: 0.2641 - val_accuracy: 0.9231 - lr: 1.3422e-05\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 43ms/step - loss: 0.0857 - accuracy: 0.9769 - val_loss: 0.2641 - val_accuracy: 0.9231 - lr: 1.3422e-05\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 0.0765 - accuracy: 0.9846 - val_loss: 0.2637 - val_accuracy: 0.9231 - lr: 1.3422e-05\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 0.0826 - accuracy: 0.9808 - val_loss: 0.2657 - val_accuracy: 0.9231 - lr: 1.3422e-05\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 0.0824 - accuracy: 0.9846 - val_loss: 0.2632 - val_accuracy: 0.9231 - lr: 1.3422e-05\n",
      "3/3 [==============================] - 1s 10ms/step\n",
      "Test Accuracy: 0.9231\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        return lr * 0.8  # 每 10 个 epoch，学习率减半\n",
    "    return lr\n",
    "\n",
    "# **编译模型**\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),  # 初始学习率\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# **使用回调函数**\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# **训练时加上 callback**\n",
    "history = model.fit(X_train, y_train, epochs=100, callbacks=[lr_callback], validation_data=(X_test, y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# **计算准确率**\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "\n",
    "# 可视化\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=encoder.classes_, yticklabels=encoder.classes_)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# history graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.20 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2403de98e458f1581c3ddc5cac98c8c9b462b82dd05a074a785d43eb5bf629fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
