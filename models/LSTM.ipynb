{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features from E:\\MSC\\Spring\\AML\\GestureLink\\data\\FZH\\processed_data\\feature_matrix.npy, shape: (390, 8, 15, 10)\n",
      "Loaded labels from E:\\MSC\\Spring\\AML\\GestureLink\\data\\FZH\\processed_data\\labels.npy, shape: (390,)\n",
      "Training set: X_train: (312, 8, 15, 10), y_train: (312,)\n",
      "Testing set: X_test: (78, 8, 15, 10), y_test: (78,)\n",
      "Loaded features from E:\\MSC\\Spring\\AML\\GestureLink\\data\\WXR\\processed_data\\feature_matrix.npy, shape: (390, 8, 15, 10)\n",
      "Loaded labels from E:\\MSC\\Spring\\AML\\GestureLink\\data\\WXR\\processed_data\\labels.npy, shape: (390,)\n",
      "Training set: X_train: (312, 8, 15, 10), y_train: (312,)\n",
      "Testing set: X_test: (78, 8, 15, 10), y_test: (78,)\n",
      "Training set: X_train: (624, 8, 15, 10), y_train: (624,)\n",
      "Testing set: X_test: (156, 8, 15, 10), y_test: (156,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(data_folder, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    加载 `feature_matrix.npy` 和 `labels.npy` 数据，并划分训练集和测试集。\n",
    "\n",
    "    参数：\n",
    "    - data_folder: 存放数据的文件夹路径\n",
    "    - test_size: 测试集比例 (默认 20%)\n",
    "    - random_state: 随机种子，保证可复现性\n",
    "\n",
    "    返回：\n",
    "    - X_train: 训练集特征，形状 (train_batches, num_windows, 15, num_channels)\n",
    "    - X_test: 测试集特征，形状 (test_batches, num_windows, 15, num_channels)\n",
    "    - y_train: 训练集标签，形状 (train_batches,)\n",
    "    - y_test: 测试集标签，形状 (test_batches,)\n",
    "    \"\"\"\n",
    "    # **加载数据**\n",
    "    feature_path = os.path.join(data_folder, \"feature_matrix.npy\")\n",
    "    label_path = os.path.join(data_folder, \"labels.npy\")\n",
    "\n",
    "    if not os.path.exists(feature_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"特征文件或标签文件未找到，请检查路径！\")\n",
    "\n",
    "    X = np.load(feature_path)  # 形状 (num_batches, num_windows, 15, num_channels)\n",
    "    y = np.load(label_path)  # 形状 (num_batches,)\n",
    "\n",
    "    # **数据基本信息**\n",
    "    print(f\"Loaded features from {feature_path}, shape: {X.shape}\")\n",
    "    print(f\"Loaded labels from {label_path}, shape: {y.shape}\")\n",
    "\n",
    "    # **划分训练集和测试集**\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=random_state\n",
    "        )\n",
    "\n",
    "    # **打印数据划分信息**\n",
    "    print(f\"Training set: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"Testing set: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "data_folder = r\"E:\\MSC\\Spring\\AML\\GestureLink\\data\\FZH\\processed_data\"\n",
    "X_train, X_test, y_train, y_test = load_data(data_folder)\n",
    "\n",
    "# # **使用示例**\n",
    "# data_folder = r\"E:\\MSC\\Spring\\AML\\GestureLink\\data\\GZA\\windowed_data\"\n",
    "# X_train_g, X_test_g, y_train_g, y_test_g = load_data(data_folder)\n",
    "\n",
    "data_folder = r\"E:\\MSC\\Spring\\AML\\GestureLink\\data\\WXR\\processed_data\"\n",
    "X_train_W, X_test_W, y_train_W, y_test_W = load_data(data_folder)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.concatenate([X_train,X_train_W], axis=0)\n",
    "X_test = np.concatenate([X_test,X_test_W], axis=0)\n",
    "y_train = np.concatenate([y_train,y_train_W], axis=0)\n",
    "y_test = np.concatenate([y_test,y_test_W], axis=0)\n",
    "\n",
    "print(f\"Training set: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Testing set: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features from E:\\MSC\\Spring\\AML\\GestureLink\\windowed_data\\feature_matrix.npy, shape: (30, 59, 15, 7)\n",
      "Loaded labels from E:\\MSC\\Spring\\AML\\GestureLink\\windowed_data\\labels.npy, shape: (30,)\n",
      "Training set: X_train: (24, 59, 15, 7), y_train: (24,)\n",
      "Testing set: X_test: (6, 59, 15, 7), y_test: (6,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(data_folder, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    加载 `feature_matrix.npy` 和 `labels.npy` 数据，并划分训练集和测试集。\n",
    "\n",
    "    参数：\n",
    "    - data_folder: 存放数据的文件夹路径\n",
    "    - test_size: 测试集比例 (默认 20%)\n",
    "    - random_state: 随机种子，保证可复现性\n",
    "\n",
    "    返回：\n",
    "    - X_train: 训练集特征，形状 (train_batches, num_windows, 15, num_channels)\n",
    "    - X_test: 测试集特征，形状 (test_batches, num_windows, 15, num_channels)\n",
    "    - y_train: 训练集标签，形状 (train_batches,)\n",
    "    - y_test: 测试集标签，形状 (test_batches,)\n",
    "    \"\"\"\n",
    "    # **加载数据**\n",
    "    feature_path = os.path.join(data_folder, \"feature_matrix.npy\")\n",
    "    label_path = os.path.join(data_folder, \"labels.npy\")\n",
    "\n",
    "    if not os.path.exists(feature_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"特征文件或标签文件未找到，请检查路径！\")\n",
    "\n",
    "    X = np.load(feature_path)  # 形状 (num_batches, num_windows, 15, num_channels)\n",
    "    y = np.load(label_path)  # 形状 (num_batches,)\n",
    "\n",
    "    # **数据基本信息**\n",
    "    print(f\"Loaded features from {feature_path}, shape: {X.shape}\")\n",
    "    print(f\"Loaded labels from {label_path}, shape: {y.shape}\")\n",
    "\n",
    "    # **划分训练集和测试集**\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=random_state\n",
    "        )\n",
    "\n",
    "    # **打印数据划分信息**\n",
    "    print(f\"Training set: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"Testing set: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# data_folder = r\"E:\\MSC\\Spring\\AML\\GestureLink\\data\\WXR\\processed_data\"\n",
    "data_folder = r\"E:\\MSC\\Spring\\AML\\GestureLink\\windowed_data\"\n",
    "X_train, X_test, y_train, y_test = load_data(data_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features from E:\\MSC\\Spring\\AML\\GestureLink\\data\\WXR\\processed_data\\feature_matrix.npy, shape: (390, 8, 200, 10)\n",
      "Loaded labels from E:\\MSC\\Spring\\AML\\GestureLink\\data\\WXR\\processed_data\\labels.npy, shape: (390,)\n",
      "Train set: X_train shape: (120, 8, 200, 10), y_train shape: (120,)\n",
      "Test set: X_test shape: (30, 8, 200, 10), y_test shape: (30,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_and_split_data(data_folder, selected_labels=[1, 2, 3], test_size=0.2, random_state=12):\n",
    "    \"\"\"\n",
    "    加载 `feature_matrix.npy` 和 `labels.npy` 数据，筛选标签为指定类别的数据，并划分训练集和测试集。\n",
    "\n",
    "    参数：\n",
    "    - data_folder: 存放数据的文件夹路径\n",
    "    - selected_labels: 需要提取的标签列表\n",
    "    - test_size: 测试集比例（默认 20%）\n",
    "    - random_state: 随机种子，保证可复现\n",
    "\n",
    "    返回：\n",
    "    - X_train, X_test: 训练和测试集的特征数据\n",
    "    - y_train, y_test: 训练和测试集的标签数据\n",
    "    \"\"\"\n",
    "    # **加载数据**\n",
    "    feature_path = os.path.join(data_folder, \"feature_matrix.npy\")\n",
    "    label_path = os.path.join(data_folder, \"labels.npy\")\n",
    "\n",
    "    if not os.path.exists(feature_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"特征文件或标签文件未找到，请检查路径！\")\n",
    "\n",
    "    X = np.load(feature_path)  # 形状 (num_batches, num_windows, 15, num_channels)\n",
    "    y = np.load(label_path)  # 形状 (num_batches,)\n",
    "\n",
    "    # **数据基本信息**\n",
    "    print(f\"Loaded features from {feature_path}, shape: {X.shape}\")\n",
    "    print(f\"Loaded labels from {label_path}, shape: {y.shape}\")\n",
    "\n",
    "    # **筛选出指定标签的数据**\n",
    "    mask = np.isin(y, selected_labels)  # 创建布尔掩码\n",
    "    X_filtered = X[mask]  # 选取符合标签的 X\n",
    "    y_filtered = y[mask]  # 选取符合标签的 y\n",
    "\n",
    "    # **划分训练集和测试集**\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_filtered, y_filtered, test_size=test_size, random_state=random_state, stratify=y_filtered\n",
    "    )\n",
    "\n",
    "    # **打印划分后数据的信息**\n",
    "    print(f\"Train set: X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"Test set: X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# **使用示例**\n",
    "data_folder = r\"E:\\MSC\\Spring\\AML\\GestureLink\\data\\WXR\\processed_data\"\n",
    "X_train, X_test, y_train, y_test = load_and_split_data(data_folder, selected_labels=[1,2,5,6,8,9,11,13,16,26])\n",
    "# X_train, X_test, y_train, y_test = load_and_split_data(data_folder, selected_labels=[1,2,6,8,9,11,13,16,26])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features from E:\\MSC\\Spring\\AML\\GestureLink\\data\\FZH\\processed_data\\feature_matrix.npy, shape: (390, 8, 200, 10)\n",
      "Loaded labels from E:\\MSC\\Spring\\AML\\GestureLink\\data\\FZH\\processed_data\\labels.npy, shape: (390,)\n",
      "Train set: X_train shape: (120, 8, 200, 10), y_train shape: (120,)\n",
      "Test set: X_test shape: (30, 8, 200, 10), y_test shape: (30,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_and_split_data(data_folder, selected_labels=[1, 2, 3], test_size=0.2, random_state=12):\n",
    "    \"\"\"\n",
    "    加载 `feature_matrix.npy` 和 `labels.npy` 数据，筛选标签为指定类别的数据，并划分训练集和测试集。\n",
    "\n",
    "    参数：\n",
    "    - data_folder: 存放数据的文件夹路径\n",
    "    - selected_labels: 需要提取的标签列表\n",
    "    - test_size: 测试集比例（默认 20%）\n",
    "    - random_state: 随机种子，保证可复现\n",
    "\n",
    "    返回：\n",
    "    - X_train, X_test: 训练和测试集的特征数据\n",
    "    - y_train, y_test: 训练和测试集的标签数据\n",
    "    \"\"\"\n",
    "    # **加载数据**\n",
    "    feature_path = os.path.join(data_folder, \"feature_matrix.npy\")\n",
    "    label_path = os.path.join(data_folder, \"labels.npy\")\n",
    "\n",
    "    if not os.path.exists(feature_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"特征文件或标签文件未找到，请检查路径！\")\n",
    "\n",
    "    X = np.load(feature_path)  # 形状 (num_batches, num_windows, 15, num_channels)\n",
    "    y = np.load(label_path)  # 形状 (num_batches,)\n",
    "\n",
    "    # **数据基本信息**\n",
    "    print(f\"Loaded features from {feature_path}, shape: {X.shape}\")\n",
    "    print(f\"Loaded labels from {label_path}, shape: {y.shape}\")\n",
    "\n",
    "    # **筛选出指定标签的数据**\n",
    "    mask = np.isin(y, selected_labels)  # 创建布尔掩码\n",
    "    X_filtered = X[mask]  # 选取符合标签的 X\n",
    "    y_filtered = y[mask]  # 选取符合标签的 y\n",
    "\n",
    "    # **划分训练集和测试集**\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_filtered, y_filtered, test_size=test_size, random_state=random_state, stratify=y_filtered\n",
    "    )\n",
    "\n",
    "    # **打印划分后数据的信息**\n",
    "    print(f\"Train set: X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"Test set: X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# **使用示例**\n",
    "data_folder = r\"E:\\MSC\\Spring\\AML\\GestureLink\\data\\FZH\\processed_data\"\n",
    "X_train_f, X_test_f, y_train_f, y_test_f = load_and_split_data(data_folder, selected_labels=[1,2,5,6,8,9,11,13,16,26])\n",
    "# X_train_f, X_test_f, y_train_f, y_test_f = load_and_split_data(data_folder, selected_labels=[1,2,6,8,9,11,13,16,26])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features from E:\\MSC\\Spring\\AML\\GestureLink\\data\\GZA\\processed_data\\feature_matrix.npy, shape: (390, 8, 200, 10)\n",
      "Loaded labels from E:\\MSC\\Spring\\AML\\GestureLink\\data\\GZA\\processed_data\\labels.npy, shape: (390,)\n",
      "Train set: X_train shape: (120, 8, 200, 10), y_train shape: (120,)\n",
      "Test set: X_test shape: (30, 8, 200, 10), y_test shape: (30,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_and_split_data(data_folder, selected_labels=[1, 2, 3], test_size=0.2, random_state=12):\n",
    "    \"\"\"\n",
    "    加载 `feature_matrix.npy` 和 `labels.npy` 数据，筛选标签为指定类别的数据，并划分训练集和测试集。\n",
    "\n",
    "    参数：\n",
    "    - data_folder: 存放数据的文件夹路径\n",
    "    - selected_labels: 需要提取的标签列表\n",
    "    - test_size: 测试集比例（默认 20%）\n",
    "    - random_state: 随机种子，保证可复现\n",
    "\n",
    "    返回：\n",
    "    - X_train, X_test: 训练和测试集的特征数据\n",
    "    - y_train, y_test: 训练和测试集的标签数据\n",
    "    \"\"\"\n",
    "    # **加载数据**\n",
    "    feature_path = os.path.join(data_folder, \"feature_matrix.npy\")\n",
    "    label_path = os.path.join(data_folder, \"labels.npy\")\n",
    "\n",
    "    if not os.path.exists(feature_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"特征文件或标签文件未找到，请检查路径！\")\n",
    "\n",
    "    X = np.load(feature_path)  # 形状 (num_batches, num_windows, 15, num_channels)\n",
    "    y = np.load(label_path)  # 形状 (num_batches,)\n",
    "\n",
    "    # **数据基本信息**\n",
    "    print(f\"Loaded features from {feature_path}, shape: {X.shape}\")\n",
    "    print(f\"Loaded labels from {label_path}, shape: {y.shape}\")\n",
    "\n",
    "    # **筛选出指定标签的数据**\n",
    "    mask = np.isin(y, selected_labels)  # 创建布尔掩码\n",
    "    X_filtered = X[mask]  # 选取符合标签的 X\n",
    "    y_filtered = y[mask]  # 选取符合标签的 y\n",
    "\n",
    "    # **划分训练集和测试集**\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_filtered, y_filtered, test_size=test_size, random_state=random_state, stratify=y_filtered\n",
    "    )\n",
    "\n",
    "    # **打印划分后数据的信息**\n",
    "    print(f\"Train set: X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"Test set: X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# **使用示例**\n",
    "data_folder = r\"E:\\MSC\\Spring\\AML\\GestureLink\\data\\GZA\\processed_data\"\n",
    "X_train_g, X_test_g, y_train_g, y_test_g = load_and_split_data(data_folder, selected_labels=[1,2,5,6,8,9,11,13,16,26])\n",
    "# X_train, X_test, y_train, y_test = load_and_split_data(data_folder, selected_labels=[1,2,6,8,9,11,13,16,26])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: X_train: (360, 8, 200, 10), y_train: (360,)\n",
      "Testing set: X_test: (180, 8, 200, 10), y_test: (180,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate([X_train,X_train_f,X_train_g], axis=0)\n",
    "X_test = np.concatenate([X_test,X_test_f,X_train_g], axis=0)\n",
    "y_train = np.concatenate([y_train,y_train_f,y_train_g], axis=0)\n",
    "y_test = np.concatenate([y_test,y_test_f,y_train_g], axis=0)\n",
    "\n",
    "print(f\"Training set: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"Testing set: X_test: {X_test.shape}, y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 测试集准确率: 0.44\n",
      "分类报告:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.56      0.32        18\n",
      "           1       0.32      0.44      0.37        18\n",
      "           2       0.38      0.33      0.35        18\n",
      "           3       0.56      0.56      0.56        18\n",
      "           4       0.95      1.00      0.97        18\n",
      "           5       0.67      0.11      0.19        18\n",
      "           6       0.31      0.28      0.29        18\n",
      "           7       0.67      0.33      0.44        18\n",
      "           8       0.48      0.78      0.60        18\n",
      "           9       1.00      0.06      0.11        18\n",
      "\n",
      "    accuracy                           0.44       180\n",
      "   macro avg       0.56      0.44      0.42       180\n",
      "weighted avg       0.56      0.44      0.42       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)  # 转换成 0,1,2\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "X_train = np.nan_to_num(X_train, nan=0.0)\n",
    "X_test = np.nan_to_num(X_test, nan=0.0)\n",
    "y_train = np.nan_to_num(y_train, nan = 0.0)\n",
    "y_test = np.nan_to_num(y_test, nan = 0.0)\n",
    "X_train = X_train[:,:,:,:]\n",
    "X_test = X_test[:,:,:,:]\n",
    "# **KNN 训练**\n",
    "knn = KNeighborsClassifier(n_neighbors=4)  # k=5\n",
    "X_train_flatten = X_train.reshape(X_train.shape[0], -1)  # (batch, 15*10)\n",
    "X_test_flatten = X_test.reshape(X_test.shape[0], -1)  # (batch, 15*10)\n",
    "\n",
    "knn.fit(X_train_flatten, y_train)\n",
    "\n",
    "# **KNN 预测**\n",
    "y_pred = knn.predict(X_test_flatten)\n",
    "\n",
    "# **评估**\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"KNN 测试集准确率: {accuracy:.2f}\")\n",
    "\n",
    "# **打印分类报告**\n",
    "print(\"分类报告:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrected Classes: 10, Batches: 360, Windows: 8, Features: 200, Channels: 10\n",
      "X_train shape: (360, 8, 200, 10), y_train shape: (360, 10)\n",
      "X_test shape: (180, 8, 200, 10), y_test shape: (180, 10)\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 8s 130ms/step - loss: 2.2388 - accuracy: 0.2444 - val_loss: 2.1709 - val_accuracy: 0.2556 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 2.1228 - accuracy: 0.3333 - val_loss: 2.0893 - val_accuracy: 0.3111 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 2.0305 - accuracy: 0.3750 - val_loss: 2.0121 - val_accuracy: 0.3278 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 1.9462 - accuracy: 0.3778 - val_loss: 1.9377 - val_accuracy: 0.3556 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.8586 - accuracy: 0.4111 - val_loss: 1.8631 - val_accuracy: 0.3833 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.7746 - accuracy: 0.4667 - val_loss: 1.7879 - val_accuracy: 0.4611 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 1.6956 - accuracy: 0.5111 - val_loss: 1.7100 - val_accuracy: 0.5111 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 1.6093 - accuracy: 0.5639 - val_loss: 1.6424 - val_accuracy: 0.5278 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 1.5448 - accuracy: 0.5694 - val_loss: 1.5762 - val_accuracy: 0.5389 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 1.4743 - accuracy: 0.5889 - val_loss: 1.5116 - val_accuracy: 0.5833 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 1.4077 - accuracy: 0.6472 - val_loss: 1.4630 - val_accuracy: 0.6056 - lr: 8.0000e-05\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 1.3544 - accuracy: 0.6889 - val_loss: 1.4147 - val_accuracy: 0.6167 - lr: 8.0000e-05\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 1.3050 - accuracy: 0.6944 - val_loss: 1.3692 - val_accuracy: 0.6222 - lr: 8.0000e-05\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.2482 - accuracy: 0.7056 - val_loss: 1.3212 - val_accuracy: 0.6556 - lr: 8.0000e-05\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 1.1920 - accuracy: 0.7583 - val_loss: 1.2743 - val_accuracy: 0.6944 - lr: 8.0000e-05\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 1.1261 - accuracy: 0.7750 - val_loss: 1.2202 - val_accuracy: 0.6833 - lr: 8.0000e-05\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 1.0634 - accuracy: 0.7972 - val_loss: 1.1616 - val_accuracy: 0.7000 - lr: 8.0000e-05\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.9757 - accuracy: 0.8194 - val_loss: 1.1142 - val_accuracy: 0.7111 - lr: 8.0000e-05\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.9079 - accuracy: 0.8222 - val_loss: 1.0699 - val_accuracy: 0.7278 - lr: 8.0000e-05\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.8188 - accuracy: 0.8611 - val_loss: 1.0135 - val_accuracy: 0.7444 - lr: 8.0000e-05\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.7370 - accuracy: 0.9083 - val_loss: 0.9770 - val_accuracy: 0.7500 - lr: 6.4000e-05\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.6795 - accuracy: 0.9028 - val_loss: 0.9397 - val_accuracy: 0.7667 - lr: 6.4000e-05\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.6095 - accuracy: 0.9056 - val_loss: 0.9093 - val_accuracy: 0.7500 - lr: 6.4000e-05\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.5496 - accuracy: 0.9389 - val_loss: 0.8828 - val_accuracy: 0.7611 - lr: 6.4000e-05\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.4918 - accuracy: 0.9444 - val_loss: 0.8506 - val_accuracy: 0.7833 - lr: 6.4000e-05\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.4314 - accuracy: 0.9583 - val_loss: 0.8292 - val_accuracy: 0.7944 - lr: 6.4000e-05\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.3840 - accuracy: 0.9611 - val_loss: 0.8167 - val_accuracy: 0.8056 - lr: 6.4000e-05\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.3377 - accuracy: 0.9806 - val_loss: 0.7952 - val_accuracy: 0.7944 - lr: 6.4000e-05\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.2973 - accuracy: 0.9722 - val_loss: 0.7834 - val_accuracy: 0.8000 - lr: 6.4000e-05\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.2592 - accuracy: 0.9861 - val_loss: 0.7851 - val_accuracy: 0.8000 - lr: 6.4000e-05\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.2338 - accuracy: 0.9861 - val_loss: 0.7876 - val_accuracy: 0.8056 - lr: 5.1200e-05\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.2117 - accuracy: 0.9861 - val_loss: 0.7800 - val_accuracy: 0.8056 - lr: 5.1200e-05\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.1915 - accuracy: 0.9889 - val_loss: 0.7662 - val_accuracy: 0.8000 - lr: 5.1200e-05\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.1789 - accuracy: 0.9861 - val_loss: 0.7595 - val_accuracy: 0.7944 - lr: 5.1200e-05\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.1641 - accuracy: 0.9833 - val_loss: 0.7629 - val_accuracy: 0.8000 - lr: 5.1200e-05\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.1446 - accuracy: 0.9889 - val_loss: 0.7581 - val_accuracy: 0.7889 - lr: 5.1200e-05\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.1377 - accuracy: 0.9889 - val_loss: 0.7578 - val_accuracy: 0.7889 - lr: 5.1200e-05\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.1238 - accuracy: 0.9889 - val_loss: 0.7594 - val_accuracy: 0.8056 - lr: 5.1200e-05\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.1148 - accuracy: 0.9917 - val_loss: 0.7504 - val_accuracy: 0.7833 - lr: 5.1200e-05\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.1101 - accuracy: 0.9889 - val_loss: 0.7531 - val_accuracy: 0.7833 - lr: 5.1200e-05\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0995 - accuracy: 0.9917 - val_loss: 0.7585 - val_accuracy: 0.7889 - lr: 4.0960e-05\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0905 - accuracy: 0.9944 - val_loss: 0.7601 - val_accuracy: 0.7889 - lr: 4.0960e-05\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0934 - accuracy: 0.9917 - val_loss: 0.7590 - val_accuracy: 0.7944 - lr: 4.0960e-05\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0846 - accuracy: 0.9917 - val_loss: 0.7706 - val_accuracy: 0.7889 - lr: 4.0960e-05\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0833 - accuracy: 0.9889 - val_loss: 0.7735 - val_accuracy: 0.7889 - lr: 4.0960e-05\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0781 - accuracy: 0.9861 - val_loss: 0.7738 - val_accuracy: 0.7889 - lr: 4.0960e-05\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.0815 - accuracy: 0.9917 - val_loss: 0.7769 - val_accuracy: 0.7944 - lr: 4.0960e-05\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0713 - accuracy: 0.9917 - val_loss: 0.7823 - val_accuracy: 0.7833 - lr: 4.0960e-05\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0696 - accuracy: 0.9917 - val_loss: 0.7871 - val_accuracy: 0.7833 - lr: 4.0960e-05\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.0662 - accuracy: 0.9917 - val_loss: 0.7887 - val_accuracy: 0.7944 - lr: 4.0960e-05\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.0655 - accuracy: 0.9861 - val_loss: 0.7885 - val_accuracy: 0.7833 - lr: 3.2768e-05\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.0616 - accuracy: 0.9889 - val_loss: 0.7855 - val_accuracy: 0.7833 - lr: 3.2768e-05\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.0596 - accuracy: 0.9944 - val_loss: 0.7879 - val_accuracy: 0.7833 - lr: 3.2768e-05\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.0604 - accuracy: 0.9889 - val_loss: 0.7880 - val_accuracy: 0.7833 - lr: 3.2768e-05\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.0561 - accuracy: 0.9917 - val_loss: 0.7996 - val_accuracy: 0.7778 - lr: 3.2768e-05\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.0565 - accuracy: 0.9917 - val_loss: 0.7939 - val_accuracy: 0.7833 - lr: 3.2768e-05\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.0524 - accuracy: 0.9917 - val_loss: 0.7911 - val_accuracy: 0.7833 - lr: 3.2768e-05\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0525 - accuracy: 0.9917 - val_loss: 0.7921 - val_accuracy: 0.7889 - lr: 3.2768e-05\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.0496 - accuracy: 0.9861 - val_loss: 0.7957 - val_accuracy: 0.7833 - lr: 3.2768e-05\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.0550 - accuracy: 0.9917 - val_loss: 0.8150 - val_accuracy: 0.7833 - lr: 3.2768e-05\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0528 - accuracy: 0.9917 - val_loss: 0.8093 - val_accuracy: 0.7833 - lr: 2.6214e-05\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.0485 - accuracy: 0.9889 - val_loss: 0.8041 - val_accuracy: 0.7833 - lr: 2.6214e-05\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0501 - accuracy: 0.9889 - val_loss: 0.8005 - val_accuracy: 0.7833 - lr: 2.6214e-05\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0470 - accuracy: 0.9917 - val_loss: 0.7979 - val_accuracy: 0.7833 - lr: 2.6214e-05\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.0417 - accuracy: 0.9944 - val_loss: 0.8057 - val_accuracy: 0.7833 - lr: 2.6214e-05\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 0.0475 - accuracy: 0.9944 - val_loss: 0.8090 - val_accuracy: 0.7833 - lr: 2.6214e-05\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.0419 - accuracy: 0.9944 - val_loss: 0.8078 - val_accuracy: 0.7833 - lr: 2.6214e-05\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0436 - accuracy: 0.9861 - val_loss: 0.8053 - val_accuracy: 0.7833 - lr: 2.6214e-05\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0455 - accuracy: 0.9889 - val_loss: 0.8027 - val_accuracy: 0.7833 - lr: 2.6214e-05\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0419 - accuracy: 0.9917 - val_loss: 0.8050 - val_accuracy: 0.7778 - lr: 2.6214e-05\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.0408 - accuracy: 0.9917 - val_loss: 0.8058 - val_accuracy: 0.7778 - lr: 2.0972e-05\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.0370 - accuracy: 0.9944 - val_loss: 0.8063 - val_accuracy: 0.7833 - lr: 2.0972e-05\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.0399 - accuracy: 0.9861 - val_loss: 0.8064 - val_accuracy: 0.7833 - lr: 2.0972e-05\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0408 - accuracy: 0.9917 - val_loss: 0.8089 - val_accuracy: 0.7833 - lr: 2.0972e-05\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.0391 - accuracy: 0.9917 - val_loss: 0.8106 - val_accuracy: 0.7833 - lr: 2.0972e-05\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0448 - accuracy: 0.9861 - val_loss: 0.8127 - val_accuracy: 0.7833 - lr: 2.0972e-05\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.0362 - accuracy: 0.9944 - val_loss: 0.8128 - val_accuracy: 0.7833 - lr: 2.0972e-05\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0371 - accuracy: 0.9861 - val_loss: 0.8111 - val_accuracy: 0.7833 - lr: 2.0972e-05\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0384 - accuracy: 0.9861 - val_loss: 0.8109 - val_accuracy: 0.7833 - lr: 2.0972e-05\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0371 - accuracy: 0.9944 - val_loss: 0.8114 - val_accuracy: 0.7833 - lr: 2.0972e-05\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.0361 - accuracy: 0.9889 - val_loss: 0.8125 - val_accuracy: 0.7833 - lr: 1.6777e-05\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.0371 - accuracy: 0.9917 - val_loss: 0.8128 - val_accuracy: 0.7778 - lr: 1.6777e-05\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0341 - accuracy: 0.9917 - val_loss: 0.8130 - val_accuracy: 0.7889 - lr: 1.6777e-05\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0339 - accuracy: 0.9917 - val_loss: 0.8116 - val_accuracy: 0.7889 - lr: 1.6777e-05\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 0.0355 - accuracy: 0.9917 - val_loss: 0.8118 - val_accuracy: 0.7833 - lr: 1.6777e-05\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.0336 - accuracy: 0.9917 - val_loss: 0.8117 - val_accuracy: 0.7778 - lr: 1.6777e-05\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.0314 - accuracy: 0.9972 - val_loss: 0.8124 - val_accuracy: 0.7833 - lr: 1.6777e-05\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.0328 - accuracy: 0.9889 - val_loss: 0.8143 - val_accuracy: 0.7833 - lr: 1.6777e-05\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.0308 - accuracy: 0.9972 - val_loss: 0.8149 - val_accuracy: 0.7778 - lr: 1.6777e-05\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0342 - accuracy: 0.9889 - val_loss: 0.8162 - val_accuracy: 0.7833 - lr: 1.6777e-05\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.0313 - accuracy: 0.9944 - val_loss: 0.8161 - val_accuracy: 0.7833 - lr: 1.3422e-05\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.0335 - accuracy: 0.9861 - val_loss: 0.8193 - val_accuracy: 0.7833 - lr: 1.3422e-05\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 0.0366 - accuracy: 0.9889 - val_loss: 0.8199 - val_accuracy: 0.7833 - lr: 1.3422e-05\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0302 - accuracy: 0.9917 - val_loss: 0.8186 - val_accuracy: 0.7833 - lr: 1.3422e-05\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0304 - accuracy: 0.9889 - val_loss: 0.8185 - val_accuracy: 0.7833 - lr: 1.3422e-05\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.0317 - accuracy: 0.9861 - val_loss: 0.8159 - val_accuracy: 0.7833 - lr: 1.3422e-05\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0310 - accuracy: 0.9917 - val_loss: 0.8162 - val_accuracy: 0.7833 - lr: 1.3422e-05\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 1s 63ms/step - loss: 0.0346 - accuracy: 0.9861 - val_loss: 0.8198 - val_accuracy: 0.7778 - lr: 1.3422e-05\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.0281 - accuracy: 0.9944 - val_loss: 0.8220 - val_accuracy: 0.7778 - lr: 1.3422e-05\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0299 - accuracy: 0.9917 - val_loss: 0.8236 - val_accuracy: 0.7833 - lr: 1.3422e-05\n",
      "6/6 [==============================] - 1s 12ms/step\n",
      "Test Accuracy: 0.7833\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed, Conv1D, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling1D\n",
    "\n",
    "\n",
    "# **加载数据**\n",
    "data_folder = r\"E:\\MSC\\Spring\\AML\\GestureLink\\data\\G\\windowed_data\"\n",
    "# X_train, X_test, y_train, y_test = load_data(data_folder)\n",
    "# X_train, X_test, y_train, y_test = load_and_split_data(data_folder, selected_labels=[24, 25, 26])\n",
    "X_train = np.nan_to_num(X_train, nan=0.0)\n",
    "X_test = np.nan_to_num(X_test, nan=0.0)\n",
    "y_train = np.nan_to_num(y_train, nan = 0.0)\n",
    "y_test = np.nan_to_num(y_test, nan = 0.0)\n",
    "# **获取数据形状**\n",
    "num_batches = X_train.shape[0]  # batch 维度\n",
    "num_windows = X_train.shape[1]  # 时间步（窗口数 59）\n",
    "num_features = X_train.shape[2]  # 特征数（15）\n",
    "num_channels = X_train.shape[3]  # 通道数（1）\n",
    "\n",
    "# **检测类别数量**\n",
    "unique_classes = np.unique(y_train)\n",
    "num_classes = len(unique_classes)  # 确保类别数正确\n",
    "\n",
    "print(f\"Corrected Classes: {num_classes}, Batches: {num_batches}, Windows: {num_windows}, Features: {num_features}, Channels: {num_channels}\")\n",
    "\n",
    "# **保持 X 形状**\n",
    "X_train = X_train.reshape(num_batches, num_windows, num_features, num_channels)\n",
    "X_test = X_test.reshape(X_test.shape[0], num_windows, num_features, num_channels)\n",
    "X_train = X_train[:,:,:,:]\n",
    "X_test = X_test[:,:,:,:]\n",
    "\n",
    "# print(X_train.shape)\n",
    "\n",
    "num_features = X_train.shape[2] \n",
    "num_channels = X_train.shape[3]\n",
    "# **标签编码**\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)  # 转换成 0,1,2\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "# **转换为 One-Hot**\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")  # (batch, 59, 15, 1) (batch, 3)\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")  # (batch, 59, 15, 1) (batch, 3)\n",
    "\n",
    "\n",
    "# model = Sequential([\n",
    "#     TimeDistributed(Flatten(), input_shape=(num_windows, 15, 10)),  # 把 (4, 10) 展平成 40\n",
    "#     LSTM(64, return_sequences=True),\n",
    "#     Dropout(0.3),\n",
    "#     LSTM(32, return_sequences=False),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(32, activation='relu'),\n",
    "#     Dense(num_classes, activation='softmax')  # 多分类\n",
    "# ])\n",
    "\n",
    "# model = Sequential([\n",
    "#     Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(num_windows, num_features * num_channels)),\n",
    "#     BatchNormalization(),\n",
    "#     MaxPooling1D(pool_size=2),\n",
    "\n",
    "#     Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "#     BatchNormalization(),\n",
    "#     MaxPooling1D(pool_size=2),\n",
    "\n",
    "#     Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "#     BatchNormalization(),\n",
    "#     MaxPooling1D(pool_size=2),\n",
    "\n",
    "#     Flatten(),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dropout(0.3),\n",
    "#     Dense(num_classes, activation='softmax')  # 多分类输出\n",
    "# ])\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], -1)  # (batch_size, 29, 40)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], -1)  \n",
    "\n",
    "# # print(num_features)\n",
    "# # **构建 LSTM 处理通道的模型**\n",
    "\n",
    "model = Sequential([\n",
    "    # TimeDistributed(Conv1D(filters=16, kernel_size=3, activation='relu'), input_shape=(num_windows, num_features, num_channels)),  \n",
    "    # TimeDistributed(GlobalAveragePooling1D()),  # 只对特征维度池化，不影响时间维度\n",
    "    LSTM(64, return_sequences=True),  # 保持时间序列结构\n",
    "    Dropout(0.2),\n",
    "    LSTM(128, return_sequences=False),  # 输出 2D (batch, 128)\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  # 最终分类\n",
    "])\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        return lr * 0.8  # 每 10 个 epoch，学习率减半\n",
    "    return lr\n",
    "\n",
    "# **编译模型**\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),  # 初始学习率\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# **使用回调函数**\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# **训练时加上 callback**\n",
    "history = model.fit(X_train, y_train, epochs=100, callbacks=[lr_callback], validation_data=(X_test, y_test))\n",
    "\n",
    "# # **编译模型**\n",
    "# model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # **训练模型**\n",
    "# epochs = 40\n",
    "\n",
    "# batch_size = 4\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     validation_data=(X_test, y_test),\n",
    "#     epochs=epochs,\n",
    "#     batch_size=batch_size,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# **测试模型**\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# **计算准确率**\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# **保存模型**\n",
    "# model.save(\"rnn_emg_model.h5\")\n",
    "# print(\"Model saved as rnn_emg_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 6s 127ms/step - loss: 0.0481 - accuracy: 0.9917 - val_loss: 0.8194 - val_accuracy: 0.7889 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0315 - accuracy: 0.9917 - val_loss: 0.8397 - val_accuracy: 0.7889 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0264 - accuracy: 0.9944 - val_loss: 0.8493 - val_accuracy: 0.7944 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0339 - accuracy: 0.9861 - val_loss: 0.8521 - val_accuracy: 0.7889 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.0266 - accuracy: 0.9889 - val_loss: 0.8423 - val_accuracy: 0.7778 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.0223 - accuracy: 0.9889 - val_loss: 0.8673 - val_accuracy: 0.7889 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.0232 - accuracy: 0.9917 - val_loss: 0.8808 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0255 - accuracy: 0.9889 - val_loss: 0.8720 - val_accuracy: 0.7889 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.0215 - accuracy: 0.9889 - val_loss: 0.8719 - val_accuracy: 0.7833 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.0199 - accuracy: 0.9889 - val_loss: 0.8795 - val_accuracy: 0.7944 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.0208 - accuracy: 0.9917 - val_loss: 0.8818 - val_accuracy: 0.7833 - lr: 8.0000e-05\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.0220 - accuracy: 0.9889 - val_loss: 0.9000 - val_accuracy: 0.7833 - lr: 8.0000e-05\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0257 - accuracy: 0.9889 - val_loss: 0.9038 - val_accuracy: 0.7833 - lr: 8.0000e-05\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.0188 - accuracy: 0.9917 - val_loss: 0.9092 - val_accuracy: 0.7833 - lr: 8.0000e-05\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.0207 - accuracy: 0.9889 - val_loss: 0.9192 - val_accuracy: 0.7833 - lr: 8.0000e-05\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.0200 - accuracy: 0.9917 - val_loss: 0.9139 - val_accuracy: 0.7833 - lr: 8.0000e-05\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.0177 - accuracy: 0.9889 - val_loss: 0.9057 - val_accuracy: 0.7722 - lr: 8.0000e-05\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.0146 - accuracy: 0.9944 - val_loss: 0.9043 - val_accuracy: 0.7833 - lr: 8.0000e-05\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.0165 - accuracy: 0.9861 - val_loss: 0.8911 - val_accuracy: 0.7889 - lr: 8.0000e-05\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.0202 - accuracy: 0.9889 - val_loss: 0.8989 - val_accuracy: 0.7889 - lr: 8.0000e-05\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 1s 80ms/step - loss: 0.0207 - accuracy: 0.9861 - val_loss: 0.9210 - val_accuracy: 0.7833 - lr: 6.4000e-05\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.0162 - accuracy: 0.9917 - val_loss: 0.9248 - val_accuracy: 0.7833 - lr: 6.4000e-05\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0194 - accuracy: 0.9861 - val_loss: 0.9160 - val_accuracy: 0.7833 - lr: 6.4000e-05\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.0194 - accuracy: 0.9889 - val_loss: 0.9145 - val_accuracy: 0.7889 - lr: 6.4000e-05\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 1s 82ms/step - loss: 0.0174 - accuracy: 0.9917 - val_loss: 0.9126 - val_accuracy: 0.7833 - lr: 6.4000e-05\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.0219 - accuracy: 0.9917 - val_loss: 0.9138 - val_accuracy: 0.7833 - lr: 6.4000e-05\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0212 - accuracy: 0.9917 - val_loss: 0.9080 - val_accuracy: 0.7833 - lr: 6.4000e-05\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0161 - accuracy: 0.9917 - val_loss: 0.9085 - val_accuracy: 0.7889 - lr: 6.4000e-05\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.0166 - accuracy: 0.9917 - val_loss: 0.9119 - val_accuracy: 0.7722 - lr: 6.4000e-05\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.0201 - accuracy: 0.9889 - val_loss: 0.9103 - val_accuracy: 0.7778 - lr: 6.4000e-05\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 0.0164 - accuracy: 0.9917 - val_loss: 0.9161 - val_accuracy: 0.7833 - lr: 5.1200e-05\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 1s 79ms/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 0.9295 - val_accuracy: 0.7833 - lr: 5.1200e-05\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.0169 - accuracy: 0.9889 - val_loss: 0.9405 - val_accuracy: 0.7833 - lr: 5.1200e-05\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.0210 - accuracy: 0.9833 - val_loss: 0.9337 - val_accuracy: 0.7889 - lr: 5.1200e-05\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0166 - accuracy: 0.9889 - val_loss: 0.9351 - val_accuracy: 0.7833 - lr: 5.1200e-05\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.0163 - accuracy: 0.9861 - val_loss: 0.9348 - val_accuracy: 0.7778 - lr: 5.1200e-05\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.0175 - accuracy: 0.9889 - val_loss: 0.9376 - val_accuracy: 0.7833 - lr: 5.1200e-05\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0144 - accuracy: 0.9889 - val_loss: 0.9371 - val_accuracy: 0.7889 - lr: 5.1200e-05\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.9448 - val_accuracy: 0.7889 - lr: 5.1200e-05\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0163 - accuracy: 0.9889 - val_loss: 0.9437 - val_accuracy: 0.7833 - lr: 5.1200e-05\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.0159 - accuracy: 0.9889 - val_loss: 0.9426 - val_accuracy: 0.7833 - lr: 4.0960e-05\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.0179 - accuracy: 0.9917 - val_loss: 0.9367 - val_accuracy: 0.7833 - lr: 4.0960e-05\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.0154 - accuracy: 0.9917 - val_loss: 0.9311 - val_accuracy: 0.7722 - lr: 4.0960e-05\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0152 - accuracy: 0.9889 - val_loss: 0.9389 - val_accuracy: 0.7833 - lr: 4.0960e-05\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0153 - accuracy: 0.9917 - val_loss: 0.9456 - val_accuracy: 0.7833 - lr: 4.0960e-05\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.0154 - accuracy: 0.9861 - val_loss: 0.9497 - val_accuracy: 0.7833 - lr: 4.0960e-05\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.0151 - accuracy: 0.9889 - val_loss: 0.9523 - val_accuracy: 0.7833 - lr: 4.0960e-05\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0127 - accuracy: 0.9944 - val_loss: 0.9506 - val_accuracy: 0.7833 - lr: 4.0960e-05\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.0142 - accuracy: 0.9917 - val_loss: 0.9589 - val_accuracy: 0.7833 - lr: 4.0960e-05\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 0.0150 - accuracy: 0.9889 - val_loss: 0.9574 - val_accuracy: 0.7722 - lr: 4.0960e-05\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.0150 - accuracy: 0.9917 - val_loss: 0.9611 - val_accuracy: 0.7722 - lr: 3.2768e-05\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0151 - accuracy: 0.9889 - val_loss: 0.9569 - val_accuracy: 0.7778 - lr: 3.2768e-05\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.0157 - accuracy: 0.9861 - val_loss: 0.9564 - val_accuracy: 0.7778 - lr: 3.2768e-05\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0153 - accuracy: 0.9917 - val_loss: 0.9586 - val_accuracy: 0.7833 - lr: 3.2768e-05\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.0165 - accuracy: 0.9861 - val_loss: 0.9599 - val_accuracy: 0.7833 - lr: 3.2768e-05\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0151 - accuracy: 0.9889 - val_loss: 0.9530 - val_accuracy: 0.7833 - lr: 3.2768e-05\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.0149 - accuracy: 0.9917 - val_loss: 0.9543 - val_accuracy: 0.7833 - lr: 3.2768e-05\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 0.0158 - accuracy: 0.9889 - val_loss: 0.9539 - val_accuracy: 0.7778 - lr: 3.2768e-05\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.0137 - accuracy: 0.9889 - val_loss: 0.9548 - val_accuracy: 0.7778 - lr: 3.2768e-05\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0152 - accuracy: 0.9861 - val_loss: 0.9548 - val_accuracy: 0.7778 - lr: 3.2768e-05\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.0117 - accuracy: 0.9917 - val_loss: 0.9552 - val_accuracy: 0.7778 - lr: 2.6214e-05\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0140 - accuracy: 0.9917 - val_loss: 0.9600 - val_accuracy: 0.7778 - lr: 2.6214e-05\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.0163 - accuracy: 0.9917 - val_loss: 0.9608 - val_accuracy: 0.7889 - lr: 2.6214e-05\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.0148 - accuracy: 0.9889 - val_loss: 0.9605 - val_accuracy: 0.7889 - lr: 2.6214e-05\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0142 - accuracy: 0.9889 - val_loss: 0.9608 - val_accuracy: 0.7889 - lr: 2.6214e-05\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.0129 - accuracy: 0.9944 - val_loss: 0.9604 - val_accuracy: 0.7778 - lr: 2.6214e-05\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.0143 - accuracy: 0.9889 - val_loss: 0.9600 - val_accuracy: 0.7833 - lr: 2.6214e-05\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0129 - accuracy: 0.9944 - val_loss: 0.9626 - val_accuracy: 0.7778 - lr: 2.6214e-05\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.0152 - accuracy: 0.9833 - val_loss: 0.9644 - val_accuracy: 0.7778 - lr: 2.6214e-05\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 0.0150 - accuracy: 0.9861 - val_loss: 0.9677 - val_accuracy: 0.7778 - lr: 2.6214e-05\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0138 - accuracy: 0.9917 - val_loss: 0.9689 - val_accuracy: 0.7833 - lr: 2.0972e-05\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0141 - accuracy: 0.9917 - val_loss: 0.9677 - val_accuracy: 0.7833 - lr: 2.0972e-05\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.0129 - accuracy: 0.9944 - val_loss: 0.9668 - val_accuracy: 0.7778 - lr: 2.0972e-05\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.0146 - accuracy: 0.9889 - val_loss: 0.9662 - val_accuracy: 0.7778 - lr: 2.0972e-05\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0143 - accuracy: 0.9917 - val_loss: 0.9642 - val_accuracy: 0.7778 - lr: 2.0972e-05\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0141 - accuracy: 0.9889 - val_loss: 0.9635 - val_accuracy: 0.7833 - lr: 2.0972e-05\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0142 - accuracy: 0.9917 - val_loss: 0.9634 - val_accuracy: 0.7889 - lr: 2.0972e-05\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.0137 - accuracy: 0.9917 - val_loss: 0.9637 - val_accuracy: 0.7889 - lr: 2.0972e-05\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0142 - accuracy: 0.9889 - val_loss: 0.9645 - val_accuracy: 0.7889 - lr: 2.0972e-05\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0142 - accuracy: 0.9944 - val_loss: 0.9673 - val_accuracy: 0.7889 - lr: 2.0972e-05\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.0139 - accuracy: 0.9917 - val_loss: 0.9677 - val_accuracy: 0.7889 - lr: 1.6777e-05\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 1s 74ms/step - loss: 0.0161 - accuracy: 0.9889 - val_loss: 0.9665 - val_accuracy: 0.7889 - lr: 1.6777e-05\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0130 - accuracy: 0.9944 - val_loss: 0.9647 - val_accuracy: 0.7833 - lr: 1.6777e-05\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 0.0140 - accuracy: 0.9889 - val_loss: 0.9657 - val_accuracy: 0.7889 - lr: 1.6777e-05\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.0124 - accuracy: 0.9917 - val_loss: 0.9662 - val_accuracy: 0.7833 - lr: 1.6777e-05\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0148 - accuracy: 0.9889 - val_loss: 0.9671 - val_accuracy: 0.7833 - lr: 1.6777e-05\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0124 - accuracy: 0.9917 - val_loss: 0.9648 - val_accuracy: 0.7833 - lr: 1.6777e-05\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 1s 66ms/step - loss: 0.0128 - accuracy: 0.9917 - val_loss: 0.9638 - val_accuracy: 0.7833 - lr: 1.6777e-05\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0125 - accuracy: 0.9944 - val_loss: 0.9649 - val_accuracy: 0.7833 - lr: 1.6777e-05\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.0134 - accuracy: 0.9917 - val_loss: 0.9669 - val_accuracy: 0.7778 - lr: 1.6777e-05\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.0153 - accuracy: 0.9889 - val_loss: 0.9675 - val_accuracy: 0.7778 - lr: 1.3422e-05\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0127 - accuracy: 0.9917 - val_loss: 0.9679 - val_accuracy: 0.7722 - lr: 1.3422e-05\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.0145 - accuracy: 0.9889 - val_loss: 0.9685 - val_accuracy: 0.7722 - lr: 1.3422e-05\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 1s 73ms/step - loss: 0.0133 - accuracy: 0.9944 - val_loss: 0.9664 - val_accuracy: 0.7722 - lr: 1.3422e-05\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 1s 76ms/step - loss: 0.0125 - accuracy: 0.9944 - val_loss: 0.9698 - val_accuracy: 0.7722 - lr: 1.3422e-05\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 1s 70ms/step - loss: 0.0160 - accuracy: 0.9889 - val_loss: 0.9693 - val_accuracy: 0.7833 - lr: 1.3422e-05\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0154 - accuracy: 0.9861 - val_loss: 0.9692 - val_accuracy: 0.7833 - lr: 1.3422e-05\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.0140 - accuracy: 0.9917 - val_loss: 0.9678 - val_accuracy: 0.7833 - lr: 1.3422e-05\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.0158 - accuracy: 0.9861 - val_loss: 0.9672 - val_accuracy: 0.7833 - lr: 1.3422e-05\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.0128 - accuracy: 0.9972 - val_loss: 0.9673 - val_accuracy: 0.7833 - lr: 1.3422e-05\n",
      "6/6 [==============================] - 1s 15ms/step\n",
      "Test Accuracy: 0.7833\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        return lr * 0.8  # 每 10 个 epoch，学习率减半\n",
    "    return lr\n",
    "\n",
    "# **编译模型**\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),  # 初始学习率\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# **使用回调函数**\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# **训练时加上 callback**\n",
    "history = model.fit(X_train, y_train, epochs=100, callbacks=[lr_callback], validation_data=(X_test, y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# **计算准确率**\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 5s 98ms/step - loss: 3.4863 - accuracy: 0.1000 - val_loss: 2.2555 - val_accuracy: 0.1222 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 3.1074 - accuracy: 0.1083 - val_loss: 2.2045 - val_accuracy: 0.1889 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 2.9247 - accuracy: 0.1333 - val_loss: 2.1664 - val_accuracy: 0.2056 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 2.8091 - accuracy: 0.1361 - val_loss: 2.1315 - val_accuracy: 0.2389 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 2.6184 - accuracy: 0.1778 - val_loss: 2.0923 - val_accuracy: 0.2333 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 2.5244 - accuracy: 0.1722 - val_loss: 2.0632 - val_accuracy: 0.2444 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 2.4448 - accuracy: 0.2000 - val_loss: 2.0459 - val_accuracy: 0.2333 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 2.4416 - accuracy: 0.1778 - val_loss: 2.0201 - val_accuracy: 0.2944 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 2.3459 - accuracy: 0.1833 - val_loss: 1.9787 - val_accuracy: 0.3222 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 2.2788 - accuracy: 0.2278 - val_loss: 1.9472 - val_accuracy: 0.3333 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 2.1972 - accuracy: 0.2528 - val_loss: 1.9144 - val_accuracy: 0.3556 - lr: 9.0000e-05\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 2.2105 - accuracy: 0.2389 - val_loss: 1.8854 - val_accuracy: 0.3778 - lr: 9.0000e-05\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 2.1041 - accuracy: 0.2639 - val_loss: 1.8641 - val_accuracy: 0.4056 - lr: 9.0000e-05\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 2.1840 - accuracy: 0.2278 - val_loss: 1.8402 - val_accuracy: 0.4222 - lr: 9.0000e-05\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 2.1116 - accuracy: 0.2361 - val_loss: 1.8101 - val_accuracy: 0.4389 - lr: 9.0000e-05\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 2.0300 - accuracy: 0.3083 - val_loss: 1.7839 - val_accuracy: 0.4778 - lr: 9.0000e-05\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 2.0904 - accuracy: 0.2556 - val_loss: 1.7571 - val_accuracy: 0.5000 - lr: 9.0000e-05\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 2.0700 - accuracy: 0.2667 - val_loss: 1.7431 - val_accuracy: 0.4944 - lr: 9.0000e-05\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 1.9805 - accuracy: 0.2917 - val_loss: 1.7268 - val_accuracy: 0.4944 - lr: 9.0000e-05\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 1.9712 - accuracy: 0.2833 - val_loss: 1.7203 - val_accuracy: 0.5278 - lr: 9.0000e-05\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.9727 - accuracy: 0.3111 - val_loss: 1.7126 - val_accuracy: 0.4889 - lr: 8.1000e-05\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.9420 - accuracy: 0.3111 - val_loss: 1.7031 - val_accuracy: 0.4722 - lr: 8.1000e-05\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.8483 - accuracy: 0.3556 - val_loss: 1.6845 - val_accuracy: 0.4722 - lr: 8.1000e-05\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 1.9302 - accuracy: 0.3222 - val_loss: 1.6689 - val_accuracy: 0.5056 - lr: 8.1000e-05\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.9323 - accuracy: 0.3194 - val_loss: 1.6541 - val_accuracy: 0.5111 - lr: 8.1000e-05\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.8605 - accuracy: 0.3444 - val_loss: 1.6345 - val_accuracy: 0.5278 - lr: 8.1000e-05\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.8638 - accuracy: 0.3139 - val_loss: 1.6224 - val_accuracy: 0.5667 - lr: 8.1000e-05\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.8187 - accuracy: 0.3500 - val_loss: 1.6054 - val_accuracy: 0.5611 - lr: 8.1000e-05\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.8943 - accuracy: 0.3444 - val_loss: 1.5976 - val_accuracy: 0.5500 - lr: 8.1000e-05\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.7574 - accuracy: 0.3806 - val_loss: 1.5945 - val_accuracy: 0.5667 - lr: 8.1000e-05\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.7043 - accuracy: 0.3972 - val_loss: 1.5908 - val_accuracy: 0.5778 - lr: 7.2900e-05\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.7679 - accuracy: 0.3583 - val_loss: 1.5737 - val_accuracy: 0.5889 - lr: 7.2900e-05\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.8031 - accuracy: 0.3778 - val_loss: 1.5521 - val_accuracy: 0.5833 - lr: 7.2900e-05\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.7382 - accuracy: 0.3833 - val_loss: 1.5372 - val_accuracy: 0.6167 - lr: 7.2900e-05\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 1.6984 - accuracy: 0.4056 - val_loss: 1.5257 - val_accuracy: 0.6389 - lr: 7.2900e-05\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.7226 - accuracy: 0.3833 - val_loss: 1.5171 - val_accuracy: 0.6000 - lr: 7.2900e-05\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.7222 - accuracy: 0.3972 - val_loss: 1.5092 - val_accuracy: 0.5722 - lr: 7.2900e-05\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.6273 - accuracy: 0.4139 - val_loss: 1.4976 - val_accuracy: 0.5944 - lr: 7.2900e-05\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.7729 - accuracy: 0.3500 - val_loss: 1.4890 - val_accuracy: 0.5778 - lr: 7.2900e-05\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.7020 - accuracy: 0.3861 - val_loss: 1.4749 - val_accuracy: 0.6056 - lr: 7.2900e-05\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.7147 - accuracy: 0.4083 - val_loss: 1.4655 - val_accuracy: 0.6056 - lr: 6.5610e-05\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.6880 - accuracy: 0.3889 - val_loss: 1.4559 - val_accuracy: 0.6056 - lr: 6.5610e-05\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.6252 - accuracy: 0.4306 - val_loss: 1.4479 - val_accuracy: 0.6167 - lr: 6.5610e-05\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.6622 - accuracy: 0.3944 - val_loss: 1.4386 - val_accuracy: 0.6056 - lr: 6.5610e-05\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.6981 - accuracy: 0.3778 - val_loss: 1.4214 - val_accuracy: 0.6333 - lr: 6.5610e-05\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.6360 - accuracy: 0.4444 - val_loss: 1.4107 - val_accuracy: 0.6389 - lr: 6.5610e-05\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.5056 - accuracy: 0.4694 - val_loss: 1.3989 - val_accuracy: 0.6333 - lr: 6.5610e-05\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.5863 - accuracy: 0.4167 - val_loss: 1.3848 - val_accuracy: 0.6389 - lr: 6.5610e-05\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.5238 - accuracy: 0.4472 - val_loss: 1.3750 - val_accuracy: 0.6500 - lr: 6.5610e-05\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 1.4911 - accuracy: 0.4722 - val_loss: 1.3613 - val_accuracy: 0.6556 - lr: 6.5610e-05\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.5462 - accuracy: 0.4611 - val_loss: 1.3504 - val_accuracy: 0.6500 - lr: 5.9049e-05\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 1.5026 - accuracy: 0.4833 - val_loss: 1.3451 - val_accuracy: 0.6444 - lr: 5.9049e-05\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.4272 - accuracy: 0.5250 - val_loss: 1.3353 - val_accuracy: 0.6667 - lr: 5.9049e-05\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 1.5043 - accuracy: 0.4278 - val_loss: 1.3286 - val_accuracy: 0.6500 - lr: 5.9049e-05\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.4964 - accuracy: 0.4694 - val_loss: 1.3187 - val_accuracy: 0.6778 - lr: 5.9049e-05\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.5097 - accuracy: 0.4528 - val_loss: 1.3095 - val_accuracy: 0.6833 - lr: 5.9049e-05\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.5282 - accuracy: 0.4639 - val_loss: 1.3028 - val_accuracy: 0.6833 - lr: 5.9049e-05\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 1.4910 - accuracy: 0.4889 - val_loss: 1.2980 - val_accuracy: 0.6722 - lr: 5.9049e-05\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.4513 - accuracy: 0.4722 - val_loss: 1.2923 - val_accuracy: 0.6778 - lr: 5.9049e-05\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.4586 - accuracy: 0.5167 - val_loss: 1.2775 - val_accuracy: 0.6667 - lr: 5.9049e-05\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.5375 - accuracy: 0.4750 - val_loss: 1.2682 - val_accuracy: 0.6778 - lr: 5.3144e-05\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 1.5317 - accuracy: 0.4444 - val_loss: 1.2616 - val_accuracy: 0.6667 - lr: 5.3144e-05\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.3780 - accuracy: 0.5500 - val_loss: 1.2510 - val_accuracy: 0.6778 - lr: 5.3144e-05\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.4200 - accuracy: 0.4917 - val_loss: 1.2407 - val_accuracy: 0.7000 - lr: 5.3144e-05\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 1.4564 - accuracy: 0.5028 - val_loss: 1.2373 - val_accuracy: 0.7000 - lr: 5.3144e-05\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.3816 - accuracy: 0.5139 - val_loss: 1.2227 - val_accuracy: 0.7222 - lr: 5.3144e-05\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.3329 - accuracy: 0.5389 - val_loss: 1.2058 - val_accuracy: 0.7278 - lr: 5.3144e-05\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.4124 - accuracy: 0.5222 - val_loss: 1.1961 - val_accuracy: 0.7333 - lr: 5.3144e-05\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.3337 - accuracy: 0.5306 - val_loss: 1.1857 - val_accuracy: 0.7167 - lr: 5.3144e-05\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.3866 - accuracy: 0.5139 - val_loss: 1.1744 - val_accuracy: 0.7111 - lr: 5.3144e-05\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.3601 - accuracy: 0.5194 - val_loss: 1.1600 - val_accuracy: 0.7111 - lr: 4.7830e-05\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.3234 - accuracy: 0.5333 - val_loss: 1.1522 - val_accuracy: 0.7111 - lr: 4.7830e-05\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.4262 - accuracy: 0.4694 - val_loss: 1.1460 - val_accuracy: 0.7278 - lr: 4.7830e-05\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.3492 - accuracy: 0.5417 - val_loss: 1.1440 - val_accuracy: 0.7167 - lr: 4.7830e-05\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 1.2842 - accuracy: 0.5611 - val_loss: 1.1413 - val_accuracy: 0.7056 - lr: 4.7830e-05\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 1.2697 - accuracy: 0.5611 - val_loss: 1.1362 - val_accuracy: 0.7222 - lr: 4.7830e-05\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.3557 - accuracy: 0.5361 - val_loss: 1.1337 - val_accuracy: 0.7222 - lr: 4.7830e-05\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 43ms/step - loss: 1.2903 - accuracy: 0.5500 - val_loss: 1.1216 - val_accuracy: 0.7389 - lr: 4.7830e-05\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.3003 - accuracy: 0.5250 - val_loss: 1.1028 - val_accuracy: 0.7556 - lr: 4.7830e-05\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.2791 - accuracy: 0.5639 - val_loss: 1.0884 - val_accuracy: 0.7611 - lr: 4.7830e-05\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 1.3409 - accuracy: 0.5139 - val_loss: 1.0829 - val_accuracy: 0.7556 - lr: 4.3047e-05\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.2029 - accuracy: 0.5889 - val_loss: 1.0713 - val_accuracy: 0.7556 - lr: 4.3047e-05\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.2189 - accuracy: 0.5694 - val_loss: 1.0621 - val_accuracy: 0.7556 - lr: 4.3047e-05\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.2420 - accuracy: 0.5861 - val_loss: 1.0562 - val_accuracy: 0.7556 - lr: 4.3047e-05\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.1306 - accuracy: 0.6083 - val_loss: 1.0501 - val_accuracy: 0.7611 - lr: 4.3047e-05\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.2582 - accuracy: 0.5528 - val_loss: 1.0441 - val_accuracy: 0.7556 - lr: 4.3047e-05\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 1.1714 - accuracy: 0.6000 - val_loss: 1.0397 - val_accuracy: 0.7722 - lr: 4.3047e-05\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 1.2018 - accuracy: 0.5972 - val_loss: 1.0324 - val_accuracy: 0.7667 - lr: 4.3047e-05\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.1550 - accuracy: 0.6028 - val_loss: 1.0213 - val_accuracy: 0.7556 - lr: 4.3047e-05\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 1.2286 - accuracy: 0.5583 - val_loss: 1.0137 - val_accuracy: 0.7556 - lr: 4.3047e-05\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 1.1680 - accuracy: 0.5972 - val_loss: 1.0073 - val_accuracy: 0.7611 - lr: 3.8742e-05\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1244 - accuracy: 0.6194 - val_loss: 0.9944 - val_accuracy: 0.7667 - lr: 3.8742e-05\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1124 - accuracy: 0.6361 - val_loss: 0.9839 - val_accuracy: 0.7611 - lr: 3.8742e-05\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 1.1937 - accuracy: 0.5778 - val_loss: 0.9783 - val_accuracy: 0.7778 - lr: 3.8742e-05\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.1550 - accuracy: 0.5861 - val_loss: 0.9730 - val_accuracy: 0.7611 - lr: 3.8742e-05\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 43ms/step - loss: 1.1646 - accuracy: 0.6194 - val_loss: 0.9664 - val_accuracy: 0.7611 - lr: 3.8742e-05\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 1.1265 - accuracy: 0.5972 - val_loss: 0.9619 - val_accuracy: 0.7611 - lr: 3.8742e-05\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 35ms/step - loss: 1.0595 - accuracy: 0.6361 - val_loss: 0.9548 - val_accuracy: 0.7667 - lr: 3.8742e-05\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 1.0955 - accuracy: 0.6083 - val_loss: 0.9422 - val_accuracy: 0.7722 - lr: 3.8742e-05\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.9993 - accuracy: 0.6556 - val_loss: 0.9262 - val_accuracy: 0.7889 - lr: 3.8742e-05\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "Test Accuracy: 0.7889\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', input_shape=(num_windows, num_features * num_channels)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(num_classes, activation='softmax')  # 多分类输出\n",
    "])\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        return lr * 0.9  # 每 10 个 epoch，学习率减半\n",
    "    return lr\n",
    "\n",
    "# **编译模型**\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),  # 初始学习率\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# **使用回调函数**\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# **训练时加上 callback**\n",
    "history = model.fit(X_train, y_train, epochs=100, callbacks=[lr_callback], validation_data=(X_test, y_test))\n",
    "# # **编译模型**\n",
    "# model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # **训练模型**\n",
    "# epochs = 80\n",
    "\n",
    "# batch_size = 8\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     validation_data=(X_test, y_test),\n",
    "#     epochs=epochs,\n",
    "#     batch_size=batch_size,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# **测试模型**\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# **计算准确率**\n",
    "accuracy = accuracy_score(y_test_classes, y_pred_classes)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 107ms/step - loss: 1.0903 - accuracy: 0.6111 - val_loss: 0.9165 - val_accuracy: 0.7889 - lr: 3.8742e-05\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.0990 - accuracy: 0.6083 - val_loss: 0.9107 - val_accuracy: 0.7889 - lr: 3.8742e-05\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 0.9860 - accuracy: 0.6694 - val_loss: 0.9058 - val_accuracy: 0.7889 - lr: 3.8742e-05\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.0682 - accuracy: 0.6333 - val_loss: 0.9035 - val_accuracy: 0.7833 - lr: 3.8742e-05\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.0370 - accuracy: 0.6306 - val_loss: 0.8972 - val_accuracy: 0.7833 - lr: 3.8742e-05\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.9786 - accuracy: 0.7000 - val_loss: 0.8865 - val_accuracy: 0.7778 - lr: 3.8742e-05\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9963 - accuracy: 0.6722 - val_loss: 0.8801 - val_accuracy: 0.7833 - lr: 3.8742e-05\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.0001 - accuracy: 0.6750 - val_loss: 0.8698 - val_accuracy: 0.7778 - lr: 3.8742e-05\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 1.0188 - accuracy: 0.6389 - val_loss: 0.8658 - val_accuracy: 0.7889 - lr: 3.8742e-05\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 0.9660 - accuracy: 0.6806 - val_loss: 0.8636 - val_accuracy: 0.7889 - lr: 3.8742e-05\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.0678 - accuracy: 0.6472 - val_loss: 0.8600 - val_accuracy: 0.7778 - lr: 3.4868e-05\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 31ms/step - loss: 1.0040 - accuracy: 0.6500 - val_loss: 0.8557 - val_accuracy: 0.7778 - lr: 3.4868e-05\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 33ms/step - loss: 1.0252 - accuracy: 0.6583 - val_loss: 0.8520 - val_accuracy: 0.7778 - lr: 3.4868e-05\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.9811 - accuracy: 0.6833 - val_loss: 0.8432 - val_accuracy: 0.7944 - lr: 3.4868e-05\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.9892 - accuracy: 0.6500 - val_loss: 0.8374 - val_accuracy: 0.7944 - lr: 3.4868e-05\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 0.9112 - accuracy: 0.6944 - val_loss: 0.8328 - val_accuracy: 0.7944 - lr: 3.4868e-05\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 28ms/step - loss: 1.0401 - accuracy: 0.6222 - val_loss: 0.8285 - val_accuracy: 0.7889 - lr: 3.4868e-05\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 30ms/step - loss: 1.0103 - accuracy: 0.6833 - val_loss: 0.8237 - val_accuracy: 0.8000 - lr: 3.4868e-05\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 32ms/step - loss: 0.9704 - accuracy: 0.6833 - val_loss: 0.8174 - val_accuracy: 0.7889 - lr: 3.4868e-05\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 36ms/step - loss: 0.8288 - accuracy: 0.7194 - val_loss: 0.8130 - val_accuracy: 0.7833 - lr: 3.4868e-05\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.9498 - accuracy: 0.6833 - val_loss: 0.8070 - val_accuracy: 0.7889 - lr: 3.1381e-05\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.9515 - accuracy: 0.6778 - val_loss: 0.8050 - val_accuracy: 0.7833 - lr: 3.1381e-05\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.9609 - accuracy: 0.6722 - val_loss: 0.8004 - val_accuracy: 0.7833 - lr: 3.1381e-05\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.8888 - accuracy: 0.6861 - val_loss: 0.7957 - val_accuracy: 0.7833 - lr: 3.1381e-05\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.8553 - accuracy: 0.7250 - val_loss: 0.7925 - val_accuracy: 0.7778 - lr: 3.1381e-05\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.9196 - accuracy: 0.6750 - val_loss: 0.7878 - val_accuracy: 0.8000 - lr: 3.1381e-05\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.8508 - accuracy: 0.7111 - val_loss: 0.7859 - val_accuracy: 0.7889 - lr: 3.1381e-05\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.8953 - accuracy: 0.6861 - val_loss: 0.7718 - val_accuracy: 0.7833 - lr: 3.1381e-05\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.8494 - accuracy: 0.7222 - val_loss: 0.7636 - val_accuracy: 0.7778 - lr: 3.1381e-05\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.8982 - accuracy: 0.6778 - val_loss: 0.7637 - val_accuracy: 0.7778 - lr: 3.1381e-05\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.8429 - accuracy: 0.7167 - val_loss: 0.7593 - val_accuracy: 0.7833 - lr: 2.8243e-05\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.8326 - accuracy: 0.7139 - val_loss: 0.7544 - val_accuracy: 0.7833 - lr: 2.8243e-05\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.8796 - accuracy: 0.6778 - val_loss: 0.7519 - val_accuracy: 0.7889 - lr: 2.8243e-05\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.8555 - accuracy: 0.7028 - val_loss: 0.7485 - val_accuracy: 0.7944 - lr: 2.8243e-05\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.8527 - accuracy: 0.7028 - val_loss: 0.7409 - val_accuracy: 0.7889 - lr: 2.8243e-05\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.8248 - accuracy: 0.7333 - val_loss: 0.7401 - val_accuracy: 0.7833 - lr: 2.8243e-05\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 43ms/step - loss: 0.8473 - accuracy: 0.7111 - val_loss: 0.7381 - val_accuracy: 0.7944 - lr: 2.8243e-05\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.8519 - accuracy: 0.7278 - val_loss: 0.7346 - val_accuracy: 0.7944 - lr: 2.8243e-05\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.8381 - accuracy: 0.7333 - val_loss: 0.7285 - val_accuracy: 0.7944 - lr: 2.8243e-05\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.8451 - accuracy: 0.7139 - val_loss: 0.7270 - val_accuracy: 0.7833 - lr: 2.8243e-05\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.8264 - accuracy: 0.7000 - val_loss: 0.7324 - val_accuracy: 0.7889 - lr: 2.5419e-05\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.8062 - accuracy: 0.7556 - val_loss: 0.7325 - val_accuracy: 0.7833 - lr: 2.5419e-05\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.7913 - accuracy: 0.7056 - val_loss: 0.7269 - val_accuracy: 0.7778 - lr: 2.5419e-05\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.7784 - accuracy: 0.7528 - val_loss: 0.7210 - val_accuracy: 0.7722 - lr: 2.5419e-05\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.7334 - accuracy: 0.7556 - val_loss: 0.7122 - val_accuracy: 0.7944 - lr: 2.5419e-05\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.6731 - accuracy: 0.7889 - val_loss: 0.7054 - val_accuracy: 0.7833 - lr: 2.5419e-05\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.7358 - accuracy: 0.7611 - val_loss: 0.7018 - val_accuracy: 0.7889 - lr: 2.5419e-05\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.6928 - accuracy: 0.7528 - val_loss: 0.7029 - val_accuracy: 0.7778 - lr: 2.5419e-05\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.8061 - accuracy: 0.7056 - val_loss: 0.7022 - val_accuracy: 0.7778 - lr: 2.5419e-05\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.7598 - accuracy: 0.7278 - val_loss: 0.6988 - val_accuracy: 0.7833 - lr: 2.5419e-05\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.7141 - accuracy: 0.7472 - val_loss: 0.6952 - val_accuracy: 0.7778 - lr: 2.2877e-05\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.7101 - accuracy: 0.7694 - val_loss: 0.6880 - val_accuracy: 0.7833 - lr: 2.2877e-05\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.7688 - accuracy: 0.7722 - val_loss: 0.6847 - val_accuracy: 0.7944 - lr: 2.2877e-05\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.7120 - accuracy: 0.7667 - val_loss: 0.6791 - val_accuracy: 0.7889 - lr: 2.2877e-05\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.6796 - accuracy: 0.7889 - val_loss: 0.6769 - val_accuracy: 0.7889 - lr: 2.2877e-05\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.7456 - accuracy: 0.7278 - val_loss: 0.6757 - val_accuracy: 0.7889 - lr: 2.2877e-05\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.6787 - accuracy: 0.7722 - val_loss: 0.6758 - val_accuracy: 0.7889 - lr: 2.2877e-05\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.6779 - accuracy: 0.7833 - val_loss: 0.6721 - val_accuracy: 0.7889 - lr: 2.2877e-05\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.7075 - accuracy: 0.7639 - val_loss: 0.6680 - val_accuracy: 0.7889 - lr: 2.2877e-05\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.7854 - accuracy: 0.7111 - val_loss: 0.6672 - val_accuracy: 0.7889 - lr: 2.2877e-05\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.6301 - accuracy: 0.7972 - val_loss: 0.6635 - val_accuracy: 0.7944 - lr: 2.0589e-05\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.6802 - accuracy: 0.7778 - val_loss: 0.6621 - val_accuracy: 0.7944 - lr: 2.0589e-05\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.6362 - accuracy: 0.7833 - val_loss: 0.6620 - val_accuracy: 0.7944 - lr: 2.0589e-05\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.7531 - accuracy: 0.7278 - val_loss: 0.6617 - val_accuracy: 0.7944 - lr: 2.0589e-05\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 43ms/step - loss: 0.6254 - accuracy: 0.8083 - val_loss: 0.6642 - val_accuracy: 0.7944 - lr: 2.0589e-05\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.6400 - accuracy: 0.7861 - val_loss: 0.6648 - val_accuracy: 0.7944 - lr: 2.0589e-05\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.7039 - accuracy: 0.7639 - val_loss: 0.6638 - val_accuracy: 0.8000 - lr: 2.0589e-05\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.7263 - accuracy: 0.7472 - val_loss: 0.6664 - val_accuracy: 0.8000 - lr: 2.0589e-05\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.7151 - accuracy: 0.7500 - val_loss: 0.6713 - val_accuracy: 0.8056 - lr: 2.0589e-05\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.6763 - accuracy: 0.7694 - val_loss: 0.6735 - val_accuracy: 0.7944 - lr: 2.0589e-05\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.6310 - accuracy: 0.8000 - val_loss: 0.6710 - val_accuracy: 0.8000 - lr: 1.8530e-05\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.6683 - accuracy: 0.7639 - val_loss: 0.6700 - val_accuracy: 0.8056 - lr: 1.8530e-05\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.6368 - accuracy: 0.7722 - val_loss: 0.6701 - val_accuracy: 0.7944 - lr: 1.8530e-05\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 43ms/step - loss: 0.6611 - accuracy: 0.7861 - val_loss: 0.6636 - val_accuracy: 0.8056 - lr: 1.8530e-05\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.6892 - accuracy: 0.7583 - val_loss: 0.6558 - val_accuracy: 0.8000 - lr: 1.8530e-05\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.5848 - accuracy: 0.8222 - val_loss: 0.6532 - val_accuracy: 0.8000 - lr: 1.8530e-05\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.6655 - accuracy: 0.7528 - val_loss: 0.6579 - val_accuracy: 0.7944 - lr: 1.8530e-05\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.6161 - accuracy: 0.8028 - val_loss: 0.6570 - val_accuracy: 0.7889 - lr: 1.8530e-05\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.6753 - accuracy: 0.7417 - val_loss: 0.6530 - val_accuracy: 0.7944 - lr: 1.8530e-05\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.5936 - accuracy: 0.8056 - val_loss: 0.6511 - val_accuracy: 0.7944 - lr: 1.8530e-05\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.6279 - accuracy: 0.8000 - val_loss: 0.6474 - val_accuracy: 0.7889 - lr: 1.6677e-05\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.6483 - accuracy: 0.7722 - val_loss: 0.6422 - val_accuracy: 0.7889 - lr: 1.6677e-05\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.5756 - accuracy: 0.8417 - val_loss: 0.6448 - val_accuracy: 0.7889 - lr: 1.6677e-05\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.6405 - accuracy: 0.7972 - val_loss: 0.6450 - val_accuracy: 0.7944 - lr: 1.6677e-05\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.5905 - accuracy: 0.8000 - val_loss: 0.6400 - val_accuracy: 0.7889 - lr: 1.6677e-05\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.6673 - accuracy: 0.7806 - val_loss: 0.6365 - val_accuracy: 0.7889 - lr: 1.6677e-05\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.6440 - accuracy: 0.7667 - val_loss: 0.6372 - val_accuracy: 0.7889 - lr: 1.6677e-05\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.5526 - accuracy: 0.8306 - val_loss: 0.6383 - val_accuracy: 0.7889 - lr: 1.6677e-05\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.5528 - accuracy: 0.8389 - val_loss: 0.6368 - val_accuracy: 0.7889 - lr: 1.6677e-05\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.6166 - accuracy: 0.7917 - val_loss: 0.6385 - val_accuracy: 0.7889 - lr: 1.6677e-05\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.5767 - accuracy: 0.8306 - val_loss: 0.6407 - val_accuracy: 0.7889 - lr: 1.5009e-05\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.6278 - accuracy: 0.7861 - val_loss: 0.6423 - val_accuracy: 0.7833 - lr: 1.5009e-05\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 39ms/step - loss: 0.5113 - accuracy: 0.8361 - val_loss: 0.6417 - val_accuracy: 0.7833 - lr: 1.5009e-05\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 41ms/step - loss: 0.5351 - accuracy: 0.8361 - val_loss: 0.6401 - val_accuracy: 0.7833 - lr: 1.5009e-05\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.5581 - accuracy: 0.8250 - val_loss: 0.6355 - val_accuracy: 0.7833 - lr: 1.5009e-05\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.5806 - accuracy: 0.8056 - val_loss: 0.6339 - val_accuracy: 0.7889 - lr: 1.5009e-05\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 42ms/step - loss: 0.5972 - accuracy: 0.7944 - val_loss: 0.6323 - val_accuracy: 0.7889 - lr: 1.5009e-05\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 38ms/step - loss: 0.6343 - accuracy: 0.7806 - val_loss: 0.6340 - val_accuracy: 0.7889 - lr: 1.5009e-05\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 37ms/step - loss: 0.5632 - accuracy: 0.8083 - val_loss: 0.6360 - val_accuracy: 0.7889 - lr: 1.5009e-05\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 40ms/step - loss: 0.5956 - accuracy: 0.7972 - val_loss: 0.6346 - val_accuracy: 0.7889 - lr: 1.5009e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, callbacks=[lr_callback], validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 26)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train.shape\n",
    "y_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.20 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2403de98e458f1581c3ddc5cac98c8c9b462b82dd05a074a785d43eb5bf629fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
