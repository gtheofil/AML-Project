{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIBSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features from E:\\MSC\\Spring\\AML\\GestureLink\\data\\G\\windowed_data\\feature_matrix.npy, shape: (390, 49, 15, 10)\n",
      "Loaded labels from E:\\MSC\\Spring\\AML\\GestureLink\\data\\G\\windowed_data\\labels.npy, shape: (390,)\n",
      "Training set: X_train: (312, 7350), y_train: (312,)\n",
      "Testing set: X_test: (78, 7350), y_test: (78,)\n",
      "Accuracy = 8.97436% (7/78) (classification)\n",
      "测试集准确率: 8.97%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from libsvm.svmutil import *\n",
    "\n",
    "def load_data(data_folder, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    加载 `feature_matrix.npy` 和 `labels.npy` 数据，并划分训练集和测试集。\n",
    "\n",
    "    参数：\n",
    "    - data_folder: 存放数据的文件夹路径\n",
    "    - test_size: 测试集比例 (默认 20%)\n",
    "    - random_state: 随机种子，保证可复现性\n",
    "\n",
    "    返回：\n",
    "    - X_train: 训练集特征，形状 (train_samples, num_features)\n",
    "    - X_test: 测试集特征，形状 (test_samples, num_features)\n",
    "    - y_train: 训练集标签，形状 (train_samples,)\n",
    "    - y_test: 测试集标签，形状 (test_samples,)\n",
    "    \"\"\"\n",
    "    feature_path = os.path.join(data_folder, \"feature_matrix.npy\")\n",
    "    label_path = os.path.join(data_folder, \"labels.npy\")\n",
    "\n",
    "    if not os.path.exists(feature_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"特征文件或标签文件未找到，请检查路径！\")\n",
    "\n",
    "    X = np.load(feature_path)  # 形状 (num_batches, num_windows, 15, num_channels)\n",
    "    y = np.load(label_path)  # 形状 (num_batches,)\n",
    "\n",
    "    print(f\"Loaded features from {feature_path}, shape: {X.shape}\")\n",
    "    print(f\"Loaded labels from {label_path}, shape: {y.shape}\")\n",
    "\n",
    "    # **展平数据 (num_batches, num_windows, 15, num_channels) -> (num_batches, num_windows * 15 * num_channels)**\n",
    "    num_batches, num_windows, height, num_channels = X.shape\n",
    "    X = X.reshape(num_batches, -1)  # 变成 (num_batches, num_windows * 15 * num_channels)\n",
    "\n",
    "    # **划分训练集和测试集**\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    print(f\"Training set: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"Testing set: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# **数据路径**\n",
    "data_folder = r\"E:\\MSC\\Spring\\AML\\GestureLink\\data\\G\\windowed_data\"\n",
    "X_train, X_test, y_train, y_test = load_data(data_folder)\n",
    "\n",
    "# **转换数据格式，适应 LIBSVM**\n",
    "X_train_list = [dict(enumerate(x, 1)) for x in X_train]  # 将 NumPy 数组转换为 LIBSVM 格式的字典列表\n",
    "X_test_list = [dict(enumerate(x, 1)) for x in X_test]  # 同样转换测试集\n",
    "\n",
    "# **训练 SVM 模型**\n",
    "svm_model = svm_train(y_train.tolist(), X_train_list, '-s 0 -t 2 -c 1')  # -s 0: C-SVC, -t 2: RBF 核, -c 1: 惩罚参数C\n",
    "\n",
    "# **在测试集上评估**\n",
    "pred_labels, acc, vals = svm_predict(y_test.tolist(), X_test_list, svm_model)\n",
    "\n",
    "print(f\"测试集准确率: {acc[0]:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting libsvm\n",
      "  Downloading libsvm-3.23.0.4.tar.gz (170 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: libsvm\n",
      "  Building wheel for libsvm (setup.py): started\n",
      "  Building wheel for libsvm (setup.py): finished with status 'done'\n",
      "  Created wheel for libsvm: filename=libsvm-3.23.0.4-py3-none-any.whl size=150399 sha256=83d0191b1006ddf8067560b38067847a4fa28a20494ab01843bd192d07d7df0b\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\c1\\ce\\25\\0d50035499973fcbcc407fcb897d53e47b6eb4601308789aa6\n",
      "Successfully built libsvm\n",
      "Installing collected packages: libsvm\n",
      "Successfully installed libsvm-3.23.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install libsvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载特征矩阵: (390, 49, 15, 10)\n",
      "加载标签: (390,)\n",
      "训练集: (312, 7350), 测试集: (78, 7350)\n",
      "NaNs in X_train: 255200 / 2293200\n",
      "NaNs in X_test: 65240 / 573300\n",
      "NaNs in X_train (after cleaning): 0 / 360150\n",
      "NaNs in X_test (after cleaning): 0 / 80850\n",
      "KNN 测试集准确率: 0.00\n",
      "分类报告:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       1.0\n",
      "           2       0.00      0.00      0.00       1.0\n",
      "           3       0.00      0.00      0.00       0.0\n",
      "           4       0.00      0.00      0.00       1.0\n",
      "           5       0.00      0.00      0.00       1.0\n",
      "           6       0.00      0.00      0.00       1.0\n",
      "           8       0.00      0.00      0.00       1.0\n",
      "          10       0.00      0.00      0.00       1.0\n",
      "          11       0.00      0.00      0.00       1.0\n",
      "          15       0.00      0.00      0.00       1.0\n",
      "          22       0.00      0.00      0.00       1.0\n",
      "          24       0.00      0.00      0.00       1.0\n",
      "\n",
      "    accuracy                           0.00      11.0\n",
      "   macro avg       0.00      0.00      0.00      11.0\n",
      "weighted avg       0.00      0.00      0.00      11.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MY_SOFTWARE\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\MY_SOFTWARE\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\MY_SOFTWARE\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\MY_SOFTWARE\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\MY_SOFTWARE\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\MY_SOFTWARE\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def load_data(data_folder, test_size=0.2, random_state=42):\n",
    "    \"\"\" 加载 MyoWare EMG 特征数据，并拆分训练集和测试集 \"\"\"\n",
    "    feature_path = os.path.join(data_folder, \"feature_matrix.npy\")\n",
    "    label_path = os.path.join(data_folder, \"labels.npy\")\n",
    "\n",
    "    if not os.path.exists(feature_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"特征文件或标签文件未找到！\")\n",
    "\n",
    "    X = np.load(feature_path)  # 形状: (num_batches, num_windows, 15, num_channels)\n",
    "\n",
    "    # X = X[:,:,:,:6]\n",
    "    y = np.load(label_path)    # 形状: (num_batches,)\n",
    "\n",
    "    print(f\"加载特征矩阵: {X.shape}\")\n",
    "    print(f\"加载标签: {y.shape}\")\n",
    "\n",
    "    # **展平数据**: (num_batches, num_windows, 15, num_channels) → (num_batches, num_windows * 15 * num_channels)\n",
    "    num_batches, num_windows, num_rows, num_channels = X.shape\n",
    "    X = X.reshape(num_batches, -1)  # 变成 (num_batches, num_features)\n",
    "\n",
    "    # **确保每个类别都有足够样本**\n",
    "    num_classes = len(np.unique(y))\n",
    "    test_size = max(num_classes, int(len(y) * test_size))  # 至少保证每个类别有样本\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    print(f\"训练集: {X_train.shape}, 测试集: {X_test.shape}\")\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# **加载数据**\n",
    "data_folder = r\"E:\\MSC\\Spring\\AML\\GestureLink\\data\\G\\windowed_data\"\n",
    "X_train, X_test, y_train, y_test = load_data(data_folder)\n",
    "\n",
    "# **检查并去除 NaN**\n",
    "print(f\"NaNs in X_train: {np.isnan(X_train).sum()} / {X_train.size}\")\n",
    "print(f\"NaNs in X_test: {np.isnan(X_test).sum()} / {X_test.size}\")\n",
    "\n",
    "# 过滤 NaN 样本\n",
    "mask_train = ~np.isnan(X_train).any(axis=1)\n",
    "mask_test = ~np.isnan(X_test).any(axis=1)\n",
    "\n",
    "X_train, y_train = X_train[mask_train], y_train[mask_train]\n",
    "X_test, y_test = X_test[mask_test], y_test[mask_test]\n",
    "# print(X_train.shape, y_train.shape)\n",
    "# **再次检查 NaN**\n",
    "print(f\"NaNs in X_train (after cleaning): {np.isnan(X_train).sum()} / {X_train.size}\")\n",
    "print(f\"NaNs in X_test (after cleaning): {np.isnan(X_test).sum()} / {X_test.size}\")\n",
    "\n",
    "# **KNN 训练**\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # k=5\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# **KNN 预测**\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# **评估**\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"KNN 测试集准确率: {accuracy:.2f}\")\n",
    "\n",
    "# **打印分类报告**\n",
    "print(\"分类报告:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "特征文件或标签文件未找到！",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# **加载数据**\u001b[39;00m\n\u001b[0;32m     46\u001b[0m data_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mMSC\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAML\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAML-Project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mG\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwindowed_data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 47\u001b[0m X_train, X_test, y_train, y_test, num_classes \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# **构建 RNN（LSTM）模型**\u001b[39;00m\n\u001b[0;32m     51\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m     52\u001b[0m     LSTM(\u001b[38;5;241m64\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])),\n\u001b[0;32m     53\u001b[0m     BatchNormalization(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m     Dense(num_classes, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# 多分类任务\u001b[39;00m\n\u001b[0;32m     62\u001b[0m ])\n",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(data_folder, test_size, random_state)\u001b[0m\n\u001b[0;32m     13\u001b[0m label_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_folder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(feature_path) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(label_path):\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m特征文件或标签文件未找到！\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(feature_path)  \u001b[38;5;66;03m# 形状: (num_batches, num_windows, 15, num_channels)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(label_path)    \u001b[38;5;66;03m# 形状: (num_batches,)\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: 特征文件或标签文件未找到！"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def load_data(data_folder, test_size=0.2, random_state=42):\n",
    "    \"\"\" 加载 MyoWare EMG 特征数据，并拆分训练集和测试集 \"\"\"\n",
    "    feature_path = os.path.join(data_folder, \"feature_matrix.npy\")\n",
    "    label_path = os.path.join(data_folder, \"labels.npy\")\n",
    "\n",
    "    if not os.path.exists(feature_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"特征文件或标签文件未找到！\")\n",
    "\n",
    "    X = np.load(feature_path)  # 形状: (num_batches, num_windows, 15, num_channels)\n",
    "    y = np.load(label_path)    # 形状: (num_batches,)\n",
    "\n",
    "    print(f\"加载特征矩阵: {X.shape}\")\n",
    "    print(f\"加载标签: {y.shape}\")\n",
    "\n",
    "    # **调整数据格式 (num_batches, num_windows, 15, num_channels) → (num_batches, num_windows, 15 * num_channels)**\n",
    "    num_batches, num_windows, num_rows, num_channels = X.shape\n",
    "    X = X.reshape(num_batches, num_windows, num_rows * num_channels)  # (num_batches, num_windows, num_features)\n",
    "\n",
    "    # **归一化数据**\n",
    "    scaler = StandardScaler()\n",
    "    X = np.array([scaler.fit_transform(x) for x in X])\n",
    "\n",
    "    # **转换标签为 one-hot 编码**\n",
    "    num_classes = len(np.unique(y))\n",
    "    y = to_categorical(y, num_classes)\n",
    "\n",
    "    # **确保每个类别都有足够样本**\n",
    "    test_size = max(num_classes, int(len(y) * test_size))  # 至少保证每个类别有样本\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y.argmax(axis=1)\n",
    "    )\n",
    "\n",
    "    print(f\"训练集: {X_train.shape}, 测试集: {X_test.shape}\")\n",
    "    return X_train, X_test, y_train, y_test, num_classes\n",
    "\n",
    "# **加载数据**\n",
    "data_folder = r\"E:\\MSC\\AML\\AML-Project\\data\\G\\windowed_data\"\n",
    "X_train, X_test, y_train, y_test, num_classes = load_data(data_folder)\n",
    "\n",
    "\n",
    "# **构建 RNN（LSTM）模型**\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    LSTM(32, return_sequences=False),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  # 多分类任务\n",
    "])\n",
    "\n",
    "# **编译模型**\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# **训练 RNN**\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# **评估 RNN**\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nRNN 测试集准确率: {accuracy:.2f}\")\n",
    "\n",
    "# **打印分类报告**\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\n分类报告:\\n\", classification_report(y_test_classes, y_pred_classes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.20 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "vscode": {
   "interpreter": {
    "hash": "2403de98e458f1581c3ddc5cac98c8c9b462b82dd05a074a785d43eb5bf629fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
