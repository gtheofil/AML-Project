{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIBSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features from E:\\MSC\\AML\\AML-Project\\data\\G\\windowed_data\\feature_matrix.npy, shape: (390, 59, 15, 10)\n",
      "Loaded labels from E:\\MSC\\AML\\AML-Project\\data\\G\\windowed_data\\labels.npy, shape: (390,)\n",
      "Training set: X_train: (312, 8850), y_train: (312,)\n",
      "Testing set: X_test: (78, 8850), y_test: (78,)\n",
      "Accuracy = 8.97436% (7/78) (classification)\n",
      "测试集准确率: 8.97%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from libsvm.svmutil import *\n",
    "\n",
    "def load_data(data_folder, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    加载 `feature_matrix.npy` 和 `labels.npy` 数据，并划分训练集和测试集。\n",
    "\n",
    "    参数：\n",
    "    - data_folder: 存放数据的文件夹路径\n",
    "    - test_size: 测试集比例 (默认 20%)\n",
    "    - random_state: 随机种子，保证可复现性\n",
    "\n",
    "    返回：\n",
    "    - X_train: 训练集特征，形状 (train_samples, num_features)\n",
    "    - X_test: 测试集特征，形状 (test_samples, num_features)\n",
    "    - y_train: 训练集标签，形状 (train_samples,)\n",
    "    - y_test: 测试集标签，形状 (test_samples,)\n",
    "    \"\"\"\n",
    "    feature_path = os.path.join(data_folder, \"feature_matrix.npy\")\n",
    "    label_path = os.path.join(data_folder, \"labels.npy\")\n",
    "\n",
    "    if not os.path.exists(feature_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"特征文件或标签文件未找到，请检查路径！\")\n",
    "\n",
    "    X = np.load(feature_path)  # 形状 (num_batches, num_windows, 15, num_channels)\n",
    "    y = np.load(label_path)  # 形状 (num_batches,)\n",
    "\n",
    "    print(f\"Loaded features from {feature_path}, shape: {X.shape}\")\n",
    "    print(f\"Loaded labels from {label_path}, shape: {y.shape}\")\n",
    "\n",
    "    # **展平数据 (num_batches, num_windows, 15, num_channels) -> (num_batches, num_windows * 15 * num_channels)**\n",
    "    num_batches, num_windows, height, num_channels = X.shape\n",
    "    X = X.reshape(num_batches, -1)  # 变成 (num_batches, num_windows * 15 * num_channels)\n",
    "\n",
    "    # **划分训练集和测试集**\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    print(f\"Training set: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"Testing set: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# **数据路径**\n",
    "data_folder = r\"E:\\MSC\\AML\\AML-Project\\data\\G\\windowed_data\"\n",
    "X_train, X_test, y_train, y_test = load_data(data_folder)\n",
    "\n",
    "# **转换数据格式，适应 LIBSVM**\n",
    "X_train_list = [dict(enumerate(x, 1)) for x in X_train]  # 将 NumPy 数组转换为 LIBSVM 格式的字典列表\n",
    "X_test_list = [dict(enumerate(x, 1)) for x in X_test]  # 同样转换测试集\n",
    "\n",
    "# **训练 SVM 模型**\n",
    "svm_model = svm_train(y_train.tolist(), X_train_list, '-s 0 -t 2 -c 1')  # -s 0: C-SVC, -t 2: RBF 核, -c 1: 惩罚参数C\n",
    "\n",
    "# **在测试集上评估**\n",
    "pred_labels, acc, vals = svm_predict(y_test.tolist(), X_test_list, svm_model)\n",
    "\n",
    "print(f\"测试集准确率: {acc[0]:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载特征矩阵: (390, 59, 15, 10)\n",
      "加载标签: (390,)\n",
      "训练集: (312, 8850), 测试集: (78, 8850)\n",
      "NaNs in X_train: 305200 / 2761200\n",
      "NaNs in X_test: 78240 / 690300\n",
      "NaNs in X_train (after cleaning): 0 / 433650\n",
      "NaNs in X_test (after cleaning): 0 / 97350\n",
      "KNN 测试集准确率: 0.18\n",
      "分类报告:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         1\n",
      "           2       0.33      1.00      0.50         1\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.33      1.00      0.50         1\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "          22       0.00      0.00      0.00         1\n",
      "          24       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.18        11\n",
      "   macro avg       0.05      0.15      0.08        11\n",
      "weighted avg       0.06      0.18      0.09        11\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ANACON\\envs\\cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\ANACON\\envs\\cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\ANACON\\envs\\cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\ANACON\\envs\\cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\ANACON\\envs\\cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\ANACON\\envs\\cv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def load_data(data_folder, test_size=0.2, random_state=42):\n",
    "    \"\"\" 加载 MyoWare EMG 特征数据，并拆分训练集和测试集 \"\"\"\n",
    "    feature_path = os.path.join(data_folder, \"feature_matrix.npy\")\n",
    "    label_path = os.path.join(data_folder, \"labels.npy\")\n",
    "\n",
    "    if not os.path.exists(feature_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"特征文件或标签文件未找到！\")\n",
    "\n",
    "    X = np.load(feature_path)  # 形状: (num_batches, num_windows, 15, num_channels)\n",
    "\n",
    "    # X = X[:,:,:,:6]\n",
    "    y = np.load(label_path)    # 形状: (num_batches,)\n",
    "\n",
    "    print(f\"加载特征矩阵: {X.shape}\")\n",
    "    print(f\"加载标签: {y.shape}\")\n",
    "\n",
    "    # **展平数据**: (num_batches, num_windows, 15, num_channels) → (num_batches, num_windows * 15 * num_channels)\n",
    "    num_batches, num_windows, num_rows, num_channels = X.shape\n",
    "    X = X.reshape(num_batches, -1)  # 变成 (num_batches, num_features)\n",
    "\n",
    "    # **确保每个类别都有足够样本**\n",
    "    num_classes = len(np.unique(y))\n",
    "    test_size = max(num_classes, int(len(y) * test_size))  # 至少保证每个类别有样本\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    print(f\"训练集: {X_train.shape}, 测试集: {X_test.shape}\")\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# **加载数据**\n",
    "data_folder = r\"E:\\MSC\\AML\\AML-Project\\data\\G\\windowed_data\"\n",
    "X_train, X_test, y_train, y_test = load_data(data_folder)\n",
    "\n",
    "# **检查并去除 NaN**\n",
    "print(f\"NaNs in X_train: {np.isnan(X_train).sum()} / {X_train.size}\")\n",
    "print(f\"NaNs in X_test: {np.isnan(X_test).sum()} / {X_test.size}\")\n",
    "\n",
    "# 过滤 NaN 样本\n",
    "mask_train = ~np.isnan(X_train).any(axis=1)\n",
    "mask_test = ~np.isnan(X_test).any(axis=1)\n",
    "\n",
    "X_train, y_train = X_train[mask_train], y_train[mask_train]\n",
    "X_test, y_test = X_test[mask_test], y_test[mask_test]\n",
    "# print(X_train.shape, y_train.shape)\n",
    "# **再次检查 NaN**\n",
    "print(f\"NaNs in X_train (after cleaning): {np.isnan(X_train).sum()} / {X_train.size}\")\n",
    "print(f\"NaNs in X_test (after cleaning): {np.isnan(X_test).sum()} / {X_test.size}\")\n",
    "\n",
    "# **KNN 训练**\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # k=5\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# **KNN 预测**\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# **评估**\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"KNN 测试集准确率: {accuracy:.2f}\")\n",
    "\n",
    "# **打印分类报告**\n",
    "print(\"分类报告:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense, Dropout, BatchNormalization\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def load_data(data_folder, test_size=0.2, random_state=42):\n",
    "    \"\"\" 加载 MyoWare EMG 特征数据，并拆分训练集和测试集 \"\"\"\n",
    "    feature_path = os.path.join(data_folder, \"feature_matrix.npy\")\n",
    "    label_path = os.path.join(data_folder, \"labels.npy\")\n",
    "\n",
    "    if not os.path.exists(feature_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"特征文件或标签文件未找到！\")\n",
    "\n",
    "    X = np.load(feature_path)  # 形状: (num_batches, num_windows, 15, num_channels)\n",
    "    y = np.load(label_path)    # 形状: (num_batches,)\n",
    "\n",
    "    print(f\"加载特征矩阵: {X.shape}\")\n",
    "    print(f\"加载标签: {y.shape}\")\n",
    "\n",
    "    # **调整数据格式 (num_batches, num_windows, 15, num_channels) → (num_batches, num_windows, 15 * num_channels)**\n",
    "    num_batches, num_windows, num_rows, num_channels = X.shape\n",
    "    X = X.reshape(num_batches, num_windows, num_rows * num_channels)  # (num_batches, num_windows, num_features)\n",
    "\n",
    "    # **归一化数据**\n",
    "    scaler = StandardScaler()\n",
    "    X = np.array([scaler.fit_transform(x) for x in X])\n",
    "\n",
    "    # **转换标签为 one-hot 编码**\n",
    "    num_classes = len(np.unique(y))\n",
    "    y = to_categorical(y, num_classes)\n",
    "\n",
    "    # **确保每个类别都有足够样本**\n",
    "    test_size = max(num_classes, int(len(y) * test_size))  # 至少保证每个类别有样本\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y.argmax(axis=1)\n",
    "    )\n",
    "\n",
    "    print(f\"训练集: {X_train.shape}, 测试集: {X_test.shape}\")\n",
    "    return X_train, X_test, y_train, y_test, num_classes\n",
    "\n",
    "# **加载数据**\n",
    "data_folder = r\"E:\\MSC\\AML\\AML-Project\\data\\G\\windowed_data\"\n",
    "X_train, X_test, y_train, y_test, num_classes = load_data(data_folder)\n",
    "\n",
    "# **构建 RNN（LSTM）模型**\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    LSTM(32, return_sequences=False),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  # 多分类任务\n",
    "])\n",
    "\n",
    "# **编译模型**\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# **训练 RNN**\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# **评估 RNN**\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nRNN 测试集准确率: {accuracy:.2f}\")\n",
    "\n",
    "# **打印分类报告**\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\n分类报告:\\n\", classification_report(y_test_classes, y_pred_classes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
