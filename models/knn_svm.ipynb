{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def load_data(data_folder, test_size=0.2, random_state=42):\n",
    "    \"\"\" Load MyoWare EMG feature data and split into training/testing sets. \"\"\"\n",
    "    feature_path = os.path.join(data_folder, \"feature_matrix.npy\")\n",
    "    label_path = os.path.join(data_folder, \"labels.npy\")\n",
    "\n",
    "    if not os.path.exists(feature_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"Feature or label file not found!\")\n",
    "\n",
    "    X = np.load(feature_path)  # Shape: (num_batches, num_windows, 15, num_channels)\n",
    "    y = np.load(label_path)  # Shape: (num_batches,)\n",
    "\n",
    "    print(f\"Loaded features: {X.shape}\")\n",
    "    print(f\"Loaded labels: {y.shape}\")\n",
    "\n",
    "    # Flatten features: Reshape (num_batches, num_windows, 15, num_channels) â†’ (num_samples, num_features)\n",
    "    num_batches, num_windows, num_rows, num_channels = X.shape\n",
    "    X = X.reshape(num_batches, -1)  # Flatten everything except batches\n",
    "\n",
    "    num_classes = len(np.unique(y))\n",
    "    test_size = max(num_classes, int(len(y) * 0.2))  # At least one sample per class\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "\n",
    "    print(f\"Training set: {X_train.shape}, Testing set: {X_test.shape}\")\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features: (45, 59, 15, 1)\n",
      "Loaded labels: (45,)\n",
      "Training set: (36, 885), Testing set: (9, 885)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_folder = \"windowed_data\"\n",
    "X_train, X_test, y_train, y_test = load_data(data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in X_train: 10 / 31860\n",
      "NaNs in X_test: 0 / 7965\n",
      "\n",
      "NaNs in X_train: 0 / 29205\n",
      "NaNs in X_test: 0 / 7965\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check if any NaN exists in the dataset\n",
    "print(f\"NaNs in X_train: {np.isnan(X_train).sum()} / {X_train.size}\")\n",
    "print(f\"NaNs in X_test: {np.isnan(X_test).sum()} / {X_test.size}\")\n",
    "\n",
    "mask_train = ~np.isnan(X_train).any(axis=1)\n",
    "mask_test = ~np.isnan(X_test).any(axis=1)\n",
    "\n",
    "X_train, y_train = X_train[mask_train], y_train[mask_train]\n",
    "X_test, y_test = X_test[mask_test], y_test[mask_test]\n",
    "\n",
    "print()\n",
    "# Check if any NaN exists in the dataset\n",
    "print(f\"NaNs in X_train: {np.isnan(X_train).sum()} / {X_train.size}\")\n",
    "print(f\"NaNs in X_test: {np.isnan(X_test).sum()} / {X_test.size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVM Results ===\n",
      "Accuracy: 0.4444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.33      0.33         3\n",
      "           2       0.50      1.00      0.67         3\n",
      "           3       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.44         9\n",
      "   macro avg       0.28      0.44      0.33         9\n",
      "weighted avg       0.28      0.44      0.33         9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\theof\\miniconda3\\envs\\grad_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\theof\\miniconda3\\envs\\grad_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\theof\\miniconda3\\envs\\grad_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train SVM Classifier\n",
    "svm_clf = SVC(kernel='rbf', C=1, gamma='scale')\n",
    "svm_clf.fit(X_train, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "# Evaluate models\n",
    "print(\"\\n=== SVM Results ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== KNN Results ===\n",
      "Accuracy: 0.6667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.67      0.57         3\n",
      "           2       0.75      1.00      0.86         3\n",
      "           3       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.67         9\n",
      "   macro avg       0.75      0.67      0.64         9\n",
      "weighted avg       0.75      0.67      0.64         9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train KNN Classifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "y_pred_knn = knn_clf.predict(X_test)\n",
    "\n",
    "print(\"\\n=== KNN Results ===\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_knn):.4f}\")\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.20 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "vscode": {
   "interpreter": {
    "hash": "2403de98e458f1581c3ddc5cac98c8c9b462b82dd05a074a785d43eb5bf629fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
