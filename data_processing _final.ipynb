{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sensor_data1.csv (1/15)\n",
      "Detected 10 channels (excluding time column).\n",
      "Processing sensor_data10.csv (2/15)\n",
      "Detected 10 channels (excluding time column).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.signal import welch\n",
    "import os\n",
    "\n",
    "def process_emg_folder(input_folder, output_folder, shuffle_order_file):\n",
    "    \"\"\"\n",
    "    遍历 input_folder 下的所有 CSV 文件，处理 EMG 和 IMU 数据，并保存特征矩阵和标签到 output_folder。\n",
    "    \"\"\"\n",
    "    # 设定采样率\n",
    "    fs = 1000  # 采样率 Hz\n",
    "    cycle_duration = 10  # 每个周期 10 秒\n",
    "    skip_seconds = 4  # 跳过前 4 秒\n",
    "    use_seconds = 6  # 需要保留的秒数\n",
    "\n",
    "    cycle_samples = fs * cycle_duration  # 10 秒数据点数 = 10000\n",
    "    skip_samples = fs * skip_seconds  # 跳过 4 秒 = 4000\n",
    "    use_samples = fs * use_seconds  # 取后 6 秒 = 6000\n",
    "\n",
    "    # 滑动窗口参数\n",
    "    window_size = 200  # 200ms = 200 采样点\n",
    "    step_size = 100  # 100ms = 100 采样点\n",
    "    num_windows = (use_samples - window_size) // step_size + 1  # 计算窗口数\n",
    "\n",
    "    # 创建存储文件夹\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # **读取 shuffle_order.xlsx**\n",
    "    shuffle_df = pd.read_excel(shuffle_order_file, engine=\"openpyxl\")\n",
    "    if shuffle_df.shape[0] < 15:\n",
    "        raise ValueError(\"标签文件数据不足 15 组！请检查 `shuffle_order.xlsx`。\")\n",
    "\n",
    "    # 存储所有数据和标签\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "\n",
    "    # **遍历 CSV 文件**\n",
    "    csv_files = sorted([f for f in os.listdir(input_folder) if f.endswith(\".csv\")])\n",
    "\n",
    "    for file_idx, file_name in enumerate(csv_files):\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        print(f\"Processing {file_name} ({file_idx+1}/{len(csv_files)})\")\n",
    "\n",
    "        # **读取数据**\n",
    "        raw_data = pd.read_csv(file_path)\n",
    "\n",
    "        # **检查通道数（忽略时间列）**\n",
    "        num_channels = raw_data.shape[1] - 1\n",
    "        print(f\"Detected {num_channels} channels (excluding time column).\")\n",
    "\n",
    "        segments = []  # 存储所有分割后的数据\n",
    "        labels = shuffle_df.iloc[file_idx].values.tolist()  # 获取该文件对应的 26 组标签\n",
    "        num_cycles = 26  # 每个文件固定 26 段（每段 10s）\n",
    "\n",
    "        for i in range(num_cycles):\n",
    "            start_idx = i * cycle_samples + skip_samples  # 跳过前 4 秒\n",
    "            end_idx = start_idx + use_samples  # 取后 6 秒\n",
    "\n",
    "            if end_idx > len(raw_data):  # 处理不足 6000 采样点的情况\n",
    "                segment = raw_data.iloc[start_idx:].values  # 取剩余数据\n",
    "                pad_size = use_samples - len(segment)  # 计算填充数\n",
    "                segment = np.pad(segment, ((0, pad_size), (0, 0)), mode='constant', constant_values=0)  # 填充 0\n",
    "            else:\n",
    "                segment = raw_data.iloc[start_idx:end_idx].values  # 正常提取数据\n",
    "\n",
    "            # **滑动窗口**\n",
    "            windows = [\n",
    "                segment[j:j + window_size, 1:]  # 取 200 采样点，忽略时间列\n",
    "                for j in range(0, use_samples - window_size + 1, step_size)  # 滑动步长 100\n",
    "            ]\n",
    "            segments.append(np.array(windows))\n",
    "\n",
    "        # **转换为 NumPy 数组**\n",
    "        segments_array = np.array(segments)  # 形状 (26, num_windows, 200, num_channels)\n",
    "\n",
    "        # **计算特征**\n",
    "        features_batches = []\n",
    "        for batch_idx in range(segments_array.shape[0]):  # 26 个 batch\n",
    "            batch_features = []  # 存储当前 batch 的所有窗口特征\n",
    "            for window_idx in range(segments_array.shape[1]):  # 计算每个窗口\n",
    "                window = segments_array[batch_idx, window_idx]  # (200, num_channels)\n",
    "                features = extract_features(window)  # 计算 (15, 10)\n",
    "                batch_features.append(features)  # 存入 batch\n",
    "\n",
    "            features_batches.append(np.array(batch_features))\n",
    "\n",
    "        features_array = np.array(features_batches)  # (26, num_windows, 15, 10)\n",
    "\n",
    "        # **存储数据**\n",
    "        all_features.append(features_array)\n",
    "        all_labels.extend(labels)  # 每个文件 26个 cycle，取 shuffle_order.xlsx 里的前 26 个标签\n",
    "\n",
    "    # **最终转换为 NumPy 数组**\n",
    "    all_features = np.vstack(all_features)  # 合并所有 batch，形状 (总 batch, num_windows, 15, 10)\n",
    "    all_labels = np.array(all_labels)  # (总 batch,)\n",
    "\n",
    "    # **保存**\n",
    "    np.save(os.path.join(output_folder, \"feature_matrix.npy\"), all_features)\n",
    "    np.save(os.path.join(output_folder, \"labels.npy\"), all_labels)\n",
    "\n",
    "    print(f\"Feature extraction complete! Shape: {all_features.shape}\")\n",
    "    print(f\"Labels saved: {all_labels.shape}\")\n",
    "    print(f\"Feature matrix saved at: {output_folder}/feature_matrix.npy\")\n",
    "    print(f\"Labels saved at: {output_folder}/labels.npy\")\n",
    "\n",
    "def extract_features(segment):\n",
    "    \"\"\"\n",
    "    计算 EMG 和 IMU 的 15 个特征，并拼接成 (15, 10)\n",
    "    \"\"\"\n",
    "    # **分离 EMG (前四列) 和 IMU (后六列)**\n",
    "    emg_signals = segment[:, :4]  # 4 个 EMG 通道 (200, 4)\n",
    "    imu_signals = segment[:, 4:]  # 6 个 IMU 通道 (200, 6)\n",
    "\n",
    "    def compute_emg_features(signal):\n",
    "        return np.array([\n",
    "            np.var(signal), np.mean(np.abs(signal)), np.sqrt(np.mean(signal**2)),\n",
    "            np.std(signal), np.mean(np.abs(np.diff(signal))), np.max(signal),\n",
    "            np.min(signal), np.sum(np.diff(signal) > 0), np.sum(np.diff(np.sign(signal)) != 0),\n",
    "            stats.kurtosis(signal), stats.skew(signal), np.sum(np.abs(np.diff(signal))),\n",
    "            np.sum(signal ** 2), np.log10(np.mean(signal**2) + 1e-10),\n",
    "            np.mean(welch(signal, fs=1000, nperseg=200)[1])\n",
    "        ])\n",
    "\n",
    "    def compute_imu_features(signal):\n",
    "        return np.array([\n",
    "            np.var(signal), np.mean(signal), np.sqrt(np.mean(signal**2)),\n",
    "            np.std(signal), np.max(signal), np.min(signal),\n",
    "            stats.kurtosis(signal), stats.skew(signal),\n",
    "            np.mean(np.abs(np.diff(signal))), np.sum(np.abs(np.diff(signal))),\n",
    "            np.sum(signal ** 2), np.log10(np.mean(signal**2) + 1e-10),\n",
    "            np.mean(welch(signal, fs=1000, nperseg=200)[1]), np.median(signal), np.ptp(signal)\n",
    "        ])\n",
    "\n",
    "    emg_features = np.array([compute_emg_features(emg_signals[:, i]) for i in range(4)]).T  # (15, 4)\n",
    "    imu_features = np.array([compute_imu_features(imu_signals[:, i]) for i in range(6)]).T  # (15, 6)\n",
    "\n",
    "    return np.concatenate((emg_features, imu_features), axis=1)  # (15, 10)\n",
    "\n",
    "# **运行函数**\n",
    "root = r\"data\\G\"\n",
    "input_folder = root\n",
    "output_folder = os.path.join(root, \"windowed_data\")\n",
    "shuffle_order_file = os.path.join(root,\"shuffle_order.xlsx\")\n",
    "process_emg_folder(input_folder, output_folder, shuffle_order_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features from E:\\MSC\\Spring\\AML\\GestureLink\\data\\G\\windowed_data\\feature_matrix.npy, shape: (390, 59, 15, 7)\n",
      "Loaded labels from E:\\MSC\\Spring\\AML\\GestureLink\\data\\G\\windowed_data\\labels.npy, shape: (390,)\n",
      "Training set: X_train: (312, 59, 15, 7), y_train: (312,)\n",
      "Testing set: X_test: (78, 59, 15, 7), y_test: (78,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(data_folder, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    加载 `feature_matrix.npy` 和 `labels.npy` 数据，并划分训练集和测试集。\n",
    "\n",
    "    参数：\n",
    "    - data_folder: 存放数据的文件夹路径\n",
    "    - test_size: 测试集比例 (默认 20%)\n",
    "    - random_state: 随机种子，保证可复现性\n",
    "\n",
    "    返回：\n",
    "    - X_train: 训练集特征，形状 (train_batches, num_windows, 15, num_channels)\n",
    "    - X_test: 测试集特征，形状 (test_batches, num_windows, 15, num_channels)\n",
    "    - y_train: 训练集标签，形状 (train_batches,)\n",
    "    - y_test: 测试集标签，形状 (test_batches,)\n",
    "    \"\"\"\n",
    "    # **加载数据**\n",
    "    feature_path = os.path.join(data_folder, \"feature_matrix.npy\")\n",
    "    label_path = os.path.join(data_folder, \"labels.npy\")\n",
    "\n",
    "    if not os.path.exists(feature_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"特征文件或标签文件未找到，请检查路径！\")\n",
    "\n",
    "    X = np.load(feature_path)  # 形状 (num_batches, num_windows, 15, num_channels)\n",
    "    y = np.load(label_path)  # 形状 (num_batches,)\n",
    "\n",
    "    # **数据基本信息**\n",
    "    print(f\"Loaded features from {feature_path}, shape: {X.shape}\")\n",
    "    print(f\"Loaded labels from {label_path}, shape: {y.shape}\")\n",
    "\n",
    "    # **划分训练集和测试集**\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=random_state\n",
    "        )\n",
    "\n",
    "    # **打印数据划分信息**\n",
    "    print(f\"Training set: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"Testing set: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# **使用示例**\n",
    "data_folder = r\"E:\\MSC\\Spring\\AML\\GestureLink\\data\\G\\windowed_data\"\n",
    "X_train, X_test, y_train, y_test = load_data(data_folder)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.20 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2403de98e458f1581c3ddc5cac98c8c9b462b82dd05a074a785d43eb5bf629fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
