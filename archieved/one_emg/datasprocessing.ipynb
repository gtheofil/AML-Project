{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment 1 saved: Rows 4000 to 10000 (Padded: 0 rows)\n",
      "Segment 2 saved: Rows 14000 to 20000 (Padded: 0 rows)\n",
      "Segment 3 saved: Rows 24000 to 30000 (Padded: 0 rows)\n",
      "Total segments saved: 3\n",
      "Final NumPy Shape: (3, 6000, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 读取数据\n",
    "file_path = 'emg_data_20250219_160546_3_10.csv'  # 替换为你的文件路径\n",
    "raw_data = pd.read_csv(file_path)\n",
    "# 设定采样率\n",
    "fs = 1000  # 采样率 Hz\n",
    "cycle_duration = 10  # 每个周期 10 秒\n",
    "skip_seconds = 4  # 跳过前 4 秒\n",
    "use_seconds = 6  # 需要保留的秒数\n",
    "\n",
    "cycle_samples = fs * cycle_duration  # 10 秒的数据点数 = 10000\n",
    "skip_samples = fs * skip_seconds  # 需要跳过 4 秒 = 4000\n",
    "use_samples = fs * use_seconds  # 需要保留 6 秒 = 6000\n",
    "\n",
    "# 创建保存文件夹\n",
    "output_folder = 'segmented_data'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "segments = []  # 存储所有分割后的数据\n",
    "num_cycles = len(raw_data) // cycle_samples  # 计算完整的10秒周期数\n",
    "\n",
    "for i in range(num_cycles):\n",
    "    start_idx = i * cycle_samples + skip_samples  # 每个周期内从第 4 秒开始\n",
    "    end_idx = start_idx + use_samples  # 取后 6 秒的数据\n",
    "\n",
    "    if end_idx > len(raw_data):  # 如果索引超出范围，则截断并填充\n",
    "        segment = raw_data.iloc[start_idx:].values  # 取剩余的数据\n",
    "        pad_size = use_samples - len(segment)  # 计算需要填充的行数\n",
    "        segment = np.pad(segment, ((0, pad_size), (0, 0)), mode='constant', constant_values=0)  # 填充 0\n",
    "    else:\n",
    "        segment = raw_data.iloc[start_idx:end_idx].values  # 正常提取数据\n",
    "\n",
    "    segments.append(segment)  # 存入列表\n",
    "\n",
    "    # 存储到 CSV\n",
    "    # pd.DataFrame(segment).to_csv(f\"{output_folder}/segment_{i+1}.csv\", index=False, header=False)\n",
    "\n",
    "    print(f\"Segment {i+1} saved: Rows {start_idx} to {end_idx} (Padded: {pad_size if end_idx > len(raw_data) else 0} rows)\")\n",
    "\n",
    "# 转换为 NumPy 数组\n",
    "segments_array = np.array(segments)  # 形状: (num_segments, 6000, 数据列数)\n",
    "\n",
    "# 保存 NumPy 文件\n",
    "np.save(f\"{output_folder}/segments.npy\", segments_array)\n",
    "\n",
    "print(f\"Total segments saved: {num_cycles}\")\n",
    "print(f\"Final NumPy Shape: {segments_array.shape}\")  # 确保形状正确\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment 1 processed: Rows 4000 to 10000 (Padded: 0 rows)\n",
      "Segment 2 processed: Rows 14000 to 20000 (Padded: 0 rows)\n",
      "Segment 3 processed: Rows 24000 to 30000 (Padded: 0 rows)\n",
      "Final shape: (3, 59, 200, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 读取数据\n",
    "file_path =r'data/emg_data_20250219_160546_3_10.csv'  # 替换为你的文件路径\n",
    "raw_data = pd.read_csv(file_path)\n",
    "\n",
    "# 设定采样率\n",
    "fs = 1000  # 采样率 Hz\n",
    "cycle_duration = 10  # 每个周期 10 秒\n",
    "skip_seconds = 4  # 跳过前 4 秒\n",
    "use_seconds = 6  # 需要保留的秒数\n",
    "\n",
    "cycle_samples = fs * cycle_duration  # 10 秒的数据点数 = 10000\n",
    "skip_samples = fs * skip_seconds  # 需要跳过 4 秒 = 4000\n",
    "use_samples = fs * use_seconds  # 需要保留 6 秒 = 6000\n",
    "\n",
    "# 滑动窗口参数\n",
    "window_size = 200  # 200ms = 200 采样点\n",
    "step_size = 100  # 100ms = 100 采样点\n",
    "num_windows = (use_samples - window_size) // step_size + 1  # 计算每个片段可以滑动的窗口数量\n",
    "\n",
    "# 创建保存文件夹\n",
    "output_folder = 'segmented_data'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "segments = []  # 存储所有分割后的数据\n",
    "num_cycles = len(raw_data) // cycle_samples  # 计算完整的10秒周期数\n",
    "\n",
    "for i in range(num_cycles):\n",
    "    start_idx = i * cycle_samples + skip_samples  # 每个周期内从第 4 秒开始\n",
    "    end_idx = start_idx + use_samples  # 取后 6 秒的数据\n",
    "\n",
    "    if end_idx > len(raw_data):  # 如果索引超出范围，则截断并填充\n",
    "        segment = raw_data.iloc[start_idx:].values  # 取剩余的数据\n",
    "        pad_size = use_samples - len(segment)  # 计算需要填充的行数\n",
    "        segment = np.pad(segment, ((0, pad_size), (0, 0)), mode='constant', constant_values=0)  # 填充 0\n",
    "    else:\n",
    "        segment = raw_data.iloc[start_idx:end_idx].values  # 正常提取数据\n",
    "\n",
    "    # 滑动窗口切片\n",
    "    windows = [\n",
    "        segment[j : j + window_size]  # 取 200 采样点窗口\n",
    "        for j in range(0, use_samples - window_size + 1, step_size)  # 滑动步长为 100\n",
    "    ]\n",
    "\n",
    "    segments.append(np.array(windows))  # 存入列表\n",
    "\n",
    "    print(f\"Segment {i+1} processed: Rows {start_idx} to {end_idx} (Padded: {pad_size if end_idx > len(raw_data) else 0} rows)\")\n",
    "\n",
    "# 转换为 NumPy 数组，形状为 (num_segments, num_windows, 200, 数据列数)\n",
    "segments_array = np.array(segments)\n",
    "\n",
    "# 保存 NumPy 文件\n",
    "np.save(f\"{output_folder}/windowed_segments.npy\", segments_array)\n",
    "\n",
    "# 打印最终形状\n",
    "print(f\"Final shape: {segments_array.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 3 batches, 59 windows per batch, 2 channels.\n",
      "Feature extraction complete! Shape: (3, 59, 15, 2)\n",
      "Labels saved: [1 2 3]\n",
      "Feature matrix saved at: windowed_data/feature_matrix.npy\n",
      "Labels saved at: windowed_data/labels.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.signal import welch\n",
    "import os\n",
    "\n",
    "# 载入滑动窗口数据\n",
    "input_npy_path = \"segmented_data/windowed_segments.npy\"\n",
    "windowed_segments = np.load(input_npy_path)  # 形状 (3, 59, 200, 2)\n",
    "\n",
    "# **获取实际通道数（排除时间列）**\n",
    "num_batches, num_windows, window_size, num_channels = windowed_segments.shape\n",
    "print(f\"Detected {num_batches} batches, {num_windows} windows per batch, {num_channels} channels.\")\n",
    "\n",
    "# 创建存储文件夹\n",
    "output_folder = \"windowed_data\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 定义特征提取函数\n",
    "def extract_features(segment):\n",
    "    \"\"\"\n",
    "    计算一个窗口的 15 个特征, segment 形状: (200, num_channels)\n",
    "    返回: (15, num_channels) 的特征矩阵\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for channel in range(segment.shape[1]):  # 遍历通道\n",
    "        signal = segment[:, channel]  # 取单个通道数据\n",
    "\n",
    "        # **时域特征**\n",
    "        VAR = np.var(signal)  # 方差\n",
    "        MAV = np.mean(np.abs(signal))  # 平均绝对值\n",
    "        RMS = np.sqrt(np.mean(signal**2))  # 均方根\n",
    "        SDV = np.std(signal)  # 标准差\n",
    "        AAC = np.mean(np.abs(np.diff(signal)))  # 平均绝对变化率\n",
    "        MAX = np.max(signal)  # 最大值\n",
    "        SSC = np.sum(np.diff(signal) > 0)  # 符号变化数\n",
    "        ZCR = np.sum(np.diff(np.sign(signal)) != 0)  # 过零率\n",
    "        KUR = stats.kurtosis(signal)  # 峭度\n",
    "        SKW = stats.skew(signal)  # 偏度\n",
    "        WWL = np.sum(np.abs(np.diff(signal)))  # 波形长度\n",
    "        SSI = np.sum(signal ** 2)  # 积分平方\n",
    "        LGD = np.log10(np.mean(signal**2) + 1e-10)  # 对数能量\n",
    "\n",
    "        # **频域特征**\n",
    "        freqs, psd = welch(signal, fs=1000, nperseg=200)  # 计算功率谱密度\n",
    "        ARC = np.sum(psd)  # 频谱面积\n",
    "        MFR = np.sum(freqs * psd) / (np.sum(psd) + 1e-10)  # 频率质心\n",
    "        \n",
    "        # 存入特征列表\n",
    "        features.append([VAR, MAV, RMS, SDV, AAC, MAX, SSC, ZCR, KUR, SKW, WWL, SSI, LGD, ARC, MFR])\n",
    "\n",
    "    return np.array(features).T  # 变成 (15, num_channels)\n",
    "\n",
    "# 遍历所有 batch 计算特征\n",
    "features_batches = []\n",
    "labels = np.array([1, 2, 3])  # 3个 batch，分别标 1, 2, 3\n",
    "\n",
    "for batch_idx in range(num_batches):\n",
    "    batch_features = []  # 存储当前 batch 所有窗口的特征\n",
    "    for window_idx in range(num_windows):\n",
    "        window = windowed_segments[batch_idx, window_idx]  # 取单个窗口数据 (200, 2)\n",
    "        features = extract_features(window)  # 计算 (15, 2)\n",
    "        batch_features.append(features)  # 存入当前 batch\n",
    "\n",
    "    features_batches.append(np.array(batch_features))  # 存入 batch 级别的列表\n",
    "\n",
    "# **转换为 NumPy 数组，形状为 (3, 59, 15, 2)**\n",
    "features_array = np.array(features_batches)\n",
    "\n",
    "# **保存 NumPy 特征和标签**\n",
    "np.save(os.path.join(output_folder, \"feature_matrix.npy\"), features_array)\n",
    "np.save(os.path.join(output_folder, \"labels.npy\"), labels)\n",
    "\n",
    "# **打印结果**\n",
    "print(f\"Feature extraction complete! Shape: {features_array.shape}\")\n",
    "print(f\"Labels saved: {labels}\")\n",
    "print(f\"Feature matrix saved at: {output_folder}/feature_matrix.npy\")\n",
    "print(f\"Labels saved at: {output_folder}/labels.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing sensor_data_20250228_164403.csv (1/10)\n",
      "Detected 7 channels (excluding time column).\n",
      "Processing sensor_data_20250228_164644.csv (2/10)\n",
      "Detected 7 channels (excluding time column).\n",
      "Processing sensor_data_20250228_164741.csv (3/10)\n",
      "Detected 7 channels (excluding time column).\n",
      "Processing sensor_data_20250228_164835.csv (4/10)\n",
      "Detected 7 channels (excluding time column).\n",
      "Processing sensor_data_20250228_164937.csv (5/10)\n",
      "Detected 7 channels (excluding time column).\n",
      "Processing sensor_data_20250228_165210.csv (6/10)\n",
      "Detected 7 channels (excluding time column).\n",
      "Processing sensor_data_20250228_165306.csv (7/10)\n",
      "Detected 7 channels (excluding time column).\n",
      "Processing sensor_data_20250228_165502.csv (8/10)\n",
      "Detected 7 channels (excluding time column).\n",
      "Processing sensor_data_20250228_165752.csv (9/10)\n",
      "Detected 7 channels (excluding time column).\n",
      "Processing sensor_data_20250228_165916.csv (10/10)\n",
      "Detected 7 channels (excluding time column).\n",
      "Feature extraction complete! Shape: (30, 59, 15, 7)\n",
      "Labels saved: (30,)\n",
      "Feature matrix saved at: windowed_data/feature_matrix.npy\n",
      "Labels saved at: windowed_data/labels.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.signal import welch\n",
    "import os\n",
    "\n",
    "def process_emg_folder(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    遍历 input_folder 下的所有 CSV 文件，处理 EMG 数据，并保存特征矩阵和标签到 output_folder。\n",
    "    \"\"\"\n",
    "    # 设定采样率\n",
    "    fs = 1000  # 采样率 Hz\n",
    "    cycle_duration = 10  # 每个周期 10 秒\n",
    "    skip_seconds = 4  # 跳过前 4 秒\n",
    "    use_seconds = 6  # 需要保留的秒数\n",
    "\n",
    "    cycle_samples = fs * cycle_duration  # 10 秒数据点数 = 10000\n",
    "    skip_samples = fs * skip_seconds  # 跳过 4 秒 = 4000\n",
    "    use_samples = fs * use_seconds  # 取后 6 秒 = 6000\n",
    "\n",
    "    # 滑动窗口参数\n",
    "    window_size = 200  # 200ms = 200 采样点\n",
    "    step_size = 100  # 100ms = 100 采样点\n",
    "    num_windows = (use_samples - window_size) // step_size + 1  # 计算窗口数\n",
    "\n",
    "    # 创建存储文件夹\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # 存储所有数据和标签\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # 遍历文件夹中的所有 CSV 文件\n",
    "    csv_files = sorted([f for f in os.listdir(input_folder) if f.endswith(\".csv\")])\n",
    "    \n",
    "    for file_idx, file_name in enumerate(csv_files):\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        print(f\"Processing {file_name} ({file_idx+1}/{len(csv_files)})\")\n",
    "\n",
    "        # 读取数据\n",
    "        raw_data = pd.read_csv(file_path)\n",
    "\n",
    "        # **自动获取通道数（忽略时间列，从第 2 列开始）**\n",
    "        num_channels = raw_data.shape[1] - 1\n",
    "        print(f\"Detected {num_channels} channels (excluding time column).\")\n",
    "\n",
    "        segments = []  # 存储所有分割后的数据\n",
    "        labels = []  # 存储当前文件的标签\n",
    "        num_cycles = 3  # 每个文件固定分 3 段\n",
    "\n",
    "        for i in range(num_cycles):\n",
    "            start_idx = i * cycle_samples + skip_samples  # 跳过前 4 秒\n",
    "            end_idx = start_idx + use_samples  # 取后 6 秒\n",
    "\n",
    "            if end_idx > len(raw_data):  # 处理不足 6000 采样点的情况\n",
    "                segment = raw_data.iloc[start_idx:].values  # 取剩余数据\n",
    "                pad_size = use_samples - len(segment)  # 计算填充数\n",
    "                segment = np.pad(segment, ((0, pad_size), (0, 0)), mode='constant', constant_values=0)  # 填充 0\n",
    "            else:\n",
    "                segment = raw_data.iloc[start_idx:end_idx].values  # 正常提取数据\n",
    "\n",
    "            # **滑动窗口**\n",
    "            windows = [\n",
    "                segment[j:j + window_size, 1:]  # 取 200 采样点，忽略时间列\n",
    "                for j in range(0, use_samples - window_size + 1, step_size)  # 滑动步长 100\n",
    "            ]\n",
    "            segments.append(np.array(windows))\n",
    "\n",
    "            # **生成标签**\n",
    "            labels.append(i + 1)  # 第 1 段 = 1, 第 2 段 = 2, 第 3 段 = 3\n",
    "\n",
    "        # **转换为 NumPy 数组**\n",
    "        segments_array = np.array(segments)  # 形状 (num_segments=3, num_windows, 200, num_channels)\n",
    "\n",
    "        # **计算特征**\n",
    "        features_batches = []\n",
    "        for batch_idx in range(segments_array.shape[0]):  # 3 个 batch\n",
    "            batch_features = []  # 存储当前 batch 的所有窗口特征\n",
    "            for window_idx in range(segments_array.shape[1]):  # 计算每个窗口\n",
    "                window = segments_array[batch_idx, window_idx]  # (200, num_channels)\n",
    "                features = extract_features(window)  # 计算 (15, num_channels)\n",
    "                batch_features.append(features)  # 存入 batch\n",
    "\n",
    "            features_batches.append(np.array(batch_features))\n",
    "\n",
    "        features_array = np.array(features_batches)  # (3, num_windows, 15, num_channels)\n",
    "\n",
    "        # **存储数据**\n",
    "        all_features.append(features_array)\n",
    "        all_labels.extend(labels)  # 直接扩展标签列表\n",
    "\n",
    "    # **最终转换为 NumPy 数组**\n",
    "    all_features = np.vstack(all_features)  # 合并所有 batch，形状 (总 batch, num_windows, 15, num_channels)\n",
    "    all_labels = np.array(all_labels)  # (总 batch,)\n",
    "\n",
    "    # **保存**\n",
    "    np.save(os.path.join(output_folder, \"feature_matrix.npy\"), all_features)\n",
    "    np.save(os.path.join(output_folder, \"labels.npy\"), all_labels)\n",
    "\n",
    "    print(f\"Feature extraction complete! Shape: {all_features.shape}\")\n",
    "    print(f\"Labels saved: {all_labels.shape}\")\n",
    "    print(f\"Feature matrix saved at: {output_folder}/feature_matrix.npy\")\n",
    "    print(f\"Labels saved at: {output_folder}/labels.npy\")\n",
    "\n",
    "def extract_features(segment):\n",
    "    \"\"\"\n",
    "    计算一个窗口的 15 个特征, segment 形状: (200, num_channels)\n",
    "    返回: (15, num_channels) 的特征矩阵\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for channel in range(segment.shape[1]):  # 遍历通道\n",
    "        signal = segment[:, channel]  # 取单个通道数据\n",
    "\n",
    "        # **时域特征**\n",
    "        VAR = np.var(signal)  # 方差\n",
    "        MAV = np.mean(np.abs(signal))  # 平均绝对值\n",
    "        RMS = np.sqrt(np.mean(signal**2))  # 均方根\n",
    "        SDV = np.std(signal)  # 标准差\n",
    "        AAC = np.mean(np.abs(np.diff(signal)))  # 平均绝对变化率\n",
    "        MAX = np.max(signal)  # 最大值\n",
    "        SSC = np.sum(np.diff(signal) > 0)  # 符号变化数\n",
    "        ZCR = np.sum(np.diff(np.sign(signal)) != 0)  # 过零率\n",
    "        KUR = stats.kurtosis(signal)  # 峭度\n",
    "        SKW = stats.skew(signal)  # 偏度\n",
    "        WWL = np.sum(np.abs(np.diff(signal)))  # 波形长度\n",
    "        SSI = np.sum(signal ** 2)  # 积分平方\n",
    "        LGD = np.log10(np.mean(signal**2) + 1e-10)  # 对数能量\n",
    "\n",
    "        # **频域特征**\n",
    "        freqs, psd = welch(signal, fs=1000, nperseg=200)  # 计算功率谱密度\n",
    "        ARC = np.sum(psd)  # 频谱面积\n",
    "        MFR = np.sum(freqs * psd) / (np.sum(psd) + 1e-10)  # 频率质心\n",
    "        \n",
    "        # 存入特征列表\n",
    "        features.append([VAR, MAV, RMS, SDV, AAC, MAX, SSC, ZCR, KUR, SKW, WWL, SSI, LGD, ARC, MFR])\n",
    "\n",
    "    return np.array(features).T  # 变成 (15, num_channels)\n",
    "\n",
    "# **运行函数**\n",
    "input_folder = r\"E:\\MSC\\Spring\\AML\\GestureLink\\Data_grove\"\n",
    "output_folder = \"windowed_data\"\n",
    "process_emg_folder(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded features from windowed_data\\feature_matrix.npy, shape: (45, 59, 15, 1)\n",
      "Loaded labels from windowed_data\\labels.npy, shape: (45,)\n",
      "Training set: X_train: (36, 59, 15, 1), y_train: (36,)\n",
      "Testing set: X_test: (9, 59, 15, 1), y_test: (9,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(data_folder, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    加载 `feature_matrix.npy` 和 `labels.npy` 数据，并划分训练集和测试集。\n",
    "\n",
    "    参数：\n",
    "    - data_folder: 存放数据的文件夹路径\n",
    "    - test_size: 测试集比例 (默认 20%)\n",
    "    - random_state: 随机种子，保证可复现性\n",
    "\n",
    "    返回：\n",
    "    - X_train: 训练集特征，形状 (train_batches, num_windows, 15, num_channels)\n",
    "    - X_test: 测试集特征，形状 (test_batches, num_windows, 15, num_channels)\n",
    "    - y_train: 训练集标签，形状 (train_batches,)\n",
    "    - y_test: 测试集标签，形状 (test_batches,)\n",
    "    \"\"\"\n",
    "    # **加载数据**\n",
    "    feature_path = os.path.join(data_folder, \"feature_matrix.npy\")\n",
    "    label_path = os.path.join(data_folder, \"labels.npy\")\n",
    "\n",
    "    if not os.path.exists(feature_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"特征文件或标签文件未找到，请检查路径！\")\n",
    "\n",
    "    X = np.load(feature_path)  # 形状 (num_batches, num_windows, 15, num_channels)\n",
    "    y = np.load(label_path)  # 形状 (num_batches,)\n",
    "\n",
    "    # **数据基本信息**\n",
    "    print(f\"Loaded features from {feature_path}, shape: {X.shape}\")\n",
    "    print(f\"Loaded labels from {label_path}, shape: {y.shape}\")\n",
    "\n",
    "    # **划分训练集和测试集**\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=random_state\n",
    "        )\n",
    "\n",
    "    # **打印数据划分信息**\n",
    "    print(f\"Training set: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"Testing set: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# **使用示例**\n",
    "data_folder = \"windowed_data\"\n",
    "X_train, X_test, y_train, y_test = load_data(data_folder)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.20 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2403de98e458f1581c3ddc5cac98c8c9b462b82dd05a074a785d43eb5bf629fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
