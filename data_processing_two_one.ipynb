{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.signal import welch\n",
    "import os\n",
    "\n",
    "# 采样率和窗口参数\n",
    "FS = 1000  # 采样率 1000Hz\n",
    "CYCLE_DURATION = 10  # 每个周期 10 秒\n",
    "SKIP_SECONDS = 4  # 跳过前 4 秒\n",
    "USE_SECONDS = 6  # 选取后 6 秒\n",
    "CYCLE_SAMPLES = FS * CYCLE_DURATION  # 10 秒总样本数 = 10000\n",
    "SKIP_SAMPLES = FS * SKIP_SECONDS  # 4 秒跳过样本数 = 4000\n",
    "USE_SAMPLES = FS * USE_SECONDS  # 6 秒有效数据样本数 = 6000\n",
    "\n",
    "# 滑动窗口参数\n",
    "WINDOW_SIZE = 200  # 200ms = 200 采样点\n",
    "STEP_SIZE = 100  # 100ms = 100 采样点\n",
    "NUM_WINDOWS = (USE_SAMPLES - WINDOW_SIZE) // STEP_SIZE + 1  # 每 6s 生成的窗口数\n",
    "MAX_CYCLES = 10  # **最多支持 10 个手势周期**\n",
    "\n",
    "# 15 种特征名称\n",
    "FEATURE_NAMES = [\"VAR\", \"MAV\", \"RMS\", \"SDV\", \"AAC\", \"MAX\", \"SSC\", \"ZCR\",\n",
    "                 \"KUR\", \"SKW\", \"WWL\", \"SSI\", \"LGD\", \"ARC\", \"MFR\"]\n",
    "\n",
    "def extract_features(window):\n",
    "    \"\"\"计算单个窗口的 15 种特征，每个通道分别计算\"\"\"\n",
    "    num_channels = window.shape[1]\n",
    "    features = np.zeros((15, num_channels))\n",
    "\n",
    "    for ch in range(num_channels):\n",
    "        signal = window[:, ch]\n",
    "\n",
    "        # 时域特征\n",
    "        features[0, ch] = np.var(signal)  # 方差 VAR\n",
    "        features[1, ch] = np.mean(np.abs(signal))  # 平均绝对值 MAV\n",
    "        features[2, ch] = np.sqrt(np.mean(signal**2))  # 均方根 RMS\n",
    "        features[3, ch] = np.std(signal)  # 标准差 SDV\n",
    "        features[4, ch] = np.mean(np.abs(np.diff(signal)))  # 平均绝对变化率 AAC\n",
    "        features[5, ch] = np.max(signal)  # 最大值 MAX\n",
    "        features[6, ch] = np.sum(np.diff(signal) > 0)  # 符号变化数 SSC\n",
    "        features[7, ch] = np.sum(np.diff(np.sign(signal)) != 0)  # 过零率 ZCR\n",
    "        features[8, ch] = stats.kurtosis(signal)  # 峭度 KUR\n",
    "        features[9, ch] = stats.skew(signal)  # 偏度 SKW\n",
    "        features[10, ch] = np.sum(np.abs(np.diff(signal)))  # 波形长度 WWL\n",
    "        features[11, ch] = np.sum(signal ** 2)  # 积分平方 SSI\n",
    "        features[12, ch] = np.log10(np.mean(signal**2) + 1e-10)  # 对数能量 LGD\n",
    "\n",
    "        # 频域特征\n",
    "        freqs, psd = welch(signal, fs=FS, nperseg=200)\n",
    "        features[13, ch] = np.sum(psd)  # 频谱面积 ARC\n",
    "        features[14, ch] = np.sum(freqs * psd) / (np.sum(psd) + 1e-10)  # 频率质心 MFR\n",
    "\n",
    "    return features\n",
    "\n",
    "def process_emg_file(file_path, label):\n",
    "    \"\"\"\n",
    "    处理单个 CSV 文件，保证输出最多 10 个手势周期（不够填充 0，多了截取）。\n",
    "    输入：\n",
    "        - file_path: CSV 文件路径\n",
    "        - label: 当前文件的手势类别\n",
    "    输出：\n",
    "        - features_array: (MAX_CYCLES, num_windows, 15, num_channels) 的 NumPy 数组\n",
    "        - labels: (MAX_CYCLES,) 的 NumPy 数组\n",
    "    \"\"\"\n",
    "    raw_data = pd.read_csv(file_path)\n",
    "    num_channels = raw_data.shape[1] - 1  # 去掉时间列\n",
    "    print(f\"Processing {file_path}, Detected {num_channels} channels\")\n",
    "\n",
    "    # 计算完整的 10s 周期数\n",
    "    num_cycles = len(raw_data) // CYCLE_SAMPLES\n",
    "    num_cycles = min(num_cycles, MAX_CYCLES)  # **最多 10 个周期**\n",
    "    segments = []\n",
    "\n",
    "    for i in range(num_cycles):\n",
    "        start_idx = i * CYCLE_SAMPLES + SKIP_SAMPLES\n",
    "        end_idx = start_idx + USE_SAMPLES\n",
    "\n",
    "        if end_idx > len(raw_data):  # 处理不足 6000 采样点的情况\n",
    "            segment = raw_data.iloc[start_idx:].values\n",
    "            pad_size = USE_SAMPLES - len(segment)\n",
    "            segment = np.pad(segment, ((0, pad_size), (0, 0)), mode='constant', constant_values=0)\n",
    "        else:\n",
    "            segment = raw_data.iloc[start_idx:end_idx].values\n",
    "\n",
    "        # 滑动窗口\n",
    "        windows = np.array([\n",
    "            segment[j:j + WINDOW_SIZE, 1:]  # 取 200 采样点，去掉时间列\n",
    "            for j in range(0, USE_SAMPLES - WINDOW_SIZE + 1, STEP_SIZE)\n",
    "        ])\n",
    "        segments.append(windows)\n",
    "\n",
    "    # **填充不足 10 个周期的数据**\n",
    "    while len(segments) < MAX_CYCLES:\n",
    "        segments.append(np.zeros_like(segments[0]))  # 填充零\n",
    "\n",
    "    segments_array = np.array(segments)[:MAX_CYCLES]  # **确保最多 10 个周期**\n",
    "    print(f\"Segments shape: {segments_array.shape}\")\n",
    "\n",
    "    # 计算特征\n",
    "    features_batches = np.array([\n",
    "        np.array([extract_features(window) for window in cycle])  # (num_windows, 15, num_channels)\n",
    "        for cycle in segments_array\n",
    "    ])\n",
    "\n",
    "    # 生成正确的标签\n",
    "    labels = np.full(features_batches.shape[0], label)\n",
    "\n",
    "    return features_batches, labels\n",
    "\n",
    "def process_emg_folder(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    处理文件夹中的所有 EMG 数据文件，正确生成手势类别标签。\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    all_features, all_labels = [], []\n",
    "\n",
    "    csv_files = sorted([f for f in os.listdir(input_folder) if f.endswith(\".csv\")])\n",
    "    \n",
    "    # **假设文件顺序从 `1.csv` 到 `10.csv`，每个代表一个手势**\n",
    "    for idx, file_name in enumerate(csv_files):\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        label = idx + 1  # 1-10 对应 10 种手势类别\n",
    "        features, labels = process_emg_file(file_path, label)\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "\n",
    "    # 转换为 NumPy 数组并保存\n",
    "    all_features = np.vstack(all_features)  # (总样本数, num_windows, 15, num_channels)\n",
    "    all_labels = np.hstack(all_labels)  # (总样本数,)\n",
    "\n",
    "    np.save(os.path.join(output_folder, \"feature_matrix.npy\"), all_features)\n",
    "    np.save(os.path.join(output_folder, \"labels.npy\"), all_labels)\n",
    "\n",
    "    print(f\"Feature extraction complete! Shape: {all_features.shape}\")\n",
    "    print(f\"Labels saved: {all_labels.shape}\")\n",
    "\n",
    "# **运行处理**\n",
    "input_folder = \"data/data_1_sensor_3_classes/\"  # 输入数据文件夹\n",
    "output_folder = \"processed_data\"  # 处理后存储的文件夹\n",
    "process_emg_folder(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(data_folder, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    加载 `feature_matrix.npy` 和 `labels.npy` 数据，并划分训练集和测试集。\n",
    "\n",
    "    参数：\n",
    "    - data_folder: 存放数据的文件夹路径\n",
    "    - test_size: 测试集比例 (默认 20%)\n",
    "    - random_state: 随机种子，保证可复现性\n",
    "\n",
    "    返回：\n",
    "    - X_train: 训练集特征，形状 (train_samples, num_windows, 15, num_channels)\n",
    "    - X_test: 测试集特征，形状 (test_samples, num_windows, 15, num_channels)\n",
    "    - y_train: 训练集标签，形状 (train_samples,)\n",
    "    - y_test: 测试集标签，形状 (test_samples,)\n",
    "    \"\"\"\n",
    "    # **加载数据**\n",
    "    feature_path = os.path.join(data_folder, \"feature_matrix.npy\")\n",
    "    label_path = os.path.join(data_folder, \"labels.npy\")\n",
    "\n",
    "    if not os.path.exists(feature_path) or not os.path.exists(label_path):\n",
    "        raise FileNotFoundError(\"特征文件或标签文件未找到，请检查路径！\")\n",
    "\n",
    "    X = np.load(feature_path)  # 形状 (num_samples, num_windows, 15, num_channels)\n",
    "    y = np.load(label_path)  # 形状 (num_samples,)\n",
    "\n",
    "    # **数据基本信息**\n",
    "    print(f\"Loaded features from {feature_path}, shape: {X.shape}\")\n",
    "    print(f\"Loaded labels from {label_path}, shape: {y.shape}\")\n",
    "\n",
    "    # **划分训练集和测试集**\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    # **打印数据划分信息**\n",
    "    print(f\"Training set: X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"Testing set: X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# **使用示例**\n",
    "data_folder = \"windowed_data\"\n",
    "X_train, X_test, y_train, y_test = load_data(data_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 读取数据\n",
    "file_path =r'data/emg_data_20250219_160546_3_10.csv'  # 替换为你的文件路径\n",
    "raw_data = pd.read_csv(file_path)\n",
    "\n",
    "# 设定采样率\n",
    "fs = 1000  # 采样率 Hz\n",
    "cycle_duration = 10  # 每个周期 10 秒\n",
    "skip_seconds = 4  # 跳过前 4 秒\n",
    "use_seconds = 6  # 需要保留的秒数\n",
    "\n",
    "cycle_samples = fs * cycle_duration  # 10 秒的数据点数 = 10000\n",
    "skip_samples = fs * skip_seconds  # 需要跳过 4 秒 = 4000\n",
    "use_samples = fs * use_seconds  # 需要保留 6 秒 = 6000\n",
    "\n",
    "# 滑动窗口参数\n",
    "window_size = 200  # 200ms = 200 采样点\n",
    "step_size = 100  # 100ms = 100 采样点\n",
    "num_windows = (use_samples - window_size) // step_size + 1  # 计算每个片段可以滑动的窗口数量\n",
    "\n",
    "# 创建保存文件夹\n",
    "output_folder = 'segmented_data'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "segments = []  # 存储所有分割后的数据\n",
    "num_cycles = len(raw_data) // cycle_samples  # 计算完整的10秒周期数\n",
    "\n",
    "for i in range(num_cycles):\n",
    "    start_idx = i * cycle_samples + skip_samples  # 每个周期内从第 4 秒开始\n",
    "    end_idx = start_idx + use_samples  # 取后 6 秒的数据\n",
    "\n",
    "    if end_idx > len(raw_data):  # 如果索引超出范围，则截断并填充\n",
    "        segment = raw_data.iloc[start_idx:].values  # 取剩余的数据\n",
    "        pad_size = use_samples - len(segment)  # 计算需要填充的行数\n",
    "        segment = np.pad(segment, ((0, pad_size), (0, 0)), mode='constant', constant_values=0)  # 填充 0\n",
    "    else:\n",
    "        segment = raw_data.iloc[start_idx:end_idx].values  # 正常提取数据\n",
    "\n",
    "    # 滑动窗口切片\n",
    "    windows = [\n",
    "        segment[j : j + window_size]  # 取 200 采样点窗口\n",
    "        for j in range(0, use_samples - window_size + 1, step_size)  # 滑动步长为 100\n",
    "    ]\n",
    "\n",
    "    segments.append(np.array(windows))  # 存入列表\n",
    "\n",
    "    print(f\"Segment {i+1} processed: Rows {start_idx} to {end_idx} (Padded: {pad_size if end_idx > len(raw_data) else 0} rows)\")\n",
    "\n",
    "# 转换为 NumPy 数组，形状为 (num_segments, num_windows, 200, 数据列数)\n",
    "segments_array = np.array(segments)\n",
    "\n",
    "# 保存 NumPy 文件\n",
    "np.save(f\"{output_folder}/windowed_segments.npy\", segments_array)\n",
    "\n",
    "# 打印最终形状\n",
    "print(f\"Final shape: {segments_array.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.signal import welch\n",
    "import os\n",
    "\n",
    "def process_emg_folder(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    遍历 input_folder 下的所有 CSV 文件，分别处理 EMG 和 IMU 数据，并保存特征矩阵和标签到 output_folder。\n",
    "    \"\"\"\n",
    "    # 设定采样率\n",
    "    fs = 1000  # 采样率 Hz\n",
    "    cycle_duration = 10  # 每个周期 10 秒\n",
    "    skip_seconds = 4  # 跳过前 4 秒\n",
    "    use_seconds = 6  # 需要保留的秒数\n",
    "\n",
    "    cycle_samples = fs * cycle_duration  # 10 秒数据点数 = 10000\n",
    "    skip_samples = fs * skip_seconds  # 跳过 4 秒 = 4000\n",
    "    use_samples = fs * use_seconds  # 取后 6 秒 = 6000\n",
    "\n",
    "    # 滑动窗口参数\n",
    "    window_size = 200  # 200ms = 200 采样点\n",
    "    step_size = 100  # 100ms = 100 采样点\n",
    "    num_windows = (use_samples - window_size) // step_size + 1  # 计算窗口数\n",
    "\n",
    "    # 创建存储文件夹\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # 存储所有数据和标签\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # 遍历文件夹中的所有 CSV 文件\n",
    "    csv_files = sorted([f for f in os.listdir(input_folder) if f.endswith(\".csv\")])\n",
    "    \n",
    "    for file_idx, file_name in enumerate(csv_files):\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        print(f\"Processing {file_name} ({file_idx+1}/{len(csv_files)})\")\n",
    "\n",
    "        # 读取数据\n",
    "        raw_data = pd.read_csv(file_path)\n",
    "\n",
    "        # **获取通道数（忽略时间列）**\n",
    "        num_channels = raw_data.shape[1] - 1\n",
    "        print(f\"Detected {num_channels} channels (excluding time column).\")\n",
    "\n",
    "        segments = []  # 存储所有分割后的数据\n",
    "        labels = []  # 存储当前文件的标签\n",
    "        num_cycles = 3  # 每个文件固定分 3 段\n",
    "\n",
    "        for i in range(num_cycles):\n",
    "            start_idx = i * cycle_samples + skip_samples  # 跳过前 4 秒\n",
    "            end_idx = start_idx + use_samples  # 取后 6 秒\n",
    "\n",
    "            if end_idx > len(raw_data):  # 处理不足 6000 采样点的情况\n",
    "                segment = raw_data.iloc[start_idx:].values  # 取剩余数据\n",
    "                pad_size = use_samples - len(segment)  # 计算填充数\n",
    "                segment = np.pad(segment, ((0, pad_size), (0, 0)), mode='constant', constant_values=0)  # 填充 0\n",
    "            else:\n",
    "                segment = raw_data.iloc[start_idx:end_idx].values  # 正常提取数据\n",
    "\n",
    "            # **滑动窗口**\n",
    "            windows = [\n",
    "                segment[j:j + window_size, 1:]  # 取 200 采样点，忽略时间列\n",
    "                for j in range(0, use_samples - window_size + 1, step_size)  # 滑动步长 100\n",
    "            ]\n",
    "            segments.append(np.array(windows))\n",
    "\n",
    "            # **生成标签**\n",
    "            labels.append(i + 1)  # 第 1 段 = 1, 第 2 段 = 2, 第 3 段 = 3\n",
    "\n",
    "        # **转换为 NumPy 数组**\n",
    "        segments_array = np.array(segments)  # 形状 (num_segments=3, num_windows, 200, num_channels)\n",
    "\n",
    "        # **计算特征**\n",
    "        features_batches = []\n",
    "        for batch_idx in range(segments_array.shape[0]):  # 3 个 batch\n",
    "            batch_features = []  # 存储当前 batch 的所有窗口特征\n",
    "            for window_idx in range(segments_array.shape[1]):  # 计算每个窗口\n",
    "                window = segments_array[batch_idx, window_idx]  # (200, num_channels)\n",
    "                features = extract_features(window)  # 计算 (15, 7)\n",
    "                batch_features.append(features)  # 存入 batch\n",
    "\n",
    "            features_batches.append(np.array(batch_features))\n",
    "\n",
    "        features_array = np.array(features_batches)  # (3, num_windows, 15, 7)\n",
    "\n",
    "        # **存储数据**\n",
    "        all_features.append(features_array)\n",
    "        all_labels.extend(labels)  # 直接扩展标签列表\n",
    "\n",
    "    # **最终转换为 NumPy 数组**\n",
    "    all_features = np.vstack(all_features)  # 合并所有 batch，形状 (总 batch, num_windows, 15, 7)\n",
    "    all_labels = np.array(all_labels)  # (总 batch,)\n",
    "\n",
    "    # **保存**\n",
    "    np.save(os.path.join(output_folder, \"feature_matrix.npy\"), all_features)\n",
    "    np.save(os.path.join(output_folder, \"labels.npy\"), all_labels)\n",
    "\n",
    "    print(f\"Feature extraction complete! Shape: {all_features.shape}\")\n",
    "    print(f\"Labels saved: {all_labels.shape}\")\n",
    "    print(f\"Feature matrix saved at: {output_folder}/feature_matrix.npy\")\n",
    "    print(f\"Labels saved at: {output_folder}/labels.npy\")\n",
    "\n",
    "def extract_features(segment):\n",
    "    \"\"\"\n",
    "    分别计算 EMG 和 IMU 的 15 个特征，并拼接成 (15, 7)\n",
    "    \"\"\"\n",
    "    # **分离 EMG (第一列) 和 IMU (后六列)**\n",
    "    emg_signal = segment[:, 0]  # EMG 数据 (200,)\n",
    "    imu_signals = segment[:, 1:]  # IMU 数据 (200, 6)\n",
    "\n",
    "    # **定义 EMG 特征**\n",
    "    def compute_emg_features(signal):\n",
    "        return np.array([\n",
    "            np.var(signal), np.mean(np.abs(signal)), np.sqrt(np.mean(signal**2)),\n",
    "            np.std(signal), np.mean(np.abs(np.diff(signal))), np.max(signal),\n",
    "            np.min(signal), np.sum(np.diff(signal) > 0), np.sum(np.diff(np.sign(signal)) != 0),\n",
    "            stats.kurtosis(signal), stats.skew(signal), np.sum(np.abs(np.diff(signal))),\n",
    "            np.sum(signal ** 2), np.log10(np.mean(signal**2) + 1e-10),\n",
    "            np.mean(welch(signal, fs=1000, nperseg=200)[1])  # 频谱均值\n",
    "        ])\n",
    "\n",
    "    # **定义 IMU 特征**\n",
    "    def compute_imu_features(signal):\n",
    "        return np.array([\n",
    "            np.var(signal), np.mean(signal), np.sqrt(np.mean(signal**2)),\n",
    "            np.std(signal), np.max(signal), np.min(signal),\n",
    "            stats.kurtosis(signal), stats.skew(signal),\n",
    "            np.mean(np.abs(np.diff(signal))), np.sum(np.abs(np.diff(signal))),\n",
    "            np.sum(signal ** 2), np.log10(np.mean(signal**2) + 1e-10),\n",
    "            np.mean(welch(signal, fs=1000, nperseg=200)[1]), np.median(signal), np.ptp(signal)  # 频谱均值、中值、峰峰值\n",
    "        ])\n",
    "\n",
    "    emg_features = compute_emg_features(emg_signal).reshape(-1, 1)  # (15, 1)\n",
    "    imu_features = np.array([compute_imu_features(imu_signals[:, i]) for i in range(6)]).T  # (15, 6)\n",
    "\n",
    "    return np.concatenate((emg_features, imu_features), axis=1)  # (15, 7)\n",
    "\n",
    "# **运行函数**\n",
    "input_folder = \"data/data_1_sensor_3_classes/\"\n",
    "output_folder = \"windowed_data\"\n",
    "process_emg_folder(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.20 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.20"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2403de98e458f1581c3ddc5cac98c8c9b462b82dd05a074a785d43eb5bf629fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
